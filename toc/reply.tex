\documentclass[12pt]{article}

%\usepackage{latexsym,amsmath,amsfonts}
%\usepackage{fullpage,amsmath, amsfonts,xspace,graphicx,relsize,bm,mathtools,xcolor}

\usepackage{amsmath, amssymb,amsfonts,xspace,graphicx,relsize,bm,mathtools,xcolor}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage[pagebackref]{hyperref}

\def\01{\{0,1\}}
\newcommand{\ceil}[1]{\lceil{#1}\rceil}
\newcommand{\floor}[1]{\lfloor{#1}\rfloor}
\newcommand{\eps}{\varepsilon}
\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\bra}[1]{\langle#1|}
\newcommand{\ketbra}[2]{|#1\rangle\langle#2|}
\newcommand{\braket}[2]{\langle#1|#2\rangle}
\newcommand{\inp}[2]{\langle{#1},{#2}\rangle} % inproduct, < , >
\newcommand{\Tr}{\mbox{\rm Tr}}
\newcommand{\diag}{\mbox{\rm diag}}
\newcommand{\polylog}{\mbox{\rm polylog}}
\newcommand{\norm}[1]{\mbox{$\parallel{#1}\parallel$}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Cc}{{\mathcal C}} %concept class, \C is already in use for complex nrs
\newcommand{\Exp}{\mathbb{E}}
\newcommand{\De}{\ensuremath{\mathcal{D}}}
\newcommand{\Sh}{\ensuremath{\mathcal{S}}}

\newcommand{\DW}{{\sf Dog-Walker }}
\newcommand{\Leash}{{\sf Leash }}
\newcommand{\Broad}{{\sf Broadbent }}
\newcommand{\EPR}{{\sf EPR }}

\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\Fspan}{\mathrm{Fspan}}
\newcommand{\Fdim}{\mathrm{Fdim}}
\newcommand{\B}{\ensuremath{\mathcal{B}}}
\newcommand{\T}{\ensuremath{\mathcal{T}}}
\newcommand{\V}{\ensuremath{\mathcal{V}}}
\newcommand{\W}{\ensuremath{\mathcal{W}}}
\newcommand{\F}{\ensuremath{\mathbb{F}}}
\newcommand{\R}{\ensuremath{\mathbb{R}}}

\DeclareMathOperator{\poly}{poly}
\newcommand{\Se}{\ensuremath{\mathcal{S}}}
\newcommand{\Fe}{\ensuremath{\mathcal{F}}}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{fact}{Fact}
\newtheorem{corollary}{Corollary}
\newtheorem{conjecture}{Conjecture}
\newtheorem{observation}{Observation}
\newtheorem{claim}{Claim}
\newcommand{\pmset}[1]{\{-1,1\}^{#1}} % hypercube in +-1 basis
\newcommand{\AND}{\mbox{\rm AND}}
\newcommand{\ADV}{\mbox{\rm ADV}}
\def\01{\{0,1\}}
\DeclareMathOperator{\Inf}{Inf}
\DeclareMathOperator{\Add}{Add}
\newcommand{\supp}{\mathrm{supp}}
\newcommand{\sgn}{\mathrm{sign}}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\spann}{span}
\usepackage{parskip}
\setlength{\parindent}{7mm}

\newcommand{\resp}[1]{\textcolor{blue}{#1}}

\usepackage{kpfonts}
%\newenvironment{proof}{\par\noindent{\bf Proof.}\quad}{  $\qed$}
\newenvironment{proofof}[1]{\par\noindent{\bf Proof of #1.}\quad}{  $\qed$}

\usepackage[margin=1in]{geometry}
\hypersetup{
	colorlinks,
	linkcolor={blue!100!black},
	citecolor={blue!100!black},
}

\newenvironment{proof}
{\noindent {\bf Proof. }}
{{\hfill $\Box$}\\
	\smallskip}



\begin{document}
	
	
\title{Response Letter}

\author{Andrea Coladangelo\thanks{}
  \and Alex B. Grilo\thanks{Sorbonne Universit\'{e}, LIP6 and CNRS, Paris, France. Alex.Bredariol-Grilo@lip6.fr}
  \and Stacey Jeffery\thanks{QuSoft and CWI, Amsterdam, the Netherlands. jeffery@cwi.nl} % Supported by an NWO Veni Innovational Research Grant under project number 639.021.752 and an NWO WISE Grant.}%\inst{2}
  \and Thomas Vidick\thanks{Department of Computing and Mathematical Sciences, Caltech, Pasadena, USA. vidick@cms.caltech.edu}}
\date{}


	\maketitle
\subsection*{General}
\subsubsection*{Reviewer 1}
Then, for the proof of the main lemmas and theorems, more details should be spelled out so that it is possible to verify by readers. As an optional improvement, I suggest the authors to consider if there are simpler and more elegant ways of proving the rigidity for Clifford observables.

As an optional improvement, I suggest the authors to consider if there are simpler and more elegant ways of proving the rigidity for Clifford observables. The choice of {X, Y, Z, F, G}, though natural arises from the EPR protocol, could have made the protocol and the analysis cumbersome. Probably considering all of the Clifford group could make the analysis more streamlined.	


\subsubsection*{Reviewer 3}

\paragraph{Introduction}
Here, I suggest to categorizing clearly the protocols early on.
 This will help the reader make a clear mental picture in their mind of what they can expect in the rest of the paper.

e.g. introduce \Leash and \DW much sooner. It is not very useful to a reader to try to make a mental image of what the ``first'' and ``second'' protocol mean-- you might as well give the correct names immediately.

\paragraph{\Broad vs. \EPR protocols}
\label{sec:broad-EPR}
Currently, the submission only focuses on the \EPR protocol from prior work. But in reality, \Leash can be based more directly on the \Broad protocol (the \Broad protocol is the ``prepare-and-measure'' scheme that is the basic protocol in [Bro18]). I don't know if the authors realize this when they write: ``Unlike in the EPR Protocol,
the interaction with PV (i.e. running $V^r_{EPR}$) will take place first, and PV will be asked to perform random
measurements from the set (...). The values~z, rather than being chosen at random, will be
chosen based on the corresponding choice of observable. ''(p.30). In this passage, it appears that they have basically re-invented \Broad. I think it is much more conceptually simple to explain that \Leash delegates the preparation of the random eigenstates required in \Broad (from $V$ to $PV$), thus enabling the classical part of \Broad to be executed between $PP$ and $V$.

Then, it is easier to explain how \DW takes advantage of the time-reversal properties of \EPR: here, we instead want $PP$ to do all their operations \emph{first}, and then we give all the classical outcomes of $PP$ directly to $PV$, who does the adaptive quantum measurements from the verifier in $\EPR$. Of course, we also need to make sure that the classical outcomes from $PP$ do not allow to violate soundness (this is ensured via rigidity, since the honest measurements result in uniform bits), and we need to make sure that $PV$ does the operations honestly (this is also ensured via rigidity).

\paragraph{Protocol Presentation}

It is currently quite difficult to piece together the protocols in order to understand how they work together. For instance, some protocols (see e.g. Figures 4, 5, 6) contain different levels of abstraction in different sub-routines (some subroutines are figures elsewhere, whereas some subroutines are ``ad-hoc'' tests, and are explained directly in that figure). Would it be possible to be consistent in the level of abstraction, for each sub-routine in a protocol, or is there a good reason for including ``ad-hoc'' tests here?

In order to help understand the links between the protocols, I suggest:
\begin{enumerate}
\item Add a summary of Figures. This will help in making the connections between the various sub-protocols.
\item Consider adding a figure that shows the link between the protocols, for each of \Leash and \DW.  These would probably end up looking each like a tree: \Leash is the root, with branches \Broad and RIGID, and then \Broad branches out into computation, X-test and Z-test, while RIGID is the conjugation, extended Pauli braiding test, and more---and so on and so forth. You could also add to this figure the intuition for each sub-protocol, to the extent that this is possible (e.g. that RIGID tests PV's preparation). This exercise may also unveil some methods to simplify the presentation (and will also highlight where the ``ad-hoc'' tests show up, and how they can be better presented).
\end{enumerate}
	
\subsection*{Section 1}
\subsubsection*{Reviewer 1}
First, in the introduction part where the intuitions are discussed, possible improvements include a discussion on the idea behind the dog-walk protocol, how it achieves the constant round property from the multiple round EPR protocol, the reason for introducing the TOM test and the idea behind the design, and so on.

\subsubsection*{Reviewer 3}


The rest of this report contains more precise suggested changes, organized by section.

Some of the comments below may overlap with those from the prior section.

\begin{enumerate}
\item (page 1) In the abstract, mention ``statistical'' or ``perfect'' soundness, in order to contrast with computational security.
\item (page 2) ``(not all papers provide explicit bounds, in which case
our estimates, although generally conservative, should be taken with caution'' : please specify which bounds are your own, and which bounds were taken from the references.
\item (page 2) ``The most efficient classical-verifier delegation protocols known [FH15, NV17]'' These two references are not in Table 1, and I fail to see why (it is because table~1 is only for the two-prover setting? Or maybe because of the ``post-hoc''?) Please clarify.
\item (page 3) ``it does not provide a means for the verifier to test
the provers’ implementation of the required circuit on a gate-by-gate basis.'' Please give more context on why this is mentionned. Is this seen as a drawback? Also, technically, is there not part of the history state verification that does check that each timestep is implemented correctly (in superposition)?
\item (page 3) Table 1, 4th row. Is it HDF2015, or HPDF15?
\item (page 3) ``the most
efficient single-prover quantum-verifier protocols can evaluate a quantum circuit with g gates in time O(g).'' : which reference achieves this?
\item (page 4) ``The robustness for
previous results in parallel self-testing typically had a polynomial dependence on the number of EPR pairs
tested. '' Please be more specific on which previous results had an inadequate scaling, and which one did. My current reading is that only [NV17] was adequate, and what your result is doing is extending [NV17]. This seems reasonable; so I would suggest to be more direct about it.
\item (page 4) You credit some ideas to [Slo16], but there are no further citations to [Slo16]. Please include more details, perhaps in the main text, of where the ideas of [Slo16] are used.
    \item (page 4--5) ``Our work is the first to propose verifiable two-prover delegation
protocols that overcome the prohibitively large resource requirements of all previous multi-prover protocols, requiring only a quasilinear amount of resources, in terms of number of EPR pairs and time. However,
notwithstanding our improvements, a physical implementation of verifiable delegation protocols remains a
challenging task for the available technology.'' This passage seems misplaced. I would place is much sooner, and only recall it here (if even necessary--- I think this has been said already).
\item (page 5). I would place the material starting at ``We introduce the protocols in more detail'' in a new subsection. Add more headings and give more structure to the text. This will make it easier for the reader to make a clear mental picture of the main contributions.
\item (page 5) ``The protocols provide different methods to delegate the
quantum computation performed by the quantum verifier from [Bro18] to a second prover (call him PV for
Prover V).'' This makes no sense to me. I think I am confused with the pronouns. ``call him PP for Prover P'' would seem correct to me, or even better would be explain here the convention of naming for both PV and PP. Then, stop using ``first'' and ``second'' prover since this gets really confusing. Call them PV and PP.
\item (page 5) ``In the first protocol''. Immediately give the name \Leash to the protocol. This is much more memorable than ``first'', so it will help the reader grasp the concepts better. Put this description in its own subsection (or subsubsection or whatever).
\item (page 5) ``As PV just performs single-qubit and Bell bsis
measurements, universal quantum computational power is not needed for this prover.'' You just said in the prior paragraph that the honest verifier needs to do Clifford observables only. But now, you add Bell basis measurements. There is certainly a reason to all of this, but right now, this is very confusing. Please clarify, or delete/move if this is not the place to be as precise as you are trying to be.
\item (page 5). It is too early to link to Figure 14 (typically, when I see a link to a Figure, I take this as meaning that I should read that Figure). Same for Figures 11, 12, 14 and 9.
 \item (page 5). ``The second game'' As described in \ref{sec:broad-EPR}, I suggest that you describe the \Leash protocol as doing the \Broad scheme, instead of the \EPR scheme.
\item (page 5) ``We remark that in both sub-games, the questions received by PV are of the form $W \in \Sigma$, where
$\Sigma = \{X,Y, Z, F, G\}$ is the set of measurements performed by the verifier in Broadbent's EPR protocol.'' I believe that this is false, and has been an extremely confusing point in this submission, that is inadequately explained. I believe that the RIGID game ends up asking PV to do Bell basis measurements as part of the rigidity tests.
\item (page 5) ``Hence, we can use our rigidity result of Theorem 1
to guarantee honest behavior of PV in the delegation sub-game'' Immediately after this passage, please explain PP's role.
\item (page 5) ``requires (2d +1) rounds''. I would remove the brackets. Currently, it looks like you forgot a ``big - O''. (Oh, maybe you did for a ``big-Oh''!).
\item (page 5) ``(see Section 2.3 for a precise definition of how this is computed).'' I skimmed Section 2.3, I could not find this description. I think this should be a reference to some location in the text that describes the \Leash protocol.
    \item (page 5) ``The protocol requires O(n+ g) EPR pairs
to delegate a g-gate circuit on n qubits,'' Please mention something about rigidity here; this should be a high-level description of the protocol, at the level that includes the rigidity tests. If you don't want to do it here, you could refer to either Section 3, or Section 4.1.
\item (page 5) ``The
input to the circuit is hidden from the provers, meaning that the protocol can be made blind by encoding the
circuit in the input, and delegating a universal circuit.'' Add here that blindness only holds as long as PP and PV stay separated, and remove the passage ``particular,
while PV and PP would have to collude after the protocol is terminated to learn the input in the leash
protocol,'' which is in the description of \DW.
\item (page 5) ``The completeness of the protocol follows directly from the completeness of [Bro18].'' I think you also need completeness of RIGID.
\item (page 5) ``since the combined
behavior of our verifier and an honest PV is nearly identical to that of Broadbent’s verifier.'' Do you mean an honest PV in the delegation game (as opposed to RIGID game)? Also, replace with ``verifier in \Broad''.
\item (page 5) ``The second protocol''. Similar as for the ``first'' protocol, start a new subsection here and immediately call this  \DW.
\item (page 5) ``Based on the Dog-Walker Protocol, it is possible to design a classical-verifier two-prover protocol for
all languages in QMA''. Start a new subsection for this. Also, please explain why this does not work for \Leash, or why you chose just \DW.
\item (page 6) ``The verifier then delegates the verification circuit to the second prover, as in the Dog-Walker Protocol; the first prover can be re-used to verify the operations of the second one.'' Grammatically unclear (I think the punctuation throws me off): does the ``as in'' qualify the ``verifier then delegates the verification circuit'', or does it qualify the ``the first prover can be re-used to verify...''? Maybe using a full stop instead of the semi-coma, and then saying ``The first prover can then be re-used (...)''. I think this would clarify (if indeed it is what you mean).
\item (page 6) ``have independently re-derived'' Remove `re'. I does not add anything, and makes it look like you are claiming precedence.
\item (page 6) ``two-prover delegation of quantum computation by classical
clients with'' I think this is more appropriately singular: ``by a classical client''. If not, please explain.
\item (page 6) In reference to [Gril17], please explain what parts subsume the current work under review, and which parts do not (e.g. is there blindness?, are the other complexity parameters the same?). Also, I would insert: ``two-prover delegation of quantum computation by classical
clients with a single round of communication. \textbf{Because of this single-round structure,} space-like separation can replace the
non-communication assumption.''
\item (page 6) Would it be appropriate to comment on subsequent work [GV19]? It would seem to be related to \Leash.
    \item (page 6) Define the acronym ``i.i.d''
    \item (page 6)``and could not use'' not clear who is the subject of this part: the ``authors'' or the ``devices''. Maybe break into two sentences.
\item (page 6) ``does not require any additional assumption.'' $\rightarrow$ ``does not require any additional assumptions.''
\item (page 6) ``Therefore, the requirement that the provers do not
communicate throughout the protocol cannot be enforced through space-like separation, and must be taken
as an a priori assumption. Since the protocol of [Gri17] is not blind,'' Explain better why [Gril17] suddenly appears here (link to space-like separation?)
\item (page 6) ``albeit not necessarily in a truly efficient manner.''. This seems vague. Can you be more specific (since the point of the submission is about efficiency, can you compare more cleanly?).
\item (page 5-6) The material of Section 6 should be included in the high-level summary somewhere.
\item (page 6) Maybe mention in ``Organization'' that Section 5.4 contains the QMA protocol?
\end{enumerate}


\subsection*{Section 2}
\subsubsection*{Reviewer 3}
\begin{enumerate}
\item (page 7) Under ``Observables'': specify what is $u$ in $\sigma_W^u = E_a(-1)^{u\cdot a} \sigma_W(a)$.

{\color{blue}Done.}

    \item (page 7) ``implicitly tensored with identity'' $\rightarrow$ ``implicitly tensored with \textbf{the} identity''
		
		{\color{blue}Done.}

\item (page 7) The set notation is strange (and this happens throughout--- there will be more comments about this). I think you need to replace the comma before $a,b,c \in \{0,1\}$ with either ``$\mid$'' or ``$:$'', depending on the convention that you want to use.  Otherwise, it looks to me like $a$, $b$ and $c\in \{0,1\}$ are all elements added to the set $\mathcal{H}^{(1)}$ (where $a$ and $b$ really have no information associated to them).

{\color{blue}Done, thanks.}

\item (page 8) ``are characterized by''. Is this a technical term? Do you mean ``satisfy'', or is there something deeper? please explain.

{\color{blue}Nothing deep; we meant that the equation can be used to define one observable from the other. Edited.}

    \item (page 8) ``involves the interaction between a verifier $V_{EPR}$ and a prover $P$.'' Please check, there is inconsistency on how the possibly cheating verifier is denoted. In Theorem~3, it is called $P_{EPR}^*$.  (I don't think that the plain $P$ is ever used, so maybe you could just call any prover $P^*_{EPR}$ and the honest one $P_{EPR}$).
		
		{\color{red} TODO}

        \item (page 8) ``Since the choice of round type is made after interaction with '' $\rightarrow$ after \textbf{the} interaction with
				
				{\color{blue}Done}
				
 \item (page 10) Table 2: I would place the row in order according to the presentation on this page: CNOT, H, T.

		{\color{red} TODO}

     \item (page 10) ``depends on a random bit $z_i$'' $\rightarrow$   depends on a \textbf{uniformly} random bit $z_i$
		
						{\color{blue}Done}

   \item (page 12) ``depending on the round type.'' add ``depending on the round type \textbf{$r$}.''
	
							{\color{blue}Done}

   \item (page 12) In step 2 of Fig 3(a), there is a call to the $V_{EPR}^r$ procedure. which takes as input $\overrightarrow{x}, \overrightarrow{c}, \overrightarrow{z}$ as well as two qubit systems (in that order). I would make the syntax uniform so that also the call in step 2 of Fig 3(a) mentions these values in the same order. [It seems like a details, but these inconsistencies add up, when the reader is trying to understand!]
	
			{\color{red} TODO}

       \item (page 13) ``Completeness and Soundness.'' uses the expression $\|\Pi_0Q|0^n\rangle\|^2$, whereas the Theorem 2 uses $\|\Pi_0Q|\overrightarrow{x}\rangle\|^2$. Please check which one you mean (I think you mean the latter).
			
						{\color{red} TODO}

       \item (page 13) The benign attacks are defined as $B_{t,m}$ , but then used as $B_{t,n}$.
			
						{\color{red} TODO}

   \end{enumerate}



\subsection*{Section 3}
\subsubsection*{Reviewer 1}
\begin{enumerate}
\item Many proofs only contain a sketch and are hard to digest. It is recommended that at least for the main lemmas, such as Lemma 10 and Theorem 11, the authors can provide more self-contained proof. Many steps in the proof sketch are very high level and it is not easy and usually time-consuming if the reader wants to verify the details.
\item The meaning of the second equation on page 23 is not clear. Are a and b fixed or are they summed over in the end in the approximation?

				{\color{blue}The approximation holds on average over uniformly random $a,b$. We added a clarification of this point.}
				
\item In item (c) of Figure 6, what is being "chosen uniformly at random"? W is already chosen so the places where $W_i = F$ or $G$ are already determined.

{\color{blue} $S$ and $T$ are uniformly random \emph{subsets} of those positions.}

\item The last equation in Theorem 4 is hard to parse and does not use the $\sim_\eps$ $\approx_\eps$ distances. Could you please explain both the meaning of this equation briefly and the reason to state the result in this form? Similarly in Corollary 13.

{\color{blue} We added some explanations right below the statement of Theorem 4.}

\item "rounds" are usually used as the sequentially exchanged messages in interactive protocols. This paper uses round and sub-round also for the potential format of messages in a particular round. Broadbent's paper on EPR protocol uses "run" instead of "round" and seems to be a better now for this context.
\item Page 17, item 2 of Relations, do you need $\omega_a$ to be different?
\item In the comment before Definition 7 on page 17, it is argued that the exact form of distribution does not matter. But what if the size of the relation R has n (say the number of qubits) dependence?
\item The last equation in Definition 7 has a mistake. When $W_A$ acts on $\ket{\psi}$ as in the first equation, you cannot apply $V^\dagger_A W_A V_A$ on it in general
\item The abbreviation after equation 4, $W^a_A \otimes I \approx I \otimes W^a_B$ does not fit syntactically with Definition 5, where the operators are always on A system only.
\item What is the "state-dependent norm" referred to in Definition 6?
\item Why do you use $Z_4$ in the range of $h_S$ before equation 6 even though it appears in the equation as $(-1)^{h_S}$
\end{enumerate}

\subsubsection*{Reviewer 2}

Sections up to and include 3.2 are fine. However starting at 3.3 things start getting quite confusing. I'll actually start with the Appendix, which covers the analysis of the Pauli Braiding Test augmented to test for the Pauli Y observables.

Comments about PBT analysis in Appendix:

\begin{itemize}
\item Page 64, description of Extended PBT: In test (c), the basis string W that is chosen is uniformly random in ${I, Y}^m$. However this seems problematic because this distribution of questions does not match the distribution of questions in parts (a) or (b): there the basis strings are uniform over ${X,Z}^m$, or ${X,Y}^m$, or ${Y,Z}^m$. Thus test (c) cannot be immediately connected to (a) or (b).

{\color{blue} Thanks for catching this; indeed we were missing a test that connects part (c) to parts (a) and (b). This has now been added; it is the new parts (c) and (d) (with the old part (c) now being part (e)). }

\item Furthermore, the tests in (b) cannot be immediately connected to the tests in (a) because the basis strings to each player contain Y w.h.p.

{\color{blue} Corrected as above}

\item Page 65: statement of Lemma 36. Right below (33), there are both maps $\Lambda_W$ and $\Delta_X/Y/Z$ used. It seems like only Lambda or Delta should be used (the proof only refers to Delta).

{\color{blue} Corrected}


\item The proof of Lemma 36 is difficult to follow. First, as mentioned before the tests (a), (b) and (c) are distinguishable from each other so it shouldn't be possible to connect the rigidity guarantees between each of those tests.

\item Furthermore,  it hand-waves over the analysis of part (c) of the test. The proof just states: success in part (c) implies [equation (34)]. This is far from obvious: part (c) consists of 3 subtests. Furthermore, parts (ii) and (iii) involve the parallel repetition of the Bell measurement subtest. Only a single instance of the Bell measurement subtest is analyzed, and it is far from clear that the error from m-parallel repetitions does not grow with m.  If it does not grow with m (as implicitly claimed in the proof), this requires a more thorough argument.
\end{itemize}


Back to Section 3.3: It appears that much of the technical work in testing the Clifford observables comes from dealing with the phase ambiguity of the Y observables. However, the treatment of how this is dealt with is itself very ambiguous!
\begin{itemize}
\item For example, the Lemma 9 establishes the existence of $Delta_Y$ observable that compensates for phase ambiguity. Lemma 10 then introduces another unitary map $\Lambda_R$, but there is no explanation of what this map is meant for. Is this meant to deal with another phase ambiguity? Why is this map needed?
\item The map $\Lambda_R$ is a unitary acting on $H_{\hat{A}}$, but is tensored twice when acting on $\ket{Aux}$. Does it also act on $H_{\hat{B}}$ as well? 
\item A related issue: the definition of $\hat{\tau}_R$ is very confusing: when referring to “relations specified in (9)”, there is no $\sigma_X$ or $\sigma_Z$; there are only abstract X and Z symbols. Did you mean those? Also, what does it mean to replace those with the specific operators $\tau_Y = \sigma_Y \otimes (i \Delta_Y)$? 
\item The "proof sketch" for Lemma 10 is quite hard to follow. Part of the difficulty comes from the setup prior:
\item 
Page 20: Line 7: it says the phase $i^{a \cdot b}$ is needed to ensure that A and B are observables. Do we also need to assume that X and Z observables anticommute? Also, shouldn’t the imaginary unit i be (-1)? For example, suppose that X = Z = Id, and $a \cdot b = 1$. Then A(a,b) = i, which is not a (binary) observable; we’re assuming that all observables are binary, right?
\item 
In fact, the whole of Section 3.3 does not seem self-consistent. Line (6) indicates that R is a unitary that conjugates Pauli operators $\sigma_X \sigma Z$. However, the A, B observables are defined in terms of the abstract X, Z observables. But then the paragraph after (7) seems to say that the unitary R conjugates A and B. 
\item 
It makes sense that ultimately X and Z, after self-testing, should correspond to actual Pauli-X and Pauli-Z operators. But it’s ambiguous what has been tested already, and what is an abstract relation you need to check. 
\item 
In (7), the observables A and B have phase factors defined. However, in the test CONJ-CLIFF, the observables A and B are specified in terms of strings of I, X, Y, Z. Where do the phase factors come into the test? Or do they only show up in the analysis? Clarification regarding this would be helpful.
\end{itemize}

Assorted other typos/comments:

---


page 10: H-gadget: “maximal such k is odd". Confused about what “maximal such k” means. Should it just be “$H(TTH)^k$ where k is odd”?

Figure 2: what is the $c_f$? Is this the f-th bit of $\vec{c}$? (seems redundant)

Does $\Sigma$ generate the set of single-qubit Clifford unitaries?

Page 17: definition of Rigid self-test. For completeness, perhaps should clarify further and say that the operators corresponding to each question in $\mathcal{Q}$ satisfy exactly the same relations as specified by $\mathcal{R}$

Page 19: Proof of Lemma 8. “anti-commutation of $X_R$ with Z certifies that $X_R$ has decomposition of the form $X_R \simeq R_X \otimes \sigma_X + R_Y \otimes \sigma_Y$”. First, what is the error in this approximation, and it would be helpful to see a proof. Similarly, for subsequent statements it looks a bit hand-wavy. It would be better if the approximations had error bounds and some of the steps were spelled out. 

Page 19: Proof of Lemma 8: $C \simeq C_I \otimes I + C_Z \otimes \sigma_Z$. The identity operator I should be $\sigma_I$. 

Top of page 20: could use more explanation for why “decompositions of A, B, C earlier imply $C_I \approx… and C_Z \approx$…”. Overall this proof is a little too sketchy.

Page 64: "...multi-qubit Pauli X and Z observales" (should be "observables")

\subsubsection*{Reviewer 3}

\begin{enumerate}
\item (page 13) ``Each of our delegation protocols includes a rigidity test''. This is confusing. Do you refer here to the official RIGID test, or to the concept of rigidity, in which case there are multiple rigidity tests in each of $\Leash$ and $\DW$. But this paragraph seems to be explaining only the concept of \Leash (again, using instead the concept of the \Broad protocol, this becomes much simpler since you are explaining here how to generate the random eigenstates of the \Broad protocol.) Maybe it would be better to instead say nothing here and to refer the reader to the introduction paragraph which explains the role of the rigidity test (or tests?) in the two main delegation protocols.
\item (page 13). ``In this section we outline the structure of the test'' I am not sure what is ``the test''. Is this RIGID? (telling the reader now will help make a good mental map of what to expect coming up) At this point in reading of the paper, there is not enough information to understand this paragraph. Here are some issues:
    \begin{enumerate}
    \item ``With constant probability
the verifier sends one of the provers a string W chosen uniformly at random from $\Sigma^m$''. This passage does not say what the other prover gets.
\item ``The test consists in a single round''. Really? from what we have so far, the delegation contains multiple rounds, and then we are supposed to intermingle with this rigidity test, which is a single round, and it should remain indistinguishable between a delegation and a test? This is confusing. I think that the resolution later on is that we repeat the rigidity test to mimick the interaction in the delegation protocol. Please explain this here.
\item ``With the remaining
probability, other queries, requiring the measurement of observables not in $\Sigma^m$ (such as the measurement of
pairs of qubits in the Bell basis), are sent.'' Sent to whom?
\item (same passage as above). This is the first place that the ``other queries'' not in $\Sigma^m$ are invoked. It would be good to explain why and how this process works. So far, the reader has the impression that the RIGID test is going to be indistinguishable from the Delegation, but this new concept violates that intuition.
    \end{enumerate}
    \item (page 14) ``Our rigidity result states that any strategy that succeeds with probability $1-\varepsilon$ in the test is within $poly(\varepsilon)$ of
the honest strategy, up to local isometries''. Please explain here or closeby how the ``honest strategy'' relates to the questions that are not in $\Sigma^m$. It looks to me (see Theorem 4) that you actually say nothing about those rounds where the questions not in  $\Sigma^m$.
\item (page 14) The concept of the ``consistency test'' (p.16) (which symmetrizes the game and the player's behavior), should be informally introduced here, at the latest before the summary of Theorem 4. Otherwise, it is confusing that the statement of Theorem~4 is only about $W_B$, yet the informal description claims that it deals with ``either player''.
    \item (page 14) ``the ancilla register to extract a single bit'' Please include the symbol here for the ancilla register.
        \item (page 14) ``For an observable $W$, let $\sigma_W = \sigma_W^{+1}-\sigma_W^{-1}$ be its eigendecomposition, where sW are the “honest”
Pauli matrices defined in (1) and (2).'' Please check consistency of notation: the eigendecomposition was given in the preliminaries (page 7) as $\sigma_W^{0}-\sigma_W^{1}$. Also, technically, $\sigma_W$ is not always Pauli matrices, as in Equation (2).

{\color{blue} Fixed}

\item Statement of Theorem 4:
\begin{enumerate}
\item A strategy has not been formally defined yet (that happens on page 16). So you should tell us informally what is a strategy (so that the symbols are defined), or refer to the definition of page 16 (however, there is no definition environment, so that would need to change it you want to refer to it).

{\color{blue} Actually, there is a definition of strategy at the top of the page (``In general, an arbitrary strategy ...''). }

 \item What is the quantifier/restriction on $|AUX\rangle?$

{\color{blue} Existential; added}

 \item   The display equation below Equation (3) is hard to parse (especially the part involving $\tau_\lambda$, can you add more description on how to read it? )

{\color{blue} We added a paragraph immediately below the statement of the theorem to explain and motivate that equation.}

\end{enumerate}
\item ``The proof of the theorem is based on standard techniques''. I think you are underselling the contribution. Now is your chance to outline the rest of this section and the contributions (or, refer to them in the introduction). Please use the same structure as the structure of the protocols as given in the Figures (this is why the "Tree" Figure would be useful). I.e., tell us that the main protocol is RIGID, which itself is composed of CLIFFORD + ad-hoc tomography, and then CLIFF is composed of CONJ, and a bunch of other tests, etc. (See comment in \ref{sec:-prot-pres}). This will help give a roadmap to reading this section.

{\color{red} TODO}

\item ``In the remainder of this section, we prove Theorem 4''. Please say exactly where this is proven. For instance, is Theorem 4 re-stated elsewhere and proven there? I could not find a ``Proof of Theorem 4'' claim anywhere. (But is looks very similar to Corollary 12).

{\color{blue} Thanks, there was a bit of a mess-up there. We removed the statement of Corollary 12 and clearly labeled its proof a proof of Theorem 4.}

    \item (page 16) the title ``Tests.'' would be more accurately described as ``consistency test''. Also, to give more structure to the paper, I would use numbered headings instead of bold font (only) headings.
		
{\color{blue} We did this.}
		
        \item (page 16)``all the games, or tests, we
consider implicitly include a “consistency test”''. It is really difficult to know what qualifies a procedure to be called a ``game'' or ``test'', and therefore which procedures get a the implicit consistency test. For instance, looking at Figure 4, is CONJ itself going to get a consistency test? And then, when about each of AC, COM, (8 possibilities)? What about the part (b) (ad-hoc test, with no name), it is also subject to another consistency test? Maybe the answer will not change the main result, but it would be good to clarify here, once and for all (the consistency test never really comes up again in the paper).

{\color{blue} We added a clarification.}

 \item (page 16) The notation at the end of the ``Tests'' paragraph is a bit repetitive from page 7 and also page 14. Please check. If need be, it can be recalled, but currently, there is no indication that this is a reminder.

{\color{blue} Done.}

 \item (page 16) ``Since the players are always treated symmetrically'' please specify why this is the case.

{\color{blue} Done.}

 \item Equation (4). What is the quantifier on $|\psi\rangle$?

{\color{blue} Clarified.}

 \item Equation below ``Relations.''. Again, I don't understand this syntax for the set notation. I think it should be $\{... \mid X, Z, H \in Obs\}$. Also, please use an example from an actual game.
 \item ``We only consider relations that can be brought in the form''. The wording ``brought'' sounds strange, something like ``expressed as'' or ``written as'' would be more standard.
     \item ``We only consider relations that can be brought in the form''. Are these two different definitions for the same symbol, $f(W)$? This seems confusing.
\item  ``Definition 6 (Rigid self-test).''
\begin{enumerate}
\item ``that is either an observable or a POVM'' Grammatically, it is impossible to know if ``that'' refers to ``symbol'', ``questions set $Q$'', ``variable'', ``game'' or even ``set of relations''. Please specify.
\item ``additional questions''.   I think these are the questions in $Q$ but not in $R$, but it is unclear. I already commented on making more clear these additional questions. The explanations added there should also help understand this passage here.
    \item Definition 7. Define where $|\psi\rangle$ comes into the definition. Is a stable relation wrt $|\psi\rangle$, or is it for all $|\psi\rangle$?
\end{enumerate}
  \item Definition 7. If possible, make the equation on the bottom of page 17 as close as possible as the Soundness condition in Definition 6 (place the $f(W)$ at the same location).
      \item ``The test
CONJ(A, B, R), given in Figure 4,'' I would delete this first reference to Figure 4, and keep only the second one, later on page 18.
  \item display equation for $C\{R,C\}$: similar problem with the set notation. I do not understand the first set in this notation $\{X_r, C, X, Z \in Obs\}$. I think this expresses conditions of $X_r, C, X, Z$, but they should not actually be elements of the set. Use the same notation as in the display equation below ``Relations'' on page 17 (after that one is fixed)?
   \item Figure 4. I get a syntax mismatch for the COM tests. On p. 58, $COM(A,B)$ is defined for $A,B$ observables on the same space. This is not the case for e.g. $COM(C,Z)$
     \item part (b) of test needs some work. First of all, it is phrased negatively (reject if...) this seems unatural. Secondly, please consider if this part (b) deserves its own name and game. Presumably, the beauty of this part (b) comes out in the proof, but the presentation is really difficult to follow.
   \item (page 20) For the Pauli relations defined in the display equation $P^m\{X,Y,Z\}$: same thing with the set notation, it makes no sense.Currently, the string $a$ is in the set: I doubt that you mean this. Each of the sets here needs to be fixed in terms of the notation of using correctly $\mid$ or $:$ to specify the nature of the observables in the set.
    \item (page 20). ``The Pauli braiding test is recalled in Appendix A.4, ''. This paragraph awkwardly refers to [NV17], as testing only some observables, and then the extension and then once more back to [NV17]. Please re-phrase so that the flow is more direct (I would first mention [NV17], say it is in Appendix A.4.1 (also mention any changes compared to the original test), and then mention the extension in Appendix A.4. Also add in the paragraph a sentence that introduces Lemma 9.
     \item (page 21). Same issues as before with the strange set notation for $J_{h_S, h_X, h_Z}$
\item (page 22) ``Let $\hat{\tau_R}$ be as defined in the paragraph preceding the lemma.'' Where is this? I think maybe this should be "in Lemma 10"?
\item (page 23) ``Finally, the relation (10) follows from self-consistency''. This is the first time ``self-consistency'' is used. It is probably the same thing as the implicit consistency test. Please add a reference to the section where the implicit consistency test is described.
 \item (page 25) ``Proof sketch.'' Please mention what would be required to make this a full proof (or promote it if this is the case).
 \item (page 26) ``We give a first corollary of Theorem 11 which expresses its conclusion (16) in terms of the post-measurement
state of the first player.''. It is unclear if ``its'' refers to the conclusion of Theorem 11, or of the upcoming Corollary 12.
\item (page 26) ``we incorporate a
small tomography test in the test, described in Figure 7.'' A test within a test --- technically, this is probably correct, but I would avoid this phrasing, it is hard to read. Next, the ``described in Figure 7'' actually refers to the result of adding the tomography to CLIFF. So I would use an explanation along those lines. Note that RIGID is the main protocol (as far as I can tell). This lead-in text does not do it justice. I would add something like ``This is our main test, which incompasses all other tests''.
\item (page 27) I think that Corollary 12 is the same as Theorem 4. Mention it here, and emphasize that this is the main result of this Section.
\item (page 27)``Moreover, players employing the honest strategy succeed with probability (...) in the test.'' Replace ``test'' with $RIGID(\Sigma,m)$.
\item (page 27) ``From Theorem 11 we get isometries '' I would add: ``From Theorem 11 and part (a) we get isometries''
\item (page 28) Section ``3.6 Tomography''. We already had a tomography test in Figure 7 (b). Please explain the difference....
\item (page 29) ``This allows us
to check that a player performs the measurement that he claims, even if the player has the choice of which
measurement to report.'' This is a very curious feature. It would be great to explain here (or elsewhere, and refer to it here, why this is important)
\item (page 29) ``Moreover, players employing the honest strategy succeed with probability 1 in tomography part of the
test.'' Both RIGID and TOM include a ``tomography'', so please be specific. Maybe here you can use $TOM(\sigma,m',m)$?
\item (page 30) ``We call the resulting protocol the Leash Protocol with parameters (pr, pd)''. Why not make this into a figure? This will help make statements more formal. Eg. The statement of Theorem 14 refers to the ``Verifier-on-a-Leash'' protocol, which is not defined; I think you mean ``Leash'' protocol as in this passage.
    \item (page 31)``Further, the protocol leaks no information about x to either prover individually, aside from an upper bound
on the length of x.'' This statement is too informal to be in a Theorem statement. In fact, it is not defined in the submission what it means to ``leak no information''. Section 4 formalizes ``blindness'' in terms of the reduced state of the provers. So it would be necessary to make Theorem 14 sufficiently formal to incorporate this notion.

\end{enumerate}


\subsection*{Sections 4, 5 and 6}
\subsubsection*{Reviewer 1}
\begin{enumerate}
\item On page 45, in the list of soundness analysis steps, what do you mean by "constant total variation distance"? It is always at most 1 by definition.
\item As in Table 4, the $W_i$'s are chosen at random and it seems that $T^0_\ell$ and $T^1_\ell$ will have roughly same/different length depending on whether it is a computation round or test round. Does this leak information about the round type to PP?

\end{enumerate}

\subsubsection*{Reviewer 2}

These sections of the paper are written quite clearly and appear correct (assuming the correctness of the self-testing components), but there are a few items that are unclear to me:

Page 31, middle: "uniformly random partition $A, B_1,..., B_d$", where "$|B_\ell| = \Theta(t_\ell)$". In each layer, there is at most one T gate. So is $|B_\ell| = 0$ when $t_\ell = 0$, and a constant otherwise?

Page 34, Step 4(b): the reject criterion is $c_i \neq a_j + e_i$, which differs from the reject criterion in the EPR protocol on page 12, Figure (a), Step 3, which is $c_i \neq a_i' + e_i$. Why are these different?

My best guess is that it has something to do with measuring the observable $W_i$ before the generation of bit $c_i$ in the delegation protocol, whereas in the EPR protocol it's measured after the bit $c_i$ is generated. But it's hard to verify this, because the "completeness proof" just appeals to the completeness of the EPR protocol.

I recommend explaining what the differences are between the EPR protocol and the Verifier on a Leash protocol, and why those differences are OK. In particular, why completeness still holds.

Page 36, Proof of Lemma 16: choosing $W_i$ at random, then choosing $z_i$, versus choosing $z_i$ at random, then computing $W_i$ are equivalent. It seems like this requires $a_j$ to be uniformly random in order for this to hold -- is that right?

Page 37, Proof of Lemma 16: "There are two reasons that $V_{EPR}$ might reject: $... c_i = a_j + e_i$ fails". Again, this seems to differ from the protocol described on Page 12, Figure (a). Which is the real EPR protocol?

Major question about Leash versus Dog Walker protocol: the Dog Walker protocol is motivated by reducing the number of rounds to constant, at the cost of giving up blindness. However, as far as I can tell, the Leash protocol only uses the sequentiality to obtain blindness. Why can't the Leash protocol be flattened to a constant number of rounds in, and still preserve completeness and soundness? The completeness proof does not depend on the sequentiality, nor does the soundness proof (or is that incorrect?).

Page 42: description of protocol, the reject criteria for the X/Z test rounds is $c_i \neq a_i' + e_i$ now, which matches the description of the EPR protocol (but differs from Leash protocol).

Page 50: the figure caption obscures the page number.


\subsubsection*{Reviewer 3}
\begin{enumerate}
\item Section ``4.1 Protocol and statement of results''. I would invest more into a better presentation in the introduction, and link to it here, and only present the essential notation at this point in the paper, and also to details that were not possible to explain in the introduction (due to their technical level).
 \item As mentioned in \ref{sec:broad-EPR}, I am suggesting that the picture here should be that the \Broad protocol (and not EPR) is the underlying idea for the delegation, and that rigidity is testing PV from \Broad. This permeates the description of the protocol, and will have e.g. an effect on the presentation on page 32.
     \item (page 36). Figure 14. As far as I can tell, $RIGID(\Sigma, m)$ has questions that are outside of $\Sigma$ (e.g. for the Bell test which is part of RIGID), hence I think it is incorrect to write ``The verifier selects questions $W, W' \in \Sigma^m$'' and to think that this covers all of the questions in RIGID. In fact, I am wondering how you manage to use the RIGID game (which has extra questions, compared to the delegation game) within the delegation game. Please explain.
         \item (page 36). ``exactly as in Step 1 of the Delegation Game'': please give Figure number for this game.
\item (page 39) ``4.4 Blindness''. I think it would be important to recognize that here, the definition of blindness does not say anything about the provers possibly \emph{increasing} their knowledge about $x$, via the protocol. It only says that if they start with no knowledge on $x$, they end with no knoweldge. Thus, the possibility of a simulation-based definition and proof is still an open question. Such simulation-based definition would be much more interesting, since usually the provers would likely start with some a-priori knowledge of what types of circuits they may be asked to run.
\item (page 39)
      I could be mistaken, but the general idea for the proof is essentially the same reason why the \EPR protocol came to be in the first place: we want to argue that PP can go first, and interact on fresh randomness (only). An explanation along these lines would be helpful.

\item (page 41)``For this reason, we must
augment the test discussed in Section 3 '' Please say which one. There are many, many tests in Section 3.
\item (page 41) ``For this reason, we introduce the Tomography test and prove'' You already introduced this test at the end of Section 3, hence you can refer to it here.
\item (page 41) ``Figure 17 (PV’s point of view)
and Figure 16 (PP’s point of view).'' Change the order so that the figures are presented in increasing order.
\item (page 49) ``We state the result and sketch its proof.'' Add the name of the Lemma (I think, Lemma 27).
\item Currently, Section 6 is not at all summarized in the intro. This should be corrected, by adding at least a few sentences about the results in this section, perhaps close to where Figure 1 is explained. Actually, this is borderline Appendix material; you could also move it to the Appendix (and refer to this Appendix in the intro).
\end{enumerate}


\subsection*{Appendix}
\subsubsection*{Reviewer 3}
\begin{enumerate}
\item The set notation for the relations in Lemma 32 is again throwing me off. Same thing for the set in A.4.1 and A.4.2

{\color{blue} We clarified the notation} 

\item The title of Section A.4.2 is the same as the title of A.4

{\color{blue} Yes. We didn't find a better title} 

\end{enumerate}



\section*{Other typos and display issues}
\subsubsection*{Reviewer 3  }
Many were already noted in the specific sections above. Here are some more.
\begin{enumerate}
\item (page 4)``Our first contribution is to extend the “Pauli braiding test” of [NV17], which allows one to test tensor
products of sX and sZ observables with constant robustness, to allow for sY observables as well.'' Use brackets here, it will be easier to read:
``Our first contribution is to extend the “Pauli braiding test” of [NV17] (which allows one to test tensor
products of sX and sZ observables with constant robustness), to allow for sY observables as well.''
\item (page 14). Double period around Footnote 6.
\item (page 15) ``decribe''
\item (page 16) ``as a result we will also often omit an
explicit specification of which player’s space an observable is applied to.'' check the grammar of this passage. I would remove the final ``to''.
   \item (page 24) ``Note that
a priori test CONJ'' $\rightarrow$ ``   \item (page 24) ``Note that,
a priori, test CONJ''''
\item (page 29) ``will be useful for our analysis of the Dog-Walker Protocol from Section 5.'' $\rightarrow$ ``will be useful for our analysis of the Dog-Walker Protocol in Section 5.''
\item (page 27) The ``hat'' command does not center nicely on the ``A'' (just below equation 18), probably due to the font that you are using.
\item ``for our analysis of the Dog-Walker Protocol from Section 5.'' $\rightarrow$ ``for our analysis of the Dog-Walker Protocol in Section 5.''
\item (page 30) I would limit parenthetical comments to one sentence. Also, check the double period at the end of the parenthesis ``(See Section 2.3 for a summary of the protocol and a description of VEPR. Throughout this section we
assume that the circuit Q provided as input is compiled in the format described in Section 2.3.).''
\item (page 30)``and t number
of T gates in Q.'' $\rightarrow$ ``and t be the number
of T gates in Q.'
\item (page 35). Add ``in the Delegation Game'' in both captions for Figure 13 and Figure 12.
\item (page 35). Place Figure 12 before Figure 13.
\item (page 38). ``If $\lambda = +$''. I would put a comma after this: ``If $\lambda = +,$''. Same thing for ``If $\lambda = -$''
\item (page 36). ``by Theorem 2 and since in
our protocol the verifier'' I would delete ``in our protocol'' since this is clear from context. Or if you want to keep it, add a comma before and after: ``by Theorem 2 and since, in
our protocol, the verifier''
\item (page 41) ``We notice''$\rightarrow$ ``We note''
\item (page 44) ``and PP play'' $\rightarrow$ ``and PP plays''
\item (page 55) Check Bibtex acronym for [BvCA18]; also use a capital ``P'' in ``pauli''
\item (references) Check for updated (published) references.
\item (page 57) ``a robust self-test test''$\rightarrow$ ``a robust self-test''
\item (page 57) ``Answers from the prover'' $\rightarrow$ ``provers''
\item (page 57) ``except the last'' $\rightarrow$ ``except the last column''
\item (page 59) is it PVM or POVM?
\item (footnote 9) ``either $\delta_i$'' I think that there are 3 possibilities, so use ``any'' instead of ``either''
\item (page 59) Remind us of the meaning of notation $\{A,X\} \approx 0$
\item (page 60) ``Accept if and only c'' $\rightarrow$ ``Accept if and only if c''
\item (page 66) ``the the''
\end{enumerate}




\clearpage

\section{Full reviews}	
	\appendix
\subsection*{Reviewer 1}
Summary

The authors construct efficient (almost linear in the number of gates) classical delegation protocols using two entangled provers. Two protocols, the least protocol and the dog-walk protocol are proposed and analyzed. Both protocols are based on the EPR protocol of Broadbent which is a delegation protocol with a verifier sharing EPR pairs with the prover V and perform simple measurements (Pauli and Clifford measurement).

The key idea of the paper is to delegate the quantum computing part of V in the EPR protocol to a prover PV. For this purpose, an efficient rigidity theorem supporting Pauli and Clifford measurements is needed. The authors build upon both the Natarajan-Vidick Pauli braiding protocol and the conjugation test first proposed by Solfstra, and designed a robust self-testing protocol that self-tests the set of Clifford observables $\{X,Y,Z,F,G\}^m$ where F and G are defined as $F = (-\sigma_X+\sigma_Y)/sqrt{2} and G = (\sigma_X + \sigma_Y)/\AND{2}$. It is one of the main technical results of this paper and may have applications in other situations.

The leash protocol then roughly corresponds to the delegated EPR protocol, simulating the circuit gate by gate, or more efficiently, layer by layer as this paper did. The quantum measurements (X, Y, Z, F, G) are delegated to the prover PV who are supposed to measure EPRs shared with PP and report back the measurement outcome. A sequential version of the rigidity test and the EPR protocol are "merged" seamlessly in the protocol. The protocol is proven to be blind by an argument that defines an equivalent alternative protocol that interacts with PP first.

The dog-walk protocol is a modification that saves the rounds complexity but loses the blindness property. In that protocol, the verifier interacts with PP in one round and then with PV in one round. The design of the dog-walk protocol is more complicated. The main idea is to design several cross-checks as in Figure 18 that enforce honest behaviour.

Strength and weakness


Overall, I feel that the techniques and the results in this paper are valuable and even though the proof techniques are usually not innovative enough and somewhat expected, the proof of rigidity and the constructions of the protocols are not trivial. Furthermore, near-linear efficiency achieved in the paper is impressive. 
A major concern before my support of acceptance in the current form is the presentation. There is plenty of room for improvement in terms of writing. I find the paper very hard to follow, and many steps of the proof are very sketchy. First, in the introduction part where the intuitions are discussed, possible improvements include a discussion on the idea behind the dog-walk protocol, how it achieves the constant round property from the multiple round EPR protocol, the reason for introducing the TOM test and the idea behind the design, and so on. Then, for the proof of the main lemmas and theorems, more details should be spelled out so that it is possible to verify by readers. As an optional improvement, I suggest the authors to consider if there are simpler and more elegant ways of proving the rigidity for Clifford observables. The choice of {X, Y, Z, F, G}, though natural arises from the EPR protocol, could have made the protocol and the analysis cumbersome. Probably considering all of the Clifford group could make the analysis more streamlined.

I, therefore, suggest that the authors perform a major revision to improve the readability of the paper.


Detailed questions and suggestions

\begin{enumerate}
\item Many proofs only contain a sketch and are hard to digest. It is recommended that at least for the main lemmas, such as Lemma 10 and Theorem 11, the authors can provide more self-contained proof. Many steps in the proof sketch are very high level and it is not easy and usually time-consuming if the reader wants to verify the details.
\item The meaning of the second equation on page 23 is not clear. Are a and b fixed or are they summed over in the end in the approximation?
\item In item (c) of Figure 6, what is being "chosen uniformly at random"? W is already chosen so the places where $W_i = F$ or $G$ are already determined.
\item The last equation in Theorem 4 is hard to parse and does not use the $\sim_\eps$ $\approx_\eps$ distances. Could you please explain both the meaning of this equation briefly and the reason to state the result in this form? Similarly in Corollary 13.
\item "rounds" are usually used as the sequentially exchanged messages in interactive protocols. This paper uses round and sub-round also for the potential format of messages in a particular round. Broadbent's paper on EPR protocol uses "run" instead of "round" and seems to be a better now for this context.
\item On page 45, in the list of soundness analysis steps, what do you mean by "constant total variation distance"? It is always at most 1 by definition.
\item As in Table 4, the $W_i$'s are chosen at random and it seems that $T^0_\ell$ and $T^1_\ell$ will have roughly same/different length depending on whether it is a computation round or test round. Does this leak information about the round type to PP?
\item Page 17, item 2 of Relations, do you need $\omega_a$ to be different?
\item In the comment before Definition 7 on page 17, it is argued that the exact form of distribution does not matter. But what if the size of the relation R has n (say the number of qubits) dependence?
\item The last equation in Definition 7 has a mistake. When $W_A$ acts on $\ket{\psi}$ as in the first equation, you cannot apply $V^\dagger_A W_A V_A$ on it in general
\item The abbreviation after equation 4, $W^a_A \otimes I \approx I \otimes W^a_B$ does not fit syntactically with Definition 5, where the operators are always on A system only.
\item What is the "state-dependent norm" referred to in Definition 6?
\item Why do you use $Z_4$ in the range of $h_S$ before equation 6 even though it appears in the equation as $(-1)^{h_S}$
\end{enumerate}

Some minor issues

\begin{enumerate}
    \item  Why is the completeness not exactly 1 in Theorem 1?
\item r used both in $V^r_{EPR}$ and $p_r$ on page 30 could be confusing to readers
\item It is not clear to me why the sequential structure of Figure 9 is crucial for blindness. Could you explain a bit more about the idea behind it?
\item AUX state not defined in Lemma 10, should be the same as in Lemma 9. Similarly, $a_i$ $b_i$ need a definition in the statement of the Lemma.
\item "A H" to "An H"
\end{enumerate}

	
\subsection*{Reviewer 2}

The results of this paper can be categorized into two parts: the first part is a new "rigidity" result that shows how to use nonlocal games to test that players are performing Clifford measurements on maximally entangled states. The second part is to use these nonlocal games as part of a protocol to efficiently delegate quantum computation using only a classical verifier.

To elaborate more: a game between a classical verifier and two quantum players (who can only communicate with the verifier, but not each other) exhibits rigidity if winning the game with high probability certifies that the players must be using specific measurements and a specific quantum state (up to local changes of basis). The well-studied CHSH and Magic Square games certify that the players use maximally entangled states (EPR states) and are performing Pauli X/Z measurements, and these games form the basis of many so-called device-independent protocols such as certifying randomness generation, quantum key distribution, and delegated quantum computation.

One well known protocol is the delegation protocol of Reichardt, Unger, Vazirani (RUV). They were the first to demonstrate that by playing many rounds of the CHSH game, interleaved with other games, a classical verifier can certify that two quantum provers are performing a quantum computation correctly. While this protocol runs in polynomial time, it is not practical by any means, as it requires an estimated $g^{8192}$ time where g is the number of gates in the computation to be delegated.

The goal of this work is to come up with a verification protocol that is much closer to practicality (at least in terms of the time complexity of the protocol). This paper presents two protocols (Leash Protocol and Dog-Walker Protocol) which achieve $O(g \log g)$ complexity. It starts by taking an existing protocol of Broadbent between a semi-quantum verifier and a single quantum prover, and transforms this into a two-prover, classical verifier protocol via the use of a new nonlocal game that tests for Clifford measurements.

At the level of the results, this is a very nice contribution to the field of device-independent quantum information processing. (A side note: I would have preferred that the paper were split into two papers, one on the Clifford testing, and then a second one giving the application to delegation.).

The most technically involved part of the paper is in the Clifford rigidity part (Section 3). The remaining sections of the paper use this Clifford rigidity more or less as a black box, to convert Broadbent's verification protocol into a device-independent protocol, and this is more straightforward.

In the process of reviewing this paper, however, I had quite a bit of difficulty verifying Section 3, the Clifford rigidity section. My overall impression is that it was quite sketchily written. Indeed, what is provided are only "proof sketches" and there are many missing steps and minor errors such that it is hard to tell which parts are easily fixable and which parts require more elaborate changes. Since the Clifford rigidity section is the technical core of the paper and would be of interest beyond delegation of quantum computation, I would recommend that the authors address the following concerns before this paper can be published. Essentially, Section 3 and the Appendix should be clarified significantly.

Comments about Section 3 and the Appendix
---

Sections up to and include 3.2 are fine. However starting at 3.3 things start getting quite confusing. I'll actually start with the Appendix, which covers the analysis of the Pauli Braiding Test augmented to test for the Pauli Y observables.

Comments about PBT analysis in Appendix
----------------------
Page 64, description of Extended PBT: In test (c), the basis string W that is chosen is uniformly random in ${I, Y}^m$. However this seems problematic because this distribution of questions does not match the distribution of questions in parts (a) or (b): there the basis strings are uniform over ${X,Z}^m$, or ${X,Y}^m$, or ${Y,Z}^m$. Thus test (c) cannot be immediately connected to (a) or (b).

Furthermore, the tests in (b) cannot be immediately connected to the tests in (a) because the basis strings to each player contain Y w.h.p.

Page 65: statement of Lemma 36. Right below (33), there are both maps $\Lambda_W$ and $\Delta_X/Y/Z$ used. It seems like only Lambda or Delta should be used (the proof only refers to Delta).

The proof of Lemma 36 is difficult to follow. First, as mentioned before the tests (a), (b) and (c) are distinguishable from each other so it shouldn't be possible to connect the rigidity guarantees between each of those tests.

Furthermore,  it hand-waves over the analysis of part (c) of the test. The proof just states: success in part (c) implies [equation (34)]. This is far from obvious: part (c) consists of 3 subtests. Furthermore, parts (ii) and (iii) involve the parallel repetition of the Bell measurement subtest. Only a single instance of the Bell measurement subtest is analyzed, and it is far from clear that the error from m-parallel repetitions does not grow with m.  If it does not grow with m (as implicitly claimed in the proof), this requires a more thorough argument.

---


Back to Section 3.3:
---
It appears that much of the technical work in testing the Clifford observables comes from dealing with the phase ambiguity of the Y observables. However, the treatment of how this is dealt with is itself very ambiguous!

For example, the Lemma 9 establishes the existence of $Delta_Y$ observable that compensates for phase ambiguity. Lemma 10 then introduces another unitary map $\Lambda_R$, but there is no explanation of what this map is meant for. Is this meant to deal with another phase ambiguity? Why is this map needed?

-The map $Lambda_R$ is a unitary acting on $H_{\hat{A}}$, but is tensored twice when acting on |Aux>. Does it also act on $H_{\hat{B}}$ as well? 

A related issue: the definition of $\hat{\tau}_R$ is very confusing: when referring to “relations specified in (9)”, there is no $\sigma_X$ or $\sigma_Z$; there are only abstract X and Z symbols. Did you mean those? Also, what does it mean to replace those with the specific operators $\tau_Y = \sigma_Y \otimes (i \Delta_Y)$? 


The "proof sketch" for Lemma 10 is quite hard to follow. Part of the difficulty comes from the setup prior:

Page 20: Line 7: it says the phase $i^{a \cdot b}$ is needed to ensure that A and B are observables. Do we also need to assume that X and Z observables anticommute? Also, shouldn’t the imaginary unit i be (-1)? For example, suppose that X = Z = Id, and $a \cdot b = 1$. Then A(a,b) = i, which is not a (binary) observable; we’re assuming that all observables are binary, right?

In fact, the whole of Section 3.3 does not seem self-consistent. Line (6) indicates that R is a unitary that conjugates Pauli operators $\sigma_X \sigma Z$. However, the A, B observables are defined in terms of the abstract X, Z observables. But then the paragraph after (7) seems to say that the unitary R conjugates A and B. 

It makes sense that ultimately X and Z, after self-testing, should correspond to actual Pauli-X and Pauli-Z operators. But it’s ambiguous what has been tested already, and what is an abstract relation you need to check. 

In (7), the observables A and B have phase factors defined. However, in the test CONJ-CLIFF, the observables A and B are specified in terms of strings of I, X, Y, Z. Where do the phase factors come into the test? Or do they only show up in the analysis? Clarification regarding this would be helpful.


Assorted other typos/comments:

---


page 10: H-gadget: “maximal such k is odd". Confused about what “maximal such k” means. Should it just be “$H(TTH)^k$ where k is odd”?

Figure 2: what is the $c_f$? Is this the f-th bit of $\vec{c}$? (seems redundant)

Does $\Sigma$ generate the set of single-qubit Clifford unitaries?

Page 17: definition of Rigid self-test. For completeness, perhaps should clarify further and say that the operators corresponding to each question in $\mathcal{Q}$ satisfy exactly the same relations as specified by $\mathcal{R}$

Page 19: Proof of Lemma 8. “anti-commutation of $X_R$ with Z certifies that $X_R$ has decomposition of the form $X_R \simeq R_X \otimes \sigma_X + R_Y \otimes \sigma_Y$”. First, what is the error in this approximation, and it would be helpful to see a proof. Similarly, for subsequent statements it looks a bit hand-wavy. It would be better if the approximations had error bounds and some of the steps were spelled out. 

Page 19: Proof of Lemma 8: $C \simeq C_I \otimes I + C_Z \otimes \sigma_Z$. The identity operator I should be $\sigma_I$. 

Top of page 20: could use more explanation for why “decompositions of A, B, C earlier imply $C_I \approx… and C_Z \approx$…”. Overall this proof is a little too sketchy.

Page 64: "...multi-qubit Pauli X and Z observales" (should be "observables")


Comments on Sections 4 and 5:
---

These sections of the paper are written quite clearly and appear correct (assuming the correctness of the self-testing components), but there are a few items that are unclear to me:

Page 31, middle: "uniformly random partition $A, B_1,..., B_d$", where "$|B_\ell| = \Theta(t_\ell)$". In each layer, there is at most one T gate. So is $|B_\ell| = 0$ when $t_\ell = 0$, and a constant otherwise?

Page 34, Step 4(b): the reject criterion is $c_i \neq a_j + e_i$, which differs from the reject criterion in the EPR protocol on page 12, Figure (a), Step 3, which is $c_i \neq a_i' + e_i$. Why are these different?

My best guess is that it has something to do with measuring the observable $W_i$ before the generation of bit $c_i$ in the delegation protocol, whereas in the EPR protocol it's measured after the bit $c_i$ is generated. But it's hard to verify this, because the "completeness proof" just appeals to the completeness of the EPR protocol.

I recommend explaining what the differences are between the EPR protocol and the Verifier on a Leash protocol, and why those differences are OK. In particular, why completeness still holds.

Page 36, Proof of Lemma 16: choosing $W_i$ at random, then choosing $z_i$, versus choosing $z_i$ at random, then computing $W_i$ are equivalent. It seems like this requires $a_j$ to be uniformly random in order for this to hold -- is that right?

Page 37, Proof of Lemma 16: "There are two reasons that $V_{EPR}$ might reject: $... c_i = a_j + e_i$ fails". Again, this seems to differ from the protocol described on Page 12, Figure (a). Which is the real EPR protocol?

Major question about Leash versus Dog Walker protocol: the Dog Walker protocol is motivated by reducing the number of rounds to constant, at the cost of giving up blindness. However, as far as I can tell, the Leash protocol only uses the sequentiality to obtain blindness. Why can't the Leash protocol be flattened to a constant number of rounds in, and still preserve completeness and soundness? The completeness proof does not depend on the sequentiality, nor does the soundness proof (or is that incorrect?).

Page 42: description of protocol, the reject criteria for the X/Z test rounds is $c_i \neq a_i' + e_i$ now, which matches the description of the EPR protocol (but differs from Leash protocol).

Page 50: the figure caption obscures the page number.

\subsection*{Reviewer 3}

\subsubsection*{Summary of contributions and techniques}

This submission considers the scenario of delegated or cloud quantum computing. That is, how to
delegate securely a quantum computation to a quantum cloud. This scenario has been examined
from many perspectives already (the submission gives an overview of selected related work in the
introduction).

The setting that is considered here in particular was, as far as I know, solved for the first
time by [RUV13]: a classical, poly-time bounded verifier wants to delegate a quantum poly-time
computation to two entangled and isolated, poly-time quantum computers. The reason we have
two provers is that we do not know how to do this with one prover (unless we at willing to make
computational assumptions, but this is not the case here).

Prior work has shown achievability of the above type of delegated quantum computation. How-
ever, it is fair to say that, so far, no work had been particularly concerned about the efficiency of
such scheme (other than polynomial bounds). Efficiency is calculated in terms of the total resources
and operations employed by the verifier and the honest provers (including: shared entanglement
and gate operations). Here, the authors show two methods for delegating quantum computations,
both with O(g log g) resources. They differ in the number of rounds as follows:
	
\begin{itemize}
    \item Verifier-on-a-Leash protocol (Leash protocol for short): The Leash protocol uses a linear
(in the depth of the quantum circuit) number of communication rounds. 
\item  Dog-Walker protocol: The Dog-Walker protocol uses a constant number of communication
rounds.	
\end{itemize}
\end{document}