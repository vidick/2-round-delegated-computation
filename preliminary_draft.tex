\documentclass[11pt,letter]{article}
\usepackage[margin=1in]{geometry}
%\usepackage{fullpage}
\usepackage{amsmath,amsfonts,amsthm}
\usepackage{mathrsfs}
\usepackage{mathpazo}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{endnotes}
\usepackage{color}
\usepackage{bm}
\usepackage{times}
\usepackage{amssymb,latexsym}
\usepackage{enumitem}
\usepackage{caption}
\usepackage{tikz}
\usepackage{multirow}
\usepackage{floatrow}
\usepackage{float}
\usepackage{ragged2e}
%\usepackage{wrapfig}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}


\newcommand{\meas}{
\begin{tikzpicture}
\filldraw[fill=white] (0,.25) rectangle (.7,-.25);
\draw (.67,-.1) arc (50:130:.5);
\draw (.35,-.2)--(.525,.2);
\end{tikzpicture}
}

\newcommand{\beq}{\begin{eqnarray}}
\newcommand{\eeq}{\end{eqnarray}}

\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\bra}[1]{\langle#1|}
\newcommand{\kb}[1]{|#1\rangle\langle#1|}
\newcommand{\proj}[1]{\ket{#1}\!\bra{#1}}
\newcommand{\Tr}{\mbox{\rm Tr}}
\newcommand{\Id}{\ensuremath{\mathop{\rm Id}\nolimits}}
\newcommand{\Es}[1]{\ensuremath{\mathop{\textsc{E}}}_{#1}}

\newcommand{\CON}{C}
\newcommand{\DIS}{d}
\newcommand{\Drho}{\DIS_\rho}
\newcommand{\Trho}{\Tr_\rho}


\newcommand{\setft}[1]{\mathrm{#1}}
\newcommand{\Density}{\setft{D}}
\newcommand{\Pos}{\setft{Pos}}
\newcommand{\Proj}{\setft{Proj}}
\newcommand{\Obs}{\setft{Obs}}
\newcommand{\Channel}{\setft{C}}
\newcommand{\Unitary}{\setft{U}}
\newcommand{\Herm}{\setft{Herm}}
\newcommand{\Lin}{\setft{L}}
\newcommand{\Trans}{\setft{T}}
\DeclareMathOperator{\poly}{poly}

\newcommand{\reg}[1]{{\textsf{#1}}}

\newcommand{\C}{\ensuremath{\mathbb{C}}}
\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\F}{\ensuremath{\mathbb{F}}}
\newcommand{\K}{\ensuremath{\mathbb{K}}}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\Z}{\ensuremath{\mathbb{Z}}}

\newcommand{\mH}{\mathcal{H}}
\newcommand{\mT}{\mathcal{T}}
\newcommand{\Alg}{\mathcal{A}}
\newcommand{\mM}{\mathcal{M}}
\newcommand{\mC}{\mathcal{C}}
\newcommand{\mR}{\mathcal{R}}

\newcommand{\eps}{\varepsilon}
\newcommand{\ph}{\ensuremath{\varphi}}

\newcommand{\Acc}{\textsc{Acc}}
\newcommand{\Samp}{\textsc{Samp}}
\newcommand{\Ext}{\ensuremath{\text{Ext}}}

\newcommand{\Hmin}{H_\infty}
\newcommand{\Hmax}{H_{\ensuremath{\text{max}}}}

\newcommand{\CHSH}{{\rm CHSH}}
\newcommand{\EPR}{{\rm EPR}}
\newcommand{\MS}{{\rm MS}}
\newcommand{\basis}{\mathcal{B}}
\newcommand{\pauli}{\mathcal{P}}
\newcommand{\paulip}{\tilde{\mathcal{P}}}
\newcommand{\pbt}{\textsc{pbt}}
\newcommand{\qauli}{\mathcal{Q}}
\newcommand{\rauli}{\mathcal{R}}
\newcommand{\raulip}{\tilde{\mathcal{R}}}
\newcommand{\qaulip}{\tilde{\mathcal{Q}}}
\newcommand{\magic}{\mathcal{M}}
\newcommand{\wagon}{\mathcal{W}}
\newcommand{\aux}{\textsc {aux}}
\newcommand{\ctl}{\textsc {ctl}}
\newcommand{\swap}{\textsc {swap}}
\newcommand{\conj}{\textsc{conj}}
\newcommand{\perm}{\textsc{tens}}
\newcommand{\prodt}{\textsc{prod}}
\newcommand{\comt}{\textsc{com}}
\newcommand{\act}{\textsc{ac}}
\newcommand{\idt}{\textsc{id}}
\newcommand{\bellt}{\textsc{Bell}}

\newcommand{\rigid}{\textsc{rigid}}
\newcommand{\conjc}{\textsc{conj-cliff}}
\newcommand{\ecliff}{\textsc{e-cliff}}
\newcommand{\cliff}{\textsc{cliff}}
\newcommand{\tom}{\textsc{tom}}
\newcommand{\SWAP}{\textsc{SW}}
\newcommand{\clifford}{\mathcal{C}}
\newcommand{\cliffordga}{{\mathcal{C}_1}}
\newcommand{\cliffordgb}{{\mathcal{C}_2}}
\newcommand{\heisg}{{\mathcal{H}^{(1)}}}
\newcommand{\heisgn}{{\mathcal{H}^{(n)}}}
\newcommand{\heisga}{{\mathcal{H}_1}}
\newcommand{\heisgb}{{\mathcal{H}_{2}}}
\newcommand{\cliffordgan}{{\mathcal{C}^{(n)}_1}}
\newcommand{\cliffordgbn}{{\mathcal{C}^{(n)}_2}}
\newcommand{\cliffordn}{G_\mathcal{C}^{(n)}}
\newcommand{\paulig}{G_{\mathcal{P}}}
\newcommand{\pauligb}{G_{\mathcal{P}_2}}
\newcommand{\paulign}{G_{\mathcal{P}}^{(n)}}
\newcommand{\conjn}{\mathcal{J}^{(n)}\!}
\newcommand{\conjr}{\mathcal{J}\!}
\newcommand{\tr}{\mathcal{T}\!}
\newcommand{\epaulin}{\hat{\mathcal{P}}^{(n)}\!}
\newcommand{\tpaulin}{\tilde{\mathcal{P}}^{(n)}\!}
\newcommand{\paulin}{\mathcal{P}^{(m)}\!}
\newcommand{\ver}{\textsc{V}}
\newcommand{\pv}{\textsc{PV}}
\newcommand{\pp}{\textsc{PP}}
\newcommand{\sk}{\ensuremath{\text{sk}}}

\newcommand{\phase}{\Lambda}

\newcommand{\ekeyspace}{\mR_{ek}}
\newcommand{\messagespace}{\mM}
\newcommand{\cipherspace}{\mC}
\newcommand{\mE}{\mathcal{E}}
\newcommand{\HEEnc}{\mbox{HE.Enc}_{pk}}
\newcommand{\QHEKeyGen}{\mbox{QHE.KeyGen}}
\newcommand{\QHEEnc}{\mbox{QHE.Enc}_{pk}}
\newcommand{\QHEEval}{\mbox{QHE.Eval}}
\newcommand{\QHEDec}{\mbox{QHE.Dec}_{sk}}


\newcommand{\anote}[1]{\textcolor{blue}{\small {\textbf{(Andrea:} #1 \textbf{) }}}}
\newcommand{\snote}[1]{\textcolor{green}{\small {\textbf{(Stacey:} #1 \textbf{) }}}}
\newcommand{\agnote}[1]{\textcolor{cyan}{\small {\textbf{(Alex:} #1 \textbf{) }}}}
\newcommand{\agchanged}[1]{\textcolor{cyan}{#1}}
\newcommand{\agftnote}[1]{\footnote{\textcolor{cyan}{\small {\textbf{(Alex:} #1\textbf{) }}}}}
\newcommand{\norm}[1]{\left\|#1\right\|}
\newcommand{\aftnote}[1]{\footnote{\textcolor{blue}{\small {\textbf{(Andrea:} #1 \textbf{) }}}}}


\bibliographystyle{alpha}

\newif\ifnotes\notestrue
%\newif\ifnotes\notesfalse

%\input{../marginnotes}
\input{marginnotes}

\begin{document}

\title{Verifier-on-a-Leash: new schemes for verifiable delegated quantum computation, with quasilinear resources}

\author{Andrea Coladangelo \thanks{Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, USA. email: \texttt{acoladan@caltech.edu}. Supported by AFOSR YIP award number FA9550-16-1-0495.}
  \and Alex Grilo\thanks{IRIF, CNRS/Universit\'e Paris Diderot, Paris, France. email: \texttt{abgrilo@irif.fr}. Supported by ERC QCC.}
  \and Stacey Jeffery\thanks{QuSoft and CWI, Amsterdam, the Netherlands. email: \texttt{jeffery@cwi.nl}. Supported by an NWO WISE Grant.}
  \and Thomas Vidick\thanks{Department of Computing and Mathematical Sciences,
    California Institute of Technology, Pasadena, USA. email:
    \texttt{vidick@cms.caltech.edu}. Supported by NSF CAREER Grant CCF-1553477, AFOSR YIP award number FA9550-16-1-0495, and the IQIM, an NSF Physics Frontiers Center (NSF Grant PHY-1125565) with support of the Gordon and Betty Moore Foundation (GBMF-12500028).}}


\date{}
\maketitle

\begin{abstract}
The problem of reliably certifying the outcome of a computation performed by a quantum device is rapidly gaining relevance. We present two protocols for a classical verifier to verifiably delegate a quantum computation to two non-communicating but entangled quantum provers. Our protocols have near-optimal complexity in terms of the total resources employed by the verifier and the honest provers, with the total number of operations of each party, including the number of entangled pairs of qubits required of the honest provers, scaling as $O(g\log g)$ for delegating a circuit of size $g$. This is in contrast to previous protocols, which all require a prohibitively large polynomial overhead. Our first protocol requires a number of rounds that is linear in the depth of the circuit being delegated, and is blind, meaning neither prover can learn the circuit being delegated. The second protocol is not blind, but requires only a constant number of rounds of interaction. 

Our main technical innovation is an efficient rigidity theorem which allows a verifier to test that two entangled provers perform measurements specified by an arbitrary $m$-qubit tensor product of single-qubit Clifford observables on their respective halves of $m$ shared EPR pairs, with a robustness that is independent of $m$. Our two-prover classical-verifier delegation protocols are obtained by combining this rigidity theorem with a single-prover quantum-verifier protocol for the verifiable delegation of a quantum computation, introduced by Broadbent.
\end{abstract}

\clearpage

\tableofcontents

\clearpage 

\section{Introduction}

Quantum computers hold the potential to speed up a wide range of computational tasks (see, for example, \cite{montanaro2016survey}). Recent progress towards implementing limited quantum devices has added urgency to the already important question of how a classical verifier can test a quantum device. This verifier could be an experimentalist running a new experimental setup; a consumer who has purchased a purported quantum device; a client who wishes to delegate some task to a quantum server. In all cases, the user would like to exert some form of control over the quantum device. For example, the experimentalist may think that she is testing that a particular experiment prepares a certain quantum state by performing a series of measurements, i.e.\ by state tomography, but this assumes some level of trust in the measurement apparatus being used.  For a classical party to truly test a quantum system, that system should be modeled in a device-independent way, having classical inputs (e.g.\ measurement settings) and classical outputs (e.g.\ measurement results). 

Tests of quantum mechanical properties of a system first appeared in the form of Bell tests \cite{Bell:64a,Clauser:69a}. These tests make one crucial assumption on the system to be tested: that it consists of two spatially isolated components which are unable to communicate throughout the experiment. While the violation of a Bell inequality can be seen as a certificate of entanglement, the area of self-testing, first introduced in \cite{mayers2004selftesting}, allows for the certification of much stronger statements, including  about which measurements are being performed, and on which state.  Informally, a \emph{robust rigidity theorem} is a statement about which kind of apparatus, quantum state and measurements, must be used by a pair of isolated devices in order to succeed in a given statistical test. Following a well-established tradition, we will refer to such tests as \emph{games}, call the devices \emph{players} (or \emph{provers}), and the quantum state and measurements that they implement the \emph{strategy} of the players. A rigidity theorem is a statement about the necessary structure of near-optimal strategies for a game.  

In 2012, Reichardt, Unger and Vazirani proved a robust rigidity theorem for playing a sequence of $n$ CHSH games \cite{reichardt2012classical}. Aside from its intrinsic interest, this rigidity theorem had two important consequences. One was the first device-independent protocol for quantum key distribution. The second was a protocol whereby a completely classical verifier can test a universal quantum computer consisting of two space-like separated devices. This latter consequence of the rigidity theorem is made possible by the model of  \emph{quantum computation by teleportation}, whereby a quantum computation can be carried out through single-qubit gates applied to EPR halves and Bell basis measurements~\cite{gottesman1999teleportation}. The resulting \emph{two-prover classical-verifier} protocol for delegating quantum computations could have important practical consequences: for the foreseeable future, making use of a quantum computer will likely require delegating the computation to a potentially untrusted cloud service, such as that already announced by IBM~\cite{ibmcloud}.  

Unfortunately, the complexity overhead of the delegation protocol from~\cite{reichardt2012classical}, in terms of both the number of EPR pairs needed for the provers and the overall time complexity of the provers as well as the (classical) verifier, while polynomial, is prohibitively large. Although the authors of~\cite{reichardt2012classical} do not provide an explicit value for the exponent, in~\cite{hajdusek2015} it is estimated that their protocol requires resources that scale like $\Omega(g^{8192})$, where $g$ is the number of gates in the delegated circuit (notwithstanding the implicit constant, this already makes the approach thoroughly impractical for even a $2$-gate circuit!).
The large overhead is in part due to a very small (although still inverse polynomial) gap between the completeness and soundness parameters of the rigidity theorem; this requires the verifier to perform many more Bell tests than the actual number of EPR pairs needed to implement the computation, which would scale linearly with the circuit size. 
%Recently~\cite{experiment_ruv} provided an experimental demonstration of a two-prover delegation protocol for a $3$-qubit quantum circuit that is arguably sufficient, based on Shor's algorithm, to factor the number $15$. The protocol is based on~\cite{reichardt2012classical} but makes the assumption that the three pairs of devices shared by the provers behave in an i.i.d.\ manner at each use. This allows them to test for the three required EPR pairs using a reasonable number, around $6000$, of Bell tests. The implementation of the protocol from~\cite{reichardt2012classical} without additional assumptions for any non-trivial circuit remains out of reach. 
While the physical implementation of the protocol from~\cite{reichardt2012classical} for any non-trivial circuit remains out of reach, recently~\cite{experiment_ruv} provided an experimental demonstration of a two-prover delegation protocol based on~\cite{reichardt2012classical} for a $3$-qubit quantum circuit based on Shor's algorithm to factor the number $15$. They are able to certify  
 that the three pairs of devices shared by the provers share a state close to three required EPR pairs while making a a reasonable number of Bell tests, around $6000$, by making the strong assumption that the devices behave in an i.i.d.\ manner at each use; as argued above, without this assumption the protocol would remain thoroughly impractical even for such a small circuit. 


Subsequent work has presented significantly more efficient protocols for achieving the same functionality~\cite{McKague16,Gheorghiu15,hajdusek2015,%hayashi2016self,
hajdusek2015posthoc,natarajan2016robust}. We refer to Table \ref{tab:comparison} for a summary of our estimated lower bounds on the complexity of each of these results (not all papers provide explicit bounds, in which case our estimates, although generally conservative, should be taken with caution). Prior to this work, the most efficient multi-prover delegation protocols, in any model of computation, required resources that scale as at least $\Omega(gn^3)$ for delegating a $g$-gate circuit on $n$ qubits. 
Thus, while there exist a number of multi-prover classical-verifier delegation protocols, based on a wide variety of techniques, all require an amount of resources, both in terms of EPR pairs and time, that make them all but infeasible to implement in practice. 

In contrast, more efficient schemes for verifiable delegation exist in the setting where the verifier has some limited quantum power, such as the ability to generate or measure single-qubit states. In that case, only a single prover is needed \cite{aharonov10qpip,fitzsimons12vubqc,Morimae14,broadbent15howtoverify,MF16} (see also~\cite{fitzsimons2016survey} for a recent survey), and the most efficient \emph{single-prover quantum-verifier} protocols can evaluate a quantum circuit with $g$ gates in time $O(g)$. The main reason these protocols are much more efficient than the classical-verifier multi-prover protocols is that they avoid the need for directly testing any of the qubits used by the prover, instead requiring the trusted verifier to directly either prepare or measure the qubits used for the computation. In addition, several of these protocols have an additional desirable property, called \emph{blindness}, which states that the prover learns nothing about the circuit being implemented (some multi-prover protocols, such as~\cite{reichardt2012classical}, are blind, but others, such as~\cite{hajdusek2015posthoc}, are not). 

\begin{table}[t]
\centering
\begin{tabular}{l|llll}
& Provers & Rounds & Total Resources & Blind\\
\hline\\[-8pt]
RUV 2012 \cite{reichardt2012classical}  &2 & poly$(n)$ & $\geq g^{8192}$ & yes\\[3pt]
McKague 2013 \cite{McKague16} &  $\mathrm{poly}(n)$ & poly$(n)$ & $\geq 2^{153}g^{22}$ & yes \\[3pt]
GKW 2015 \cite{Gheorghiu15} &  2 & poly$(n)$ & $\geq g^{2048}$ & yes \\[3pt]
HDF 2015 \cite{hajdusek2015} &  poly$(n)$& poly$(n)$ & $\Theta(g^4\log g)$ & yes \\[3pt]
%HH 2016 \cite{hayashi2016self} & & & $\Theta(g^4\log g)$ & yes\\
FH 2015 \cite{hajdusek2015posthoc} & 5 & poly$(n)$ & $>gn^3$ & no\\[3pt]
NV 2016 \cite{natarajan2016robust} &  7 & 2 & $>gn^3$ & no\\[3pt]
\hline\\[-8pt]
Verifier-on-a-Leash Protocol (Section \ref{sec:leash})   & 2 & $O(\mbox{depth})$  & $\Theta(g\log g)$ & yes %\footnote{Since the scheme only hides the input, blindness is achieved by delegating a universal quantum circuit, which increases the total resources to $O(g\log g)$.}
\\[3pt]
Dog-Walker Protocol (Section \ref{sec:dog-walker})  & 2 & $O(1)$ & $\Theta(g\log g)$ & no 
\end{tabular}
\caption{Resource requirements of various delegation protocols in the multi-prover model. 
We use $n$ to denote the number of qubits and $g$ the number of gates in the
  delegated circuit. ``depth'' refers to the depth of the delegated circuit. ``Total Resources'' refers to the gate complexity of the
  provers, the number of EPR pairs of entanglement needed, and the number of
  bits of communication in the protocol. To ensure fair comparison, we require
  of each protocol that it produces the correct answer with probability $99\%$. For all protocols except~NV 2016, and our two new protocols, this requires a polynomial number of sequential repetitions, which is taken into account when computing the total resources. (In~\cite{natarajan2016robust} the gap amplification is performed by taking tensor powers and executing the verification procedure in parallel, so that the protocol achieves a constant gap with a single round of interaction; an additional round is needed to distribute the history state between the provers.)}
\label{tab:comparison}
\end{table}



\paragraph{Our contributions} We overcome the efficiency limitations of
multi-prover delegation protocols by introducing a new robust rigidity theorem.
We use the theorem to adapt the efficient single-prover quantum-verifier delegation
protocol introduced by Broadbent~\cite{broadbent15howtoverify} to obtain two new
two-prover classical-verifier protocols in which the complexity of verifiably
delegating a $g$-gate quantum circuit scales as $O(g\log g)$\footnote{The $\log g$ overhead is due to the complexity of sampling from the right distribution in rigidity tests. We leave the possibility of removing this by derandomization for future work. Another source of overhead is in achieving blindness, since in order to hide the circuit, we encode it as part of the input to a universal circuit, which introduces $\log g$ overhead.}.  %, or $O(g\log g)$ if we also want to achieve \emph{blindness}, in which the circuit being performed is hidden from each prover (the logarithmic overhead is due to the use of a universal circuit for the computation, which allows the circuit to be given as part of the input). 
Our protocols are the first protocols with a classical verifier to achieve this near-optimal complexity. We note that both our protocols require the verifier to communicate with one prover after at least one round of communication with the other has been completed. This means that the requirement that the two provers do not communicate throughout the protocol cannot be enforced through space-like separation, and should rather be seen as an additional assumption. This is also a drawback of previous protocols.

Before giving an overview of the delegation protocols, we introduce our robust rigidity theorem. The goal of the theorem is to provide the means to certify that a prover performs a desired measurement on $m$ EPR pairs, where the measurement can be any $m$-fold tensor product of (possibly distinct) single-qubit Clifford observables.

\begin{theorem}[Informal]\label{thm:rigid-informal}
Let $m\in\mathbb{Z}_{>0}$. Let $\cal G$ be a fixed, finite set of single-qubit Clifford observables. Then there exists an efficient two-prover test $\textsc{rigid}({\cal G},m)$ with $O(m)$-bit questions (a constant fraction of which are of the form $W\in{\cal G}^m$) and answers such that the following properties hold:
\begin{itemize}
\item (Completeness) There is a strategy for the provers that uses $m+1$ EPR pairs and measurements of tensor products of single-qubit Clifford observables and succeeds with probability at least $1 - e^{-\Omega(m)}$ in the test.
\item (Soundness) For any $\eps>0$, any strategy for the provers that succeeds with probability $1-\eps$ in the test must be $\poly(\eps)$-close, up to local isometries, to a strategy in which the provers begin with $(m+1)$ EPR pairs and is such that upon receipt of a question of the form $W\in {\cal G}^m$ the prover measures the ``correct'' observable $W$. 
\end{itemize}
\end{theorem}


This theorem is proven in Section \ref{sec:rigidity}. The key point in the theorem is the ``robustness'', which scales polynomially in $\eps$ but independently of $m$. (Although we do not strive to obtain the best dependence on $\eps$, we believe it should be possible to obtain a scaling of the form $C\sqrt{\eps}$ for a reasonably controlled constant $C$.) The test is also very efficient. The analysis builds upon the ``Pauli braiding test'' of~\cite{natarajan2016robust}, which establishes a similar result for the more restricted case of Pauli $\sigma_X$ and $\sigma_Z$ observables. A first contribution of our result is to show how to also test for $\sigma_Y$ observables. This is somewhat subtle due to an ambiguity in the complex phase that cannot be detected by a classical two-player test. In addition, we show how to test for more general Clifford observables by introducing a new ``conjugation test'' which tests how an observable applied by the provers acts on the Pauli group. We give a more detailed overview of the test in  Section \ref{sec:rigidity}. 

\medskip

We now introduce our two-prover classical-verifier protocols. Both protocols use the single-prover quantum-verifier protocol introduced by Broadbent~\cite{broadbent15howtoverify} as a starting point and provide different methods to delegate the quantum computation performed by the quantum verifier to a second prover (call him $\pv$ for Prover $V$). The rigidity test is used to verify that the second prover indeed performs the same actions as the honest verifier of \cite{broadbent15howtoverify}, which are sequences of single-qubit measurements of Clifford observables. 

In the first protocol, one of the provers plays the role of Broadbent's prover (call him $\pp$ for Prover $P$), and the other plays the role of Broadbent's verifier ($\pv$). The protocol enforces correct behavior of $\pv$ using Theorem~\ref{thm:rigid-informal}. We call it the \emph{Verifier-on-a-Leash Protocol}, or ``leash protocol'' for short. The protocol has a constant soundness-completeness gap, in the sense that there is a constant gap between the acceptance probability of honest provers on a \textit{yes} instance and the acceptance probability of any cheating provers on a \textit{no} instance. It requires $(2d+1)$ rounds of interaction, where $d$ is the depth of the circuit being delegated (see Section~\ref{sec:EPR-protocol} for a precise definition of how this is computed). The first round of interaction requires communication linear in the size of the circuit; the subsequent $2d$ rounds have communication that totals to an amount linear in the circuit size --- in particular, each round corresponds to a \emph{layer} of the circuit, and the communication in that round scales as the number of gates in that layer. The protocol requires $O(n+g)$ EPR pairs to delegate a $g$-gate circuit on $n$ qubits, and the overall time complexity of the protocol is $O(g\log g)$.
The input to the circuit is hidden from the provers, meaning that the protocol can be made blind by encoding the circuit in the input, and delegating a universal circuit. 

The completeness of the protocol follows directly from the completeness of \cite{broadbent15howtoverify}. Once we ensure the correct behavior of $\pv$ using our rigidity test, soundness follows from \cite{broadbent15howtoverify} as well, since the combined behavior of our verifier and an honest $\pv$ is nearly identical to that of Broadbent's verifier. 

The second protocol also starts from Broadbent's protocol, but modifies it in a different way to achieve a protocol with a constant number of rounds of interaction: it is only required that the verifier exchange one round of classical messages with the first prover, followed by one round with the second prover. The proof of security is slightly more involved, but the key ideas are  the same: we use a combination of our new self-testing results and the techniques of Broadbent's protocol to control the two provers, one of which plays the role of Broadbent's verifier, and the other the role of the prover. Because of the more complicated ``leash'' structure in this protocol, we call it the \emph{Dog-Walker Protocol}. 
 Like the leash protocol, the Dog-Walker Protocol has constant completeness-soundness gap, and overall time complexity $O(g\log g)$. One drawback of this protocol is that we do not currently know how to make it blind. In particular, while $\pv$ and $\pp$ would have to collude after the protocol is terminated to learn the input in the leash protocol, in the Dog-Walker protocol, $\pv$ simply receives the input in clear.

A constant-round protocol for verifiable, but not blind, delegated computation was previously given in~\cite{hajdusek2015posthoc}. There the idea is to ask the provers to share an encoding of the history state of the computation. The encoding can  be verified with a single round of interaction by using a technique from~\cite{Ji16}. This ``post-hoc'' verification requires the provers to learn the verifier's input even before they are separated, so that they can exchange the required history state. Alternatively, the state can be created by a single prover and teleported to the others with the help of the verifier; in this case the protocol requires two rounds of communication. In comparison with~\cite{hajdusek2015posthoc}, our protocol has a lower overhead in terms of the computation required of the provers, and it only requires two provers, instead of five for~\cite{hajdusek2015posthoc}.

Based on the Dog-Walker Protocol, it is possible to design a classical-verifier  two-prover protocol for all languages in QMA. This is achieved along the same lines as the proof that QMIP = MIP$^*$ from~\cite{reichardt2012classical}. The first prover, given the input, creates the QMA witness and teleports it to the second prover with the help of the verifier. The verifier then delegates the verification circuit to the second prover, as in the Dog-Walker Protocol; the first prover can be re-used to verify the operations of the second one.



\paragraph{Open Questions}
We have introduced a new rigidity theorem and shown how the theorem could be used to transform a specific quantum-verifier delegation protocol, due to Broadbent, into a classical-verifier protocol with an additional prover, while suffering very little overhead in terms of the efficiency of the protocol. We believe that a similar transformation could be performed starting from delegation protocols based on other models of computation, such as the protocol in the measurement-based model of~\cite{fitzsimons12vubqc} or the protocol based on computation by teleportation considered in~\cite{reichardt2012classical}, and would lead to similar efficiency improvements. 

A drawback of all these protocols, however, is that they require multiple rounds of adaptive communication. As a result, the no-communication requirement on the provers cannot be enforced by space-like separation, and needs to be taken as an a priori assumption. An important question left open by our work is whether there exists a multi-prover delegation protocol that consists of a single round of simultaneous communication with each prover, and is both blind and verifiable.


\paragraph{Organization.} The remainder of this paper is organized as follows. In Section \ref{sec:prelim}, we give the necessary preliminaries including outlining Broadbent's EPR Protocol (Section \ref{sec:EPR-protocol}). In Section \ref{sec:rigidity}, we present our new rigidity theorems. In Section \ref{sec:leash}, we present our first protocol, the leash protocol, and in Section \ref{sec:dog-walker}, we present our second protocol, the Dog-Walker Protocol. In Section \ref{sec:sequential}, we show that the constant soundness-completeness gap of our protocols can be amplified by sequential repetition.


\paragraph{Acknowledgments.} We thank Anne Broadbent for useful discussions in the early stages of this work. All authors acknowledge the IQIM, an NSF Physics Frontiers Center at the California Institute of Technology, where this research was initiated. 

\section{Preliminaries}\label{sec:prelim}


\subsection{Notation}
\label{sec:prelim-notation}

We often write $\vec{x} =(x_1,\ldots,x_n)\in \{0,1\}^n$ for a string of bits, and $W=W_1\cdots W_m\in\Sigma^m$ for a string, where $\Sigma$ is a finite alphabet. If $S\subseteq \{1,\ldots,m\}$ we write $W_S$ for the sub-string of $W$ indexed by $S$. For an event $E$, we use $1_{E}$ to denote the indicator variable for that event, so $1_E=1$ if $E$ is true, and othewise $1_E=0$. We write $\poly(\eps)$ for $O(\eps^c)$, where $c$ is a universal constant that may change each time the notation is used. 

$\mH$ is a finite-dimensional Hilbert space.  We denote by $\Unitary(\mH)$ the set of unitary operators, $\Obs(\mH)$ the set of binary observables (we omit the term ``binary'' from here on; in this paper all observables are binary) and $\Proj(\mH)$ the set of projective measurements on $\mH$ respectively.  
We let $\ket{\EPR}$ denote an EPR pair: 
$$\ket{\EPR}\,=\,\frac{1}{\sqrt{2}}\left(\ket{00}+\ket{11}\right).$$


\paragraph{Observables.}
We use capital letters $X,Z,W,\ldots$ to denote observables. We use greek letters $\sigma$, $\tau$ with a subscript $\sigma_W$, $\tau_W$, to emphasize that the observable $W$ specified as subscript acts in a particular basis. For example, $X$ is an arbitrary observable but $\sigma_X$ is specifically the Pauli $X$ matrix defined in~\eqref{eq:pauli-matrix}.

For $a\in\{0,1\}^n$ and commuting observables $\sigma_{W_1},\ldots,\sigma_{W_n}$, we write $\sigma_W(a) = \prod_{i=1}^n (\sigma_{W_i})^{a_i}$. The associated projective measurements are $\sigma_{W_i} = \sigma_{W_i}^0 - \sigma_{W_i}^1$ and $\sigma_W^u = \Es{a} (-1)^{u\cdot a} \sigma_W(a)$.  Often the $\sigma_{W_i}$ will be single-qubit observables acting on distinct qubits, in which case each is implicitly tensored with identity outside of the qubit on which it acts. 


\paragraph{Pauli and Clifford groups.}
Let 
\begin{equation}\label{eq:pauli-matrix}
\sigma_I = \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix},\qquad \sigma_X = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix},\qquad \sigma_Y = \begin{pmatrix} 0 & -i \\ i & 0 \end{pmatrix}\qquad\text{and}\qquad \sigma_Z = \begin{pmatrix} 1 & 0 \\ 0 & -1\end{pmatrix}
\end{equation}
denote the standard Pauli matrices acting on a qubit.  The single-qubit Weyl-Heisenberg group
$$\heisg = H(\Z_2)=\Big\{(-1)^c\sigma_X(a)\sigma_Z(b),\;a,b,c\in\{0,1\}\Big\} $$
is the matrix group generated by the Pauli $\sigma_X$ and $\sigma_Z$. We let $\heisgn = H(\Z_2^n)$ be the direct product of $n$ copies of $\heisg$.  
The $n$-qubit Clifford group is the normalizer of $\heisgn$ in the unitary group, up to phase: 
$$\cliffordn = \big\{G\in\Unitary((\C^2)^{\otimes n}):\, G \sigma G^\dagger \in \heisgn \quad\forall \sigma \in \heisgn\big\}.$$
Some Clifford observables we will use include 
\begin{equation}\label{eq:pauli-matrix-2}
 \sigma_H = \frac{\sigma_X+\sigma_Z}{\sqrt{2}},\qquad \sigma_{H'} = \frac{\sigma_X-\sigma_Z}{\sqrt{2}},\qquad \sigma_F = \frac{-\sigma_X+\sigma_Y}{\sqrt{2}},\qquad \sigma_{G} = \frac{\sigma_X+\sigma_Y}{\sqrt{2}}.
\end{equation}
Note that  $\sigma_H$ and $\sigma_{H'}$ are characterized by $\sigma_X \sigma_H \sigma_X = \sigma_{H'}$ and $\sigma_Z \sigma_H \sigma_Z = -\sigma_{H'}$. Similarly, $\sigma_F$ and $\sigma_G$ are characterized by $\sigma_X \sigma_F \sigma_X = -\sigma_G$ and $\sigma_Y \sigma_F \sigma_Y = \sigma_G$. 



\subsection{Quantum circuits} 

We use capital letters in sans-serif font to denote gates. We work with the universal quantum gate set $\{{\sf CNOT}, {\sf H}, {\sf T}\}$, where the controlled-not gate is the two-qubit gate with the unitary action 
$${\sf CNOT}\ket{b_1,b_2}=\ket{b_1,b_1\oplus b_2},$$ 
and the Hadamard and $\sf T$ gates are single-qubit gates with actions 
$${\sf H}\ket{b}=\frac{1}{\sqrt{2}}\left(\ket{0}+(-1)^b\ket{1}\right)\;\;\mbox{and}\;\;{\sf T}\ket{b}=e^{ib\pi/4}\ket{b},$$ respectively. We will also use the following gates:
$${\sf X}\ket{b}=\ket{b\oplus 1},\;\; {\sf Z}\ket{b}=(-1)^b\ket{b},\;\;\mbox{and}\;\;{\sf P}\ket{b}=i^b\ket{b}.$$
Measurements in the $Z$ basis (or computational basis) will be denoted by the standard measurement symbol:
\begin{center}
\begin{tikzpicture}
\draw (0,0)--(2,0);
\node at (1,0) {\meas};
\end{tikzpicture}
\end{center}
To measure another observable, $W$, we can perform a unitary change of basis $\mathsf{U}_{W}$, so that the following circuit meaures in the eigenbasis of $W$:
\begin{center}
\begin{tikzpicture}
\draw (-1,0)--(2,0);
\filldraw[fill=white] (-.5,.25) rectangle (.25,-.25);
\node at (-.125,0) {$\mathsf{U}_W$};
\node at (1,0) {\meas};
\end{tikzpicture}
\end{center}

We assume that every circuit has a specified output wire, which is measured at the end of the computation to obtain the output bit. Without loss of generality, we can assume this is always the first wire. For an $n$-qubit system, we let $\Pi_b$, for $b \in \{0,1\}$, denote the orthogonal projector onto states with $\ket{b}$ in the output wire: $\ket{b}\bra{b}\otimes \Id$. For example, the probability that a circuit $Q$ outputs 0 on input $\ket{\vec{x}}$ is $\norm{\Pi_0 Q\ket{\vec{x}}}^2$. 

We can always decompose a quantum circuit into layers such that each layer contains at most one $\sf T$ gate applied to each wire. The minimum number of layers for which this is possible is called the \emph{$\sf T$ depth} of the circuit. 
We note that throughout this work, we will assume circuits are compiled in a specific form that introduces extra $\sf T$ gates (see the paragraph on the $\sf H$ gadget in Section~\ref{sec:EPR-protocol}). The $\sf T$ depth of the resulting circuit is proportional to the depth of the original circuit. 
% (this depth should be computed after the circuit has been put in a specific normal form; see the paragraph on the $H$ gadget in Section~\ref{sec:EPR-protocol}). 


%\subsection{Quantum one-time pad}



\subsection{Broadbent's EPR Protocol}
\label{sec:EPR-protocol}


In this section we summarize the main features of a delegation protocol introduced in~\cite{broadbent15howtoverify}, highlighting the aspects that will be relevant to understanding our subsequent adaptation into two-prover protocols. The ``EPR Protocol'' from \cite{broadbent15howtoverify} involves the interaction between a verifier $V_{EPR}$ and a prover $P$. We write $P_{EPR}$ for the ``honest'' behavior of the prover. The verifier $V_{EPR}$ has limited quantum powers. Her goal is to delegate a BQP computation to the prover $P$ in a verifiable way. Specifically, the verifier has as input a quantum circuit $Q$ on $n$ qubits and an input string $\vec{x}\in\{0,1\}^n$, and the prover gets as input $Q$. The verifier and prover interact. At the end of the protocol, the verifier outputs either $\sf accept$ or $\sf reject$. The protocol is such that there exist values $p_{\mathrm{sound}}$ and $p_{\mathrm{compl}}$ with $p_{\mathrm{sound}}< p_{\mathrm{compl}}$ such that $p_{\mathrm{compl}}-p_{\mathrm{sound}}$, called the \emph{soundness-completeness gap}, is a constant independent of input size, and moreover:

\begin{description}
\item[Completeness:] If the prover is honest and $\norm{\Pi_0Q\ket{\vec{x}}}^2 \geq 2/3$, then the verifier outputs $\sf accept$ with probability at least $p_{\mathrm{compl}}$;  
\item[Soundness:] If $\norm{\Pi_0Q\ket{\vec{x}}}^2 \leq 1/3$, then the probability the verifier outputs $\sf accept$ is at most $p_{\mathrm{sound}}$.
\end{description}
%Recall that we use $\Pi_b$, for $b\in\{0,1\}$, to denote the projection on the designated output qubit for the circuit being in state $\proj{b}$.  

In Section \ref{sec:sequential}, we show that sequential repetition can be used to turn any such protocol, including our two-prover variants, into one in which the verifier outputs $0$, $1$, or $\sf abort$, and we have the following: (1) If the prover(s) is/are honest, the verifier outputs $\sf abort$ with probability at most $.01$; and (2) If $\norm{\Pi_b Q\ket{\vec{x}}}^2 \geq 2/3$ for some $b\in\{0,1\}$ then the probability that the verifier outputs $1-b$ is at most~$.01$.



In the EPR protocol, $V_{EPR}$ and $P_{EPR}$ are assumed to share $(n+t)$ EPR pairs at the start of the protocol, where $t$ is the number of $\sf T$ gates in $Q$ and $n$ the number of input bits. (In~\cite{broadbent15howtoverify} the EPR protocol is only considered in the analysis, and it is assumed that the EPR pairs are prepared by the verifier.)
 The first $n$ EPR pairs correspond to the input to the computation; they are indexed by $N=\{1,\dots,n\}$. The remaining pairs are indexed by $T=\{n+1,\dots,n+t\}$; they will be used as ancilla qubits to  implement each of the $\sf T$ gates in the delegated circuit. 

The behavior of $V_{EPR}$ depends on a \emph{round type} randomly chosen by $V_{EPR}$ after her interaction with $P_{EPR}$. There are three possible round types:
\begin{itemize}[nolistsep]
\item Computation round ($r=0$): the verifier delegates the computation to $P_{EPR}$, and at the end of the round can recover its output if $P_{EPR}$ behaves honestly;
\item $X$-test round ($r=1$) and $Z$-test round ($r=2$): the verifier tests that  $P_{EPR}$  behaves honestly, and rejects if malicious behavior is detected.
\end{itemize}
For some constant $p$, $\ver$ chooses $r=0$ with probability $p$, and otherwise chooses $r\in\{1,2\}$ with equal probability. Since the choice of round type is made after interaction with $P_{EPR}$, $P_{EPR}$'s behavior cannot depend on the round type. In particular, any deviating behavior in a computation round is reproduced in both types of test rounds. The analysis amounts to showing that any deviating behavior that affects the outcome of the computation will be detected in at least one of the test rounds. 

In slightly more detail, the high-level structure of the protocol is the following. $V_{EPR}$ measures her halves of the $n$ qubits in $N$ in order to prepare the input state on $P_{EPR}$'s system. As a result the input is quantum one-time padded with keys that depend on $V_{EPR}$'s measurement results. For example, in a computation round, $V_{EPR}$ measures each input qubit in the $Z$ basis, and gets some result $\vec{d}\in\{0,1\}^n$, meaning the input on $P_{EPR}$'s side has been prepared as ${\sf X}^{\vec{d}}\ket{0}^{\otimes n}$. In \cite{broadbent15howtoverify}, the input is always considered to be $\vec{0}$, but we can also prepare an arbitrary classical input $\vec{x}\in\{0,1\}^n$ by reinterpreting the one-time pad key as $\vec{a}=\vec{d}\oplus \vec{x}$ so that the input state on $P_{EPR}$'s side is ${\sf X}^{\vec{a}}\ket{\vec{x}}$. In a test round, on the other hand, the input is prepared as the one-time pad of either $\ket{0}^{\otimes n}$ or $\ket{+}^{\otimes n}$. Note that as indicated in Figure~\ref{fig:EPR-high-level} this choice of measurements will be made after the interaction with $P_{EPR}$ has taken place.

The honest prover $P_{EPR}$ applies the circuit $Q$, which we assume is compiled in the universal gate set $\{{\sf H},{\sf T},{\sf CNOT}\}$, to his one-time padded input. We will shortly describe gadgets that $P_{EPR}$ can apply in order to implement each of the three gate types. The gadgets are designed in a way that in a test round each gadget amounts to an application of an identity gate; this is what enables $V_{EPR}$ to perform certain tests in those rounds that are meant to identify deviating behavior of a dishonest prover. After each gadget, the one-time padded keys can be updated by $V_{EPR}$, who is able be able to keep track of the keys at any point in the circuit using the \emph{update rules} in Table \ref{tab:EPR-key-updates}. We now describe the three gadgets, before giving a complete description of the protocol. 


\paragraph{CNOT Gadget} To implement a $\sf CNOT$ gate on wires $j$ and $j'$, $P_{EPR}$ simply performs the $\sf CNOT$ gate on those wires of his input qubits. The one-time pad keys are changed by the update rule in Table \ref{tab:EPR-key-updates}, because ${\sf CNOT}\cdot {\sf X}^{a_j}{\sf Z}^{b_j}\otimes {\sf X}^{a_{j'}}{\sf Z}^{b_{j'}}={\sf X}^{a_j}{\sf Z}^{b_j+b_{j'}}\otimes {\sf X}^{a_j+a_{j'}}{\sf Z}^{b_{j'}}\cdot {\sf CNOT}$. Note that ${\sf CNOT}\ket{0}\ket{0}=\ket{0}\ket{0}$ and ${\sf CNOT}\ket{+}\ket{+}=\ket{+}\ket{+}$, so in the test runs, $P_{EPR}$ is applying the identity. 

%---------------------------------------%
\begin{table}[t]
\begin{tikzpicture}
\draw (8,3)--(16,3);
\draw (0,2.5)--(16,2.5);
\draw (1.5,2)--(16,2);
\draw (1.5,1.5)--(16,1.5);
\draw (0,1)--(16,1);
\draw (0,.5)--(16,.5);
\draw (0,0)--(16,0);

\node at (.75,1.75) {$\sf T$};
\node at (.75,.75) {$\sf H$};
\node at (.75,.25) {$\sf CNOT$};

\node at (12,2.75) {Key Update Rule};
\node at (12,2.25) {$(a_j,b_j)\leftarrow(a_j+ c_i,b_j+e_i+a_j+c_i+(a_j+c_i)z_i)$};
\node at (12,1.75) {$(a_j,b_j)\leftarrow(e_i,0)$};
\node at (12,1.25) {$(a_j,b_j)\leftarrow(0,b_j+e_i+z_i)$};
\node at (12,.75) {$(a_j,b_j)\leftarrow(b_j,a_j)$};
\node at (12,.25) {$(a_j,b_j,a_{j'},b_{j'})\leftarrow(a_j,b_j+b_{j'},a_{j}+a_{j'},b_{j'})$};

\node at (4.75,2.25) {Computation Round};
\node at (4.75,1.75) {$X$-Test, even parity; or $Z$-test, odd parity};
\node at (4.75,1.25) {$Z$-Test, even parity; or $X$-test, odd parity};

\draw (0,2.5)--(0,0);
\draw (1.5,2.5)--(1.5,1);
\draw (8,3)--(8,0);
\draw (16,3)--(16,0);
\end{tikzpicture}


\caption{Rules for updating the one-time-pad keys after applying each type of gate in the EPR Protocol, in particular: after applying the $i$-th $\sf T$ gate to the $j$-th wire; applying an $\sf H$ gate to the $j$-th wire; or applying a $\sf CNOT$ gate controlled on the $j$-th wire and targeting the $j'$-th wire. 
}\label{tab:EPR-key-updates}
\end{table}
%-------------------------------%


\paragraph{H Gadget} To implement an $\sf H$ gate on wire $j$, $P_{EPR}$ simply performs the $\sf H$ on wire $j$, and the one-time-pad keys are changed as in Table \ref{tab:EPR-key-updates}. Unlike $\sf CNOT$, $\sf H$ does not act as the identity on $\ket{0}$ and $\ket{+}$, so it is not the identity in a test round. To remedy this, assume that $Q$ is compiled so that every $\sf H$ gate appears in a pattern ${\sf H}({\sf TTH})^k$, where the maximal such $k$ is odd. This can be accomplished by replacing each $\sf H$ by $\sf HTTHTTHTTH$, which implements the same unitary. In test rounds, the $\sf T$ gadget, described shortly, implements the identity, and since ${\sf H}(\Id {\sf H})^k$ for odd $k$ implements the identity, ${\sf H}({\sf TTH})^k$ will also have no effect in test rounds. 

\paragraph{Parity of a T Gate} Within a pattern ${\sf H}({\sf TTH})^k$, the $\sf H$ has the effect of switching between an $X$-test round scenario (the state $\ket{0}$) and a $Z$-test round scenario (the state $\ket{+})$. In order to consistently talk about the type of a round while evaluating the circuit, we can associate a parity with each $\sf T$ gate in the circuit. The parity of the $\sf T$ gates that are not part of the pattern ${\sf H}({\sf TTH})^k$ will be defined to be even. A ${\sf H}$ will always flip the parity, so that within such a pattern, the first two ${\sf T}$ gates will be odd, the next two will be even, etc., until the last two $\sf T$ gates will be odd again. 

\paragraph{T Gadget} The gadget for implementing the $i$-th $\sf T$ gate on the $j$-th wire is performed on $P_{EPR}$'s $j$-th input qubit, and his $i$-th auxiliary qubit (indexed by $n+i$), which we can think of as being prepared in a particular auxiliary state by $V_{EPR}$ measuring her half of the corresponding EPR pair, as shown in Figure~\ref{fig:tgadget-EPR}. The gadget depends on a random bit $z_i$ that is chosen by $V_{EPR}$ and sent to the prover. 



%------------------------------------%

\begin{figure}[H]
\centering
\begin{tikzpicture}
%\node at (0,4) {${\sf X}^a{\sf Z}^b\ket{\psi}$};

\node at (1,4.25) {$j$};
\node at (1,3.25) {$n+i$};

\draw (.75,4) -- (4,4) -- (5,3) -- (5.5,3);
\filldraw[white] (4.5,3.5) circle (.1);
\draw (0,2.25) -- (.75,3) -- (4,3) -- (5,4) -- (5.5,4);
\draw (0,2.25) -- (.75,1.5) -- (10,1.5);

%\node at (1.75,2) {$z\in_R\{0,1\}$};
%\draw (2.75,2.025) -- (3.225,2.025) -- (3.225,3);
%\draw (2.75,1.975) -- (3.275,1.975) -- (3.275,3);
%\filldraw (3.25,2) circle (.075);


\draw (2,4) circle (.15);
\filldraw (2,3) circle (.075);
\draw (2,4.15) -- (2,3);

\filldraw[fill=white] (3,3.25) rectangle (3.5,2.75);
\node at (3.25,3) {${\sf P}^{z_i}$};

\draw (6,3.025) -- (6.525,3.025) -- (6.525,2.025) -- (7,2.025);
\draw (6,2.975) -- (6.475,2.975) -- (6.475,1.975) -- (7,1.975);
\node at (5.75,3) {\meas};
\filldraw (6.5,3) circle (.075);
\filldraw (6.5,2) circle (.075);
\node at (7.25,2) {$c_i$};


\draw[dashed] (-1,2.5) -- (10.5,2.5);


%%%%%%%%%%%

\filldraw[fill=white] (8.5,1.25) rectangle (9.25,1.75);
\node at (8.875,1.5) {$\mathsf{U}_{W_i}$};


\draw (10,1.525) -- (10.5,1.525);
\draw (10,1.475) -- (10.5,1.475);
\node at (9.75,1.5) {\meas};
\node at (10.75,1.5) {$e_i$};

%\node at (6.5,4) {${\sf X}^{a'}{\sf Z}^{b'}\ket{\psi'}$};

\node at (-2.3,3.45) {Prover ($P_{EPR}$)};
\node[yscale=4,xscale=2] at (-.95,3.4) {$\{$};
\node at (-2.4,1.65) {Verifier ($V_{EPR}$)};
\node[yscale=4,xscale=2] at (-.95,1.6) {$\{$};

\end{tikzpicture}
\caption{The gadget for implementing the $i$-th $\sf T$ gate on the $j$-th wire. The gate $\mathsf{U}_{W_i}$ implementing the change of basis associated with observable $W_i$ is applied as part of the procedure $V_{EPR}^r$ (see Figure \ref{fig:original-protocol-VEPRr}) and is determined by the round type $r$, the parity of the $i$-th $\sf T$ gate, $z_i$, $c_i$, and $a_i'$ (the $\sf X$-key going into the $i$-th $\sf T$ gate), as in Table~\ref{tab:Oy}. %The new one-time-pad keys, $a'$ and $b'$, depend on the round type $a$, $b$, $c$, $e$, and $z$, and are given in equation \eqref{eq:EPR-key-updates}. %One can check that in a computation round, $\ket{\psi'}={\sf T}\ket{\psi}$, whereas in a test round, $\ket{\psi'}=\ket{\psi}$. 
%$$O_y=\left\{\begin{array}{ll}
%Id \mbox{ (observable $Z$)} & \mbox{$X$-test, even Hadamard parity; or $Z$-test, and odd Hadamard parity}\\
%H \mbox{ (observable $X$)} & \mbox{if }\\
%HP \mbox{ (observable $Y$)} & \mbox{if }\\
%HT \mbox{ (observable $G$)} & \mbox{if }\\
%HPT \mbox{ (observable $F$)} & \mbox{if }\\
%\end{array}\right.$$ 
}\label{fig:tgadget-EPR}
\end{figure}
%------------------------------------%


%-------------------------------%
\begin{table}[H]
\begin{tikzpicture}
\node at (-2.5,3.25) {Computation Round};
\node at (-2.5,2) {$X$-Test Round};
\node at (-2.5,.5) {$Z$-Test Round};

\node at (1.25,3.5) {$a_i'\oplus c_i\oplus z_i=0$};
\node at (1.25,3) {$a_i'\oplus c_i\oplus z_i=1$};
\node at (.5,2.5) {even $\sf T$ gate};
\node at (.5,1.75) {odd $\sf T$ gate}; 	\node at (2.5,2) {$z_i=0$};
						\node at (2.5,1.5) {$z_i=1$};
\node at (.5,1) {odd $\sf T$ gate};
\node at (.5,.25) {even $\sf T$ gate}; 	\node at (2.5,.5) {$z_i=0$};
						\node at (2.5,0) {$z_i=1$};

\node at (5,4) {$\mathsf{U}_{W_i}$ (observable $W_i$)};
\node at (5,3.5) {${\sf HT}$ (observable $G$)};
\node at (5,3) {${\sf HPT}$ (observable $F$)};
\node at (5,2.5) {$\Id$ (observable $Z$)};
\node at (5,2) {${\sf H}$ (observable $X$)};
\node at (5,1.5) {${\sf HP}$ (observable $Y$)};
\node at (5,1) {$\Id$ (observable $Z$)};
\node at (5,.5) {${\sf H}$ (observable $X$)};
\node at (5,0) {${\sf HP}$ (observable $Y$)};

\draw (3.25,4.25)--(6.75,4.25);
\draw (-4.25,3.75)--(6.75,3.75);
\draw (-.75,3.25)--(6.75,3.25);
\draw (-4.25,2.75)--(6.75,2.75);
\draw (-.75,2.25)--(6.75,2.25);
\draw (1.75,1.75)--(6.75,1.75);
\draw (-4.25,1.25)--(6.75,1.25);
\draw (-.75,.75)--(6.75,.75);
\draw (1.75,.25)--(6.75,.25);
\draw (-4.25,-.25)--(6.75,-.25);

\draw (-4.25,3.75)--(-4.25,-.25);
\draw (-.75,3.75)--(-.75,-.25);
\draw (1.75,2.25)--(1.75,1.25); \draw (1.75,.75)--(1.75,-.25);
\draw (3.25,4.25)--(3.25,-.25);
\draw (6.75,4.25)--(6.75,-.25);
\end{tikzpicture}
\caption{The choice of $\mathsf{U}_{W_i}$ in the $\sf T$ gadget. We also indicate the observable $W_i$ associated with the final measurement $W_i=\mathsf{U}_{W_i}^\dagger Z \mathsf{U}_{W_i}$.}\label{tab:Oy}
\end{table}
%---------------------------------------%


%------------------------------------%

\begin{figure}[h]
\floatbox[{\capbeside\thisfloatsetup{capbesideposition={right,top},capbesidewidth=8cm}}]{figure}[\FBwidth]
{\begin{tikzpicture}

%\draw (0,0) circle (.1);

\draw (2.5,2)--(2.5,5.25)-- (4.5,6) --(6.5,5.25)--(6.5,5);
\draw (3,2)--(3,5.25)-- (5,6) --(7,5.25)--(7,5);


\draw (2,5) rectangle (4,-1.25);
\node at (2.45,-1) {$V_{EPR}$};

\filldraw[fill=white] (6,5) rectangle (7.5,2);
\node at (6.75,3.5) {$P_{EPR}$};


\node at (5,4.5) {$\vec{z}\in\{0,1\}^t$};
\draw[->] (4,4.25)--(6,4.25);

\node at (5,3.5) {$\vec{c}\in\{0,1\}^t$};
\node at (5,3) {$c_f\in\{0,1\}$};
\draw[<-] (4,2.75)--(6,2.75);

\filldraw[fill=white] (2.25,2) rectangle (3.75,.5);
\node at (3,1.25) {$V_{EPR}^{r}$};

\draw[->] (3.5,2.5)--(3.5,2);
\node at (3.5,2.75) {$\vec{x},\vec{c},\vec{z}$};

\draw[->] (3,.5)--(3,0);
\node at (3,-.25) {$\vec{a},\vec{b},\vec{e}$};

\draw[white] (8,0) circle (.1);

\end{tikzpicture}}
{\caption{This figure describes how different pieces of the protocol fit together. $V_{EPR}$ and $P_{EPR}$ share $n+t$ EPR pairs. The honest prover $P_{EPR}$ can be seen as a procedure that acts on $n+t$ qubits --- the EPR pair halves --- depending on a $t$-bit string $\vec{z}$.  We have separated the quantum part of $V_{EPR}$ into its own procedure, called $V_{EPR}^{r}$, where $r\in\{0,1,2\}$ indicates the \emph{round type}, which $V_{EPR}$ runs on her $n+t$ EPR halves, and the $2t$ bits $\vec{c}$ and $\vec{z}$. Aside from running $V_{EPR}^r$, $V_{EPR}$ is classical. }\label{fig:EPR-high-level}}
\end{figure}

% ------------------------------------------ %


\paragraph{The EPR Protocol.} We show how the gadgets just described are used in the complete protocol. We first describe the protocol for $V_{EPR}$ below.  For later convenience we have divided the action of $V_{EPR}$ into classical actions and a single quantum subroutine $V_{EPR}^r$ depending on the round type. 

%----------------%
\begin{figure}[H]
\rule[1ex]{16.5cm}{0.5pt}
%$V_{EPR}$ and $P_{EPR}$ share $n+t$ EPR pairs.
\begin{enumerate}
\item $V_{EPR}$ chooses $\vec{z}\in_R\{0,1\}^t$, sends it to $P_{EPR}$,\footnote{We note that in the original EPR Protocol of \cite{broadbent15howtoverify}, this is accomplished by $P_{EPR}$ and $V_{EPR}$ both measuring $t$ EPR pairs in the $Z$ basis to get a shared random string $\vec{z}$.} and receives back $\vec{c}\in\{0,1\}^t$ and $c_f\in\{0,1\}$.
\item $V_{EPR}$ chooses a random round type $r\in\{0,1,2\}$ and runs $V_{EPR}^r$ (see Figure \ref{fig:original-protocol-VEPRr}) on her EPR halves, $\vec{x}$, $\vec{c}$ and $\vec{z}$, to obtain bits $\vec{a},\vec{b}\in\{0,1\}^n$ and $\vec{e}\in\{0,1\}^t$. 
\item $V_{EPR}$ applies the update rules from Table \ref{tab:EPR-key-updates} on the initial keys $(\vec{a},\vec{b})$, gate-by-gate, to obtain, for every $i\in [t]$, the $\sf X$-key before the $i$-th $\sf T$ gate is applied, $a'_i$, and the final $\sf X$ key for the output wire, $a_f'$. If $r=1$ ($X$-test round) and there exists an $i$ such that the $i$-th $\sf T$ gate is even and $c_i\neq a'_i\oplus e_i$, output $\sf reject$. If $r=2$ ($Z$-test round) and there exists an $i$ such that the $i$-th $\sf T$ gate is odd and $c_i\neq a'_i\oplus e_i$, output $\sf reject$. If $r\in\{0,1\}$ (computation or $X$-test round) and $c_f\oplus a_f'\neq 0$, output $\sf reject$. Otherwise, output $\sf accept$. 
\end{enumerate}
\rule[2ex]{16.5cm}{0.5pt}\vspace{-.5cm}
\caption{The EPR Protocol: $V_{EPR}$'s point of view.}
  \label{fig:original-protocol-VEPR}
\end{figure}
%----------------%

The procedure $V_{EPR}^r$ measures each of the $n+t$ EPR halves according to some observable that depends on $r$, $\vec{c}$, and $\vec{z}$. In the case of a computation round, $V_{EPR}^0$ measures the qubits in $T$ adaptively. 

%----------------%
\begin{figure}[H]
\rule[1ex]{16.5cm}{0.5pt}
\raggedright
Input: A circuit $Q$ with $t$ $\sf T$ gates, $\vec{x}\in\{0,1\}^n$, $\vec{c},\vec{z}\in\{0,1\}^t$, an $n$-qubit system indexed by $N$, and a $t$-qubit system indexed by $T$.
\begin{enumerate}
\item If $r\in\{0,1\}$, measure each qubit in $N$ in the $Z$ basis, and otherwise measure in the $X$ basis, to get results $\vec{d}\in\{0,1\}^n$. If $r=0$, set $(\vec{a},\vec{b})=(\vec{d}\oplus \vec{x},0^n)$; if $r=1$, set $(\vec{a},\vec{b})=(\vec{d},0^n)$; and if $r=2$ set $(\vec{a},\vec{b})=(0^n,\vec{d})$. 
\item Going through $Q$ gate-by-gate, use the update rules in Table
  \ref{tab:EPR-key-updates} to update the one-time-pad keys. For every
    $i\in[t]$, when the $i$-th $\sf T$ gate is reached, let $a_i'$ be the $\sf
    X$ key before the $i$-th $\sf T$ gate is applied. Choose an observable $W_i$ according to Table \ref{tab:Oy} in which to measure the $i$-th qubit in $T$, corresponding to the $i$-th $\sf T$ gate, obtaining result $e_i$.  
\end{enumerate}
\rule[2ex]{16.5cm}{0.5pt}\vspace{-.5cm}
\caption{The procedure $V_{EPR}^r$, employed by $V_{EPR}$.}
  \label{fig:original-protocol-VEPRr}
\end{figure}
%----------------%

\noindent Finally, we describe the behavior of an honest prover, $P_{EPR}$.

%----------------%
\begin{figure}[H]
\rule[1ex]{16.5cm}{0.5pt}
\begin{enumerate}
\item Receive $\vec{z}\in\{0,1\}^t$ from $V_{EPR}$. 
\item Evaluate $Q$ gate-by-gate using the appropriate gadget for each gate.
In particular, use $z_i$ to implement the $i$-th $\sf T$ gadget, and obtain measurement result $c_i$. 
\item Measure the output qubit to obtain $c_f$, and return $\vec{c}$ and $c_f$ to $V_{EPR}$.
\end{enumerate}
\rule[2ex]{16.5cm}{0.5pt}\vspace{-.5cm}
\caption{The EPR Protocol: Honest prover strategy $P_{EPR}$.}
  \label{fig:original-protocol-PEPR}
\end{figure}
%----------------%

%%%














%Note that in an $X$-test round when the parity is even, or $Z$-test round when parity is odd, $\ket{\psi}=\ket{0}$, so we can consider the $Z$ key to be 0. Similarly, in other test cases, $\ket{\psi}=\ket{+}$, so we can consider the $\sf X$ key to be 0. 














%%----------------%
%\begin{figure}[H]
%\rule[1ex]{16.5cm}{0.5pt}
%Suppose the circuit to be performed is broken into $d$ layers, each with at most one $\sf T$ gate per wire. Let $t$ be the total number of $\sf T$ gates in the circuit.
%\begin{enumerate}
%\item $V_{EPR}$ shares $n+2t$ EPR pairs with the prover, where $n$ is the
%  input size and $t$ is the number of $\sf T$ gadgets that must be performed, and
%    also random bits for the execution of the $\sf T$ gadgets.
%\item $V_{EPR}$ and $P_{EPR}$ each measure their halves of the $n+1,\dots,n+t$-th EPR pairs in the $Z$ basis to obtain shared randomness $\vec{z}\in\{0,1\}^t$. 
%\item  $P_{EPR}$ executes the circuit using his first $n$ EPR halves as
%  input and his last $t$ EPR halves as auxiliary qubits for the $\sf T$ gadgets.
%\item $P_{EPR}$ answers with the measurements of the $\sf T$ gadgets and the output
%  bit of the computation.
%\item $V_{EPR}$ chooses one of the run types at random:
%\begin{description}
%%\item[Computation Round:] $V_{EPR}$ measures her first $n$ EPR halves in the $Z$ basis, obtaining outcomes $\vec{f}$, and sets her one-time-pad keys as $\vec{a}=\vec{x}\oplus \vec{f}$ and $\vec{b}=0^n$. 
%\item[Computation or $X$-test Round:] $V_{EPR}$ measures her first $n$ EPR halves in the $Z$ basis, obtaining outcomes $\vec{f}$, and sets her one-time pad keys as $\vec{a}=\vec{f}$ and $\vec{b}=0^n$.
%\item[$Z$-test Round:] $V_{EPR}$ measures her first $n$ EPR halves in the $X$ basis, obtaining outcomes $\vec{f}$, and sets her one-time pad keys as $\vec{a}=0^n$, $\vec{b}=\vec{f}$.
%\end{description}
%\item For each gate in the circuit, $V_{EPR}$ performs the appropriate key update rule, and, in the case of $\sf T$ gates, performs the corresponding measurement for the $\sf T$ gadget on one of her last $t$ EPR halves. If for any even $\sf T$ gadget in the case of an $X$-test round, or any odd $\sf T$ gadget in the case of a $Z$-test round, the measurement result $c$ returned by $P_{EPR}$, the measurement result $e$ obtained by $V_{EPR}$, and the $\sf X$ key of the computational wire going into the $\sf T$ gadget, $a$, do not satisfy $a\oplus e=c$, then $V_{EPR}$ rejects. 
%\item $V_{EPR}$ uses the final $\sf X$ key of the output wire to decrypt the output bit she received from $P_{EPR}$, and accepts if and only if the decrypted bit is 0.
%\end{enumerate}
%\rule[2ex]{16.5cm}{0.5pt}\vspace{-.5cm}
%\caption{The EPR Protocol. \snote{fig:original-protocol}}
%  \label{fig:original-protocol}
%\end{figure}
%%----------------%


\paragraph{Completeness and Soundness.} 
We summarize the relevant part of the analysis of the EPR protocol from~\cite{broadbent15howtoverify}. First suppose $P_{EPR}$ behaves honestly. If $\norm{\Pi_0 Q\ket{0^n}}^2=p$, then in a computation round, $V_{EPR}$ outputs $\sf accept$ with probability $p$, whereas in a test round, $V_{EPR}$ outputs $\sf accept$ with probability $1$. This establishes completeness of the protocol:

\begin{theorem}[Completeness]\label{thm:EPR-correctness} 
Suppose the verifier executes the EPR Protocol, choosing $r=0$ with probability $p$, on an input $(Q,\ket{\vec{x}})$ such that $\norm{\Pi_0 Q\ket{\vec{x}}}^2\geq 1-\delta$. Then the probability that $V_{EPR}$ accepts when interacting with the honest prover $P_{EPR}$ is at least $(1-p)+p(1-\delta)$. 
\end{theorem}

%In~\cite{broadbent15howtoverify} it is argued that a cheating prover behaving dishonestly can only decrease the chances of $V_{EPR}$ accepting, since he is likely to be detected in the test rounds. 
The following theorem is implicit in~\cite[Section 7.6]{broadbent15howtoverify}, but we include a brief proof sketch:

\begin{theorem}[Soundness]\label{thm:EPR-soundness} 
Suppose the verifier executes the EPR Protocol, choosing $r=0$ with probability $p$, on an input $(Q,\ket{\vec{x}})$ such that $\norm{\Pi_0 Q\ket{\vec{x}}}^2\leq \delta$. Let $P_{EPR}^*$ be an arbitrary prover such that $P_{EPR}^*$ is accepted by  $V_{EPR}$ with probability $q_t$ conditioned on $r\neq 0$, and $q_c$ conditioned on $r=0$. Then the prover's overall acceptance probability is $pq_c+(1-p)q_t$, and
$$q_c \,\leq\, 2\left(q_t\,\delta+(1-q_t)\right)-\delta.$$ 
% the probability that $V_{EPR}$ accepts when interacting with $P_{EPR}^*$ is at most $(1-p)+p\delta$. \anote{This is not true for any $p$. $p$ must be small enough. Like 1/3 and lower or something like that.}  
\end{theorem}
\begin{proof}[Proof sketch]
Using the notation of \cite{broadbent15howtoverify}, let $A=\sum_k\sum_{Q\in B'_{t,n}}|\alpha_{k,Q}|^2$. For intuition, $A$ should be thought of as the total weight on attacks that could change the outcome of the computation, called non-benign attacks in \cite{broadbent15howtoverify}. By \cite{broadbent15howtoverify}, the probability of rejecting in a computation round is $1-q_c\geq (1-\delta)(1-A)$, whereas the probability of rejecting in a test round is $1-q_t\geq \frac{1}{2}A$. Combining these gives $q_c\leq 2(q_t\delta+(1-q_t))-\delta$.
\end{proof}






%===============================%
\section{Rigidity}
\label{sec:rigidity}
%===============================%

\input{rigidity.tex}




%===============================%
\section{The Verifier-on-a-Leash Protocol}
\label{sec:leash}
%===============================%




\subsection{Protocol and statement of results}

The Verifier-on-a-Leash Protocol (or ``Leash Protocol'' for short) involves a classical verifier and two quantum provers.
The idea behind the Leash Protocol is to have a first prover, nicknamed $\pv$ for Prover $V$, carry out the quantum part of $V_{EPR}$ from Broadbent's EPR Protocol by implementing the procedure $V_{EPR}^r$. (See Section~\ref{sec:EPR-protocol} for a summary of the protocol and a description of $V_{EPR}$. Throughout this section we assume that the circuit $Q$ provided as input is compiled in the format described in Section~\ref{sec:EPR-protocol}.). A second prover, nicknamed $\pp$ for Prover $P$, will play the part of the prover $P_{EPR}$. Unlike in the EPR Protocol, the interaction with $\pv$ (i.e. running $V_{EPR}^r$) will take place {first}, and $\pv$ will be asked to perform {random} measurements from the set $\Sigma = \{X,Y,Z,F,G\}$. The values $\vec{z}$, rather than being chosen at random, will be chosen based on the corresponding choice of observable. We let $n$ be the number of input bits and $t$ number of $\sf T$ gates in $Q$. 

The protocol is divided into two sub-games; which game is played is chosen by the verifier by flipping a biased coin with probability $(p_r,p_d=1-p_r)$.
\begin{itemize}[nolistsep]
\item The first game is a sequential version of the rigidity game $\rigid(\Sigma,m)$ (from Section~\ref{sec:rigidity}) described in Figure~\ref{fig:consistency-game}. This aims to enforce that $\pv$ performs precisely the right measurements;

\item The second game is the delegation game, described in Figures \ref{fig:leash-protocol-V}, \ref{fig:leash-protocol-PV}, and \ref{fig:leash-protocol-PP}, and whose structure is summarized in Figure~\ref{fig:full-picture}. Here the verifier guides $\pp$ through the computation in a similar way as in the EPR Protocol.
\end{itemize}

We call the resulting protocol the Leash Protocol with parameters $(p_r,p_d)$. In both sub-games the parameter $m=\Theta(n+t)$ is chosen large enough so that with probability close to $1$ each symbol in $\Sigma$ appears in a random $W\in \Sigma^m$ at least $n+t$ times. It is important that $\pv$ is not able to tell which kind of game is being played. Notice also that in order to ensure blindness, we will require that the interaction with $\pv$ in the delegation game is sequential (more details on this are found in Section \ref{sec:leash-blind}). In order for the two sub-games to be indistinguishable, we also require that the rigidity game $\rigid(\Sigma,m)$ be played sequentially (i.e. certain subsets of questions and answers are exchanged sequentially, but the acceptance condition in the test is the same). Note, importantly, that the rigidity guarantees of $\rigid(\Sigma,m)$ from Section \ref{sec:rigidity} hold verbatim when the game is played sequentially, since this only reduces the number of ways that the provers can cheat. The following theorem states the guarantees of the Leash Protocol.

\begin{theorem}\label{thm:leash}
There are constants $p_r,p_d=1-p_r$, and $\Delta>0$ such that the following hold of the Verifier-on-a-Leash Protocol with parameters $(p_r,p_d)$, when executed on an input $(Q,\ket{\vec{x}})$.
\begin{itemize}
\item \emph{(Completeness:)} Suppose that $\|\Pi_0 Q\ket{\vec{x}}\|^2 \geq 2/3$. Then there is a strategy for $\pv$ and $\pp$ that is accepted with probability at least $p_{\mathrm{compl}} = p_r(1-e^{-\Omega(n+t)})+8p_d/9$. 
\item \emph{(Soundness:)} Suppose that $\|\Pi_0 Q\ket{\vec{x}}\|^2 \leq 1/3$. Then any strategy for $\pv$ and $\pp$ is accepted with probability at most $p_{\mathrm{sound}} = p_{\mathrm{compl}} - \Delta$. 
\end{itemize}
%Further, the protocol leaks no information about  $(Q,\ket{\vec{x}})$ to either prover individually, aside from an upper bound on the size of $Q$. 
Further, the protocol leaks no information about $\vec{x}$ to either prover individually, aside from an upper bound on the length of $\vec{x}$. 
\end{theorem}



The proof of the completeness property is given in Lemma~\ref{lem:leash-completeness}. The soundness property is shown in Lemma~\ref{lem:leash-soundness}. Blindness is established in Section~\ref{sec:leash-blind}. 
We first give a detailed description of the protocol. We start by describing the delegation game, specified in Figures \ref{fig:leash-protocol-V}, \ref{fig:leash-protocol-PV} and \ref{fig:leash-protocol-PP}, which describe the protocol from the verifier's view, an honest $\pv$'s view, and an honest $\pp$'s view respectively. This will motivate the need for a sequential version of the game $\rigid(\Sigma,m)$, described in Figure \ref{fig:consistency-game}. As we will show, the rigidity game forces $\pv$ to behave honestly. Thus, for the purpose of exposition, we assume for now that $\pv$ behaves honestly, which results in the joint behavior of $\pv$ and $\ver$ being similar to that of the verifier $V_{EPR}$ in the EPR Protocol. 

\begin{figure}
%\begin{wrapfigure}{L}{.5\textwidth}
\centering
\begin{tikzpicture}
\node at (1,4.25) {Verifer};
\draw (0,-.75) rectangle (2,9.25); 

\node at (6,6.875) {Prover $V$};
\draw (5,9.25) rectangle (7,4.5);

\node at (6,1.625) {Prover $P$};
\draw (5,4) rectangle (7,-.75);

\draw[->] (2,9)--(5,9);
\node at (3.5,9.25) {$A, W_{A}\in\Sigma^{|A|}$};
\draw[->] (5,8.25)--(2,8.25);
\node at (3.5,8.5) {$\vec{e}_{A}\in\{0,1\}^{|A|}$};
\draw[->] (2,7.5)--(5,7.5);
\node at (3.5,7.75) {$B_1,W_{B_1}\in\Sigma^{|B_1|}$};
\draw[->] (5,6.75)--(2,6.75);
\node at (3.5,7) {$\vec{e}_{B_1}\in\{0,1\}^{|B_1|}$};
\node at (3.5,6.5) {$\vdots$};
\draw[->] (2,5.5)--(5,5.5);
\node at (3.5,5.75) {$B_d,W_{B_d}\in \Sigma^{|B_d|}$};
\draw[->] (5,4.75)--(2,4.75);
\node at (3.5,5) {$\vec{e}_{B_d}\in\{0,1\}^{|B_d|}$};

\draw[->] (2,3.75)--(5,3.75);
\node at (3.5,4) {$T,N\subset [m]$};
\draw[->] (5,3)--(2,3);
\node at (3.5,3.25) {$\vec{c}_{T_1}\in \{0,1\}^{T_1}$};
\draw[->] (2,2.25)--(5,2.25);
\node at (3.5,2.5) {$\vec{z}_{T_1}\in\{0,1\}^{T_1}$};
\node at (3.5,2) {$\vdots$};
\draw[->] (5,1)--(2,1);
\node at (3.5,1.25) {$\vec{c}_{T_\ell}\in \{0,1\}^{T_\ell}$};
\draw[->] (2,0.25)--(5,0.25);
\node at (3.5,0.5) {$\vec{z}_{T_\ell}\in\{0,1\}^{T_\ell}$};
\draw[->] (5,-.5)--(2,-.5);
\node at (3.5,-.25) {$c_f\in\{0,1\}$};

\end{tikzpicture}
\caption{Structure of the delegation game.}\label{fig:full-picture}
%\end{wrapfigure}
\end{figure}

From the rigidity game we may also assume that $\pv$ and $\pp$ share $m$ EPR pairs, labeled $\{1,\ldots,m\}$, for $m=\Theta(n+t)$. We will assume that the circuit $Q$ is broken into $d$ layers, $Q=Q_1\dots Q_d$, such that in every $Q_\ell$, each wire has at most one $\sf T$ gate applied to it, after which no other gates are applied to that wire. We will suppose the $\sf T$ gates are indexed from $1$ to $t$, in order of layer.
 
The protocol begins with an interaction between the verifier and $\pv$. The verifier selects a uniformly random partition $A,B_1,\dots,B_d$ of $\{1,\dots,m\}$, with $|A|=\Theta(n)$, and for every $\ell\in\{1,\dots,d\}$, $|B_{\ell}|=\Theta(t_\ell)$, where $t_{\ell}$ is the number of $\sf T$ gates in $Q_\ell$. The verifier also selects a uniformly random $W\in\Sigma^m$, and partitions it into substrings $W_A$ and $W_{B_1},\ldots,W_{B_d}$, meant to contain observables to initialize the computation qubits and auxiliary qubits for each layer of ${\sf T}$ gates respectively. The verifier instructs $\pv$ to measure his halves of the EPR pairs using the observables $W_A$ first, and then $W_{B_1},\ldots,W_{B_d}$, sequentially. Upon being instructed to measure a set of observables, $\pv$ measures the corresponding half-EPR pairs and returns the results $\vec{e}$ to the verifier. Breaking this interaction into multiple rounds is meant to enforce that, for example, the results output by $\pv$ upon receiving $W_{B_{\ell}}$, which we call $\vec{e}_{B_{\ell}}$, cannot depend on the choice of observables $W_{B_{\ell+1}}$. This is required for blindness. 

Once the interaction with $\pv$ has been completed, as in the EPR Protocol, $\ver$ selects one of three round types: computation $(r=0)$, $X$-test ($r=1$), and $Z$-test $(r=2)$. 
The verifier selects a subset $N\subset A$ of size $n$ of qubits to play the role of inputs to the computation. These are chosen from the subset of $A$ corresponding to wires that $\pv$ has measured in the appropriate observable for the round type (see Table \ref{tab:index-choices}). For example, in an $X$-test round, $\pv$'s EPR halves corresponding to input wires should be measured in the $Z$ basis so that $\pp$ is left with a one-time pad of the state $\ket{0}^{\otimes n}$, so in an $X$-test round, the computation wires are chosen from the set $\{i\in A:W_i=Z\}$. The input wires $N$ are labeled by ${\cal X}_1,\dots,{\cal X}_n$. 




The verifier also chooses subsets $T_\ell = T_\ell^0 \cup T_\ell^1 \subset B_\ell$ of sizes $t_{\ell,0}$ and $t_{\ell,1} = t_\ell-t_{\ell,0}$ respectively, where $t_{\ell,0}$ is the number of odd $\sf T$ gates in the $\ell$-th layer of $Q$ (recall the definition of even and odd $\sf T$ gates from Section~\ref{sec:EPR-protocol}). The wires $T^0_\ell$ and $T^1_\ell$ will play the role of auxiliary states used to perform $\sf T$ gates from the $\ell$-th layer. They are chosen from those wires from $B_\ell$ whose corresponding EPR halves have been measured in a correct basis, depending on the round type.  For example, in an $X$-test round, the auxiliaries corresponding to odd $\sf T$ gates should be prepared by measuring the corresponding EPR half in either the $X$ or $Y$ basis (see Table \ref{tab:Oy}), so in an $X$-test round, $T_\ell^1$ is chosen from $\{i\in B_\ell:\,W_i\in \{X,Y\}\}$ (see Table \ref{tab:index-choices}). We will let ${\cal T}_1,\dots,{\cal T}_t$ label those EPR pairs that will be used as auxiliary states. In particular, the system ${\cal T}_i$ will be used for the $i$-th $\sf T$ gate in the circuit, so if the $i$-th $\sf T$ gate is even, ${\cal T}_i$ should be chosen from $T^0=\cup_\ell T_\ell^0$, and otherwise it should be chosen from $T_1=\cup_\ell T_\ell^1$. The verifier sends labels ${\cal T}_1,\dots,{\cal T}_t$ and ${\cal X}_1,\dots,{\cal X}_n$ to $\pp$, who will act as $P_{EPR}$ on the $n+t$ qubits specified by these labels.


Just as in the EPR Protocol, the input on $\pp$'s system specified by ${\cal X}_1,\dots,{\cal X}_n$ is a quantum one-time pad of either $\ket{\vec{x}}$, $\ket{0}^{\otimes n}$, or $\ket{+}^{\otimes n}$, depending on the round type, with $\ver$ holding the keys (determined by $\vec{e}$). Throughout the interaction, $\pp$ always maintains a one-time pad of the current state of the computation, with the verifier in possession of the one-time-pad keys. The verifier updates her keys as the computation is carried out, using the rules in Table \ref{tab:EPR-key-updates}. 




From $\pp$'s perspective, the protocol works just as the EPR Protocol, except that he does not receive the bit $z_i$ needed to implement the $\sf T$ gadget until \emph{during} the $\sf T$ gadget, after he has sent $\ver$ his measurement result $c_i$ (see Figure \ref{fig:leash-T-gadget}).


 
To perform the $i$-th $\sf T$ gate on the $j$-th wire, $\pp$ performs the circuit shown in Figure \ref{fig:leash-T-gadget}. As Figure~\ref{fig:leash-T-gadget} shows, $\pv$ has already applied the observable specified by $\ver$ to his half of the EPR pair. The $\sf T$ gadget requires interaction with the verifier, to compute the bit $z_i$, which depends on the measured $c_i$, the value $W_i$, and one-time-pad key $a_j$, however, this interaction can be done in parallel for $\sf T$ gates in the same layer. 
%Upon receiving the bit $z_i$ from the verifier, $\pp$ applies ${\sf P}^{z_i}$ to the appropriate wire, as specified by $Q$, ${\cal X}_{j}$. 


%\begin{table}
%\centering
%\begin{tabular}{r}
%\begin{tikzpicture} %X
%\node at (-.5,0) {$X$};
%\draw (0,0)--(2,0);  
%\filldraw[fill=white] (.75,.25) rectangle (1.25,-.25);
%\node at (1,0) {$\sf H$};
%\node at (2.3,0) {\meas};
%\end{tikzpicture}\\
% \begin{tikzpicture} %Y
%\node at (-.5,0) {$Y$};
%\draw (0,0)--(2,0);  
%\filldraw[fill=white] (.35,.25) rectangle (.85,-.25);
%\node at (.6,0) {$\sf P$};
%\filldraw[fill=white] (1.65,.25) rectangle (1.15,-.25);
%\node at (1.4,0) {$\sf H$};
%\node at (2.3,0) {\meas};
%\end{tikzpicture}\\
% \begin{tikzpicture} %Z
%\node at (-.5,0) {$Z$};
%\draw (0,0)--(2,0);  
%\node at (2.3,0) {\meas};
%\end{tikzpicture}\\
% \begin{tikzpicture} %G
%\node at (-.5,0) {$G$};
%\draw (0,0)--(2,0);  
%\filldraw[fill=white] (.35,.25) rectangle (.85,-.25);
%\node at (.6,0) {$\sf T$};
%\filldraw[fill=white] (1.65,.25) rectangle (1.15,-.25);
%\node at (1.4,0) {$\sf H$};
%\node at (2.3,0) {\meas};
%\end{tikzpicture}\\
% \begin{tikzpicture} %F
%\node at (-.5,0) {$F$}; 
%\draw (0,0)--(2,0);  
%\filldraw[fill=white] (.1,.25) rectangle (.6,-.25);
%\node at (.4,0) {$\sf T$};
%\filldraw[fill=white] (.75,.25) rectangle (1.25,-.25);
%\node at (1,0) {$\sf P$};
%\filldraw[fill=white] (1.4,.25) rectangle (1.9,-.25);
%\node at (1.65,0) {$\sf H$};
%\node at (2.35,0) {\meas};
%\end{tikzpicture}
%\end{tabular}
%\caption{Observables and their corresponding circuits. \snote{We could remove this figure, since it just reproduces information in Table \ref{tab:Oy}, and takes up a lot of space}\snote{fig:obs-meas}}\label{fig:obs-meas}
%\end{table}


%---------------------------------------%
%\begin{table}[H]
%\begin{tikzpicture}
%\draw (7,3)--(16,3);
%\draw (0,2.5)--(16,2.5);
%\draw (.5,2)--(16,2);
%\draw (.5,1.5)--(16,1.5);
%\draw (0,1)--(16,1);
%\draw (0,.5)--(16,.5);
%\draw (0,0)--(16,0);
%
%\node at (.25,1.75) {$\sf T$};
%\node at (.25,.75) {$\sf H$};
%\node at (.65,.25) {$\sf CNOT$};
%
%\node at (3.75,2.25) {Computation Round};
%\node at (3.75,1.75) {$X$-Test, even parity; or $Z$-test, odd parity};
%\node at (3.75,1.25) {$Z$-Test, even parity; or $X$-test, odd parity};
%
%\node at (11.5,2.75) {Key Update Rule};
%\node at (11.5,2.25) {$(a_j,b_j)\leftarrow(a_j+ c_i,b_j+e_i+a_j+c_i+(a_j+c_i)1_{y_i\neq F})$};
%\node at (11.5,1.75) {$(a_j,b_j)\leftarrow(e_i,0)$};
%\node at (11.5,1.25) {$(a_j,b_j)\leftarrow(0,b_j+e_i+1_{y_i=Y})$};
%\node at (11.5,.75) {$(a_j,b_j)\leftarrow(b_j,a_j)$};
%\node at (11.5,.25) {$(a_j,b_j,a_{j'},b_{j'})\leftarrow(a_j,b_j+b_{j'},a_{j}+a_{j'},b_{j'})$};
%
%\draw (0,2.5)--(0,0);
%\draw (.5,2.5)--(.5,1);
%\draw (7,3)--(7,0);
%\draw (16,3)--(16,0);
%\end{tikzpicture}
%
%
%\caption{Rules for updating the one-time-pad keys after applying each type of gate in the leash protocol, in particular: after applying to the $i$-th $\sf T$-th gate to the $j$-th wire; applying a $\sf H$ gate to the $j$-th wire; or applying a $\sf CNOT$ gate controlled on the $j$-th wire and targeting the $j'$-th wire. The $\sf H$ and $\sf CNOT$ rules, as well as the $\sf T$ rule for $X$-test round, are the same as in the EPR Protocol (see Table \ref{tab:EPR-update-rules}). The $\sf T$ rule for a computation round is the same as in the EPR protocol if we let $z_i=a_j+c_i+1_{y_i=F}$, and the $\sf T$ rule for a $Z$-test round is the same as in the EPR Protocol if we let $z_i=1_{y_i=Y}$.\snote{tab:key-updates}\snote{Perhaps replace this table with an explanation (or perhaps an unproven lemma) and reference to Table \ref{tab:EPR-update-rules}?}
%}\label{tab:key-updates}
%\end{table}
%-------------------------------%

%------------------------------------%

%\begin{figure}[H]
%\begin{tikzpicture}
%\node at (-1,4) {${\sf X}^{a_{s(i)}}{\sf Z}^{b_{s(i)}}\ket{\psi}$};
%
%
%\draw (0,4) -- (2,4) -- (3,3) -- (4,3);
%\filldraw[white] (2.5,3.5) circle (.1);
%\draw (-.75,2.25)--(0,3)--(2,3)--(3,4)--(8.5,4);
%\draw (-.75,2.25)--(0,1.5)--(1.5,1.5);
%
%
%\node at (.5,4.25) {${\cal X}_{s(i)}$};
%\node at (8.25,4.25) {${\cal X}_{s(i)}$};
%\node at (.5,3.25) {${\cal AUX}_{i}$};
%
%\draw (1.5,4) circle (.15);
%\filldraw(1.5,3) circle (.075);
%\draw (1.5,4.15)--(1.5,3);
%
%\draw (4,3.025)--(4.525,3.025)--(4.525,1.525)--(5,1.525);
%\draw (4,2.975)--(4.475,2.975)--(4.475,1.475)--(5,1.475);
%\filldraw (4.5,3) circle (.075);
%\filldraw (4.5,1.5) circle (.075);
%\node at (3.75,3) {\meas};
%\node at (5.25,1.5) {$c_i$};
%
%\draw (7,1.525)--(7.475,1.525)--(7.475,4);
%\draw (7,1.475)--(7.525,1.475)--(7.525,4);
%\filldraw (7.5,1.5) circle (.075);
%\filldraw[fill=white] (7.25,4.25) rectangle (7.75,3.75);
%\node at (7.5,4) {${\sf P}^{z_i}$};
%\node at (6.75,1.5) {$z_i$};
%
%\node at (9.75,.6) {$z_i=\left\{\begin{array}{ll}
%a_{s(i)}\oplus c_i & \mbox{if }y_i=G\\
%a_{s(i)}\oplus c_i\oplus 1 & \mbox{if }y_i=F\\
%r\in_R\{0,1\} & \mbox{if }y_i=Z\\
%0 & \mbox{if }y_i=X\\
%1 & \mbox{if }y_i=Y
%\end{array}\right.$};
%
%\draw (0,0.025)--(.475,0.025)--(.475,1.25);
%\draw (0,-0.025)--(.525,-0.025)--(.525,1.25);
%\filldraw[fill=white] (.15,1.75) rectangle (.75,1.25);
%\node at (.495,1.5) {$O_{y_i}$};
%\node at (-1.75,0) {$y_i\in_R\{X,Y,Z,G,F\}$};
%\filldraw (.5,0) circle (.075);
%
%\draw (1.5,1.525)--(2.025,1.525)--(2.025,0.025)--(2.5,0.025);
%\draw (1.5,1.475)--(1.975,1.475)--(1.975,-0.025)--(2.5,-0.025);
%\node at (1.25,1.5) {\meas};
%\filldraw (2,1.5) circle (.075);
%\filldraw (2,0) circle (.075);
%\node at (2.75,0) {$e_i$};
%
%\draw[dashed] (-2.5,5) rectangle (9,2.5);
%\node at (-2.2,2.75) {$PP$};
%
%\draw[dashed] (-.5,2) rectangle (2.5,.75);
%\node at (-.15,1) {$PV$};
%
%\draw[dotted] (3.75,2) rectangle (12.5,-.75);
%\node at (4,-.5) {$V$};
%
%\draw[dotted] (-3.75,.5) rectangle (3.25,-1);
%\node at (-3.5,-.75) {$V$};
%
%
%\end{tikzpicture}
%\caption{Notation: $s(i)\in [n]$ is the wire to which we apply the $i$-th $T$ gate; ${\cal X}_j$ denotes the $j$-th computation wire; ${\cal AUX}_i$ denotes the $i$-th auxiliary wire (PP's half of an EPR pair).  \snote{fig:leash-T-gadget}}\label{fig:leash-T-gadget}
%\end{figure}

\begin{figure}[H]
\begin{tikzpicture}
%\node at (-1,4) {${\sf X}^{a_{s(i)}}{\sf Z}^{b_{s(i)}}\ket{\psi}$};


\draw (0,4) -- (2,4) -- (3,3) -- (4,3);
\filldraw[white] (2.5,3.5) circle (.1);
\draw (-.75,2.25)--(0,3)--(2,3)--(3,4)--(8,4);
\draw (-.75,2.25)--(0,1.5)--(1.5,1.5);


\node at (.5,4.25) {${\cal X}_{j}$};
\node at (7.5,4.25) {${\cal X}_{j}$};
\node at (.25,3.25) {${\cal T}_{i}$};

\draw (1.5,4) circle (.15);
\filldraw(1.5,3) circle (.075);
\draw (1.5,4.15)--(1.5,3);

\draw (4,3.025)--(4.525,3.025)--(4.525,1.775)--(5,1.775);
\draw (4,2.975)--(4.475,2.975)--(4.475,1.725)--(5,1.725);
\filldraw (4.5,3) circle (.075);
\filldraw (4.5,1.75) circle (.075);
\node at (3.75,3) {\meas};
\node at (5.25,1.75) {$c_i$};


%%%%%%%%%%%%%% P correction

\filldraw[fill=white] (6.25,3.75) rectangle (6.75,4.25);
\node at (6.5,4) {${\sf P}^{z_i}$};

\draw (6.25,1.775)--(6.525,1.775)--(6.525,3.75);
\draw (6.25,1.725)--(6.475,1.725)--(6.475,3.75);
\filldraw (6.5,1.75) circle (.075);
\node at (6,1.75) {$z_i$};

%%%%%%%%%%%%%%%%%%%%%


\node at (8,.25) {$z_i=\left\{\begin{array}{ll}
a_{j}+ c_i & \mbox{if }W_i=G\\
a_{j}+ c_i+1 & \mbox{if }W_i=F\\
z\in_R\{0,1\} & \mbox{if }W_i=Z\\
0 & \mbox{if }W_i=X\\
1 & \mbox{if }W_i=Y
\end{array}\right.$};

\draw (0,0.025)--(.475,0.025)--(.475,1.25);
\draw (0,-0.025)--(.525,-0.025)--(.525,1.25);
\filldraw[fill=white] (.15,1.75) rectangle (.9,1.25);
\node at (.525,1.5) {$\mathsf{U}_{W_i}$};
\node at (-1.85,0) {$W_i\in_R\{X,Y,Z,G,F\}$};
\filldraw (.5,0) circle (.075);

\draw (1.5,1.525)--(2.025,1.525)--(2.025,0.025)--(2.5,0.025);
\draw (1.5,1.475)--(1.975,1.475)--(1.975,-0.025)--(2.5,-0.025);
\node at (1.4,1.5) {\meas};
\filldraw (2,1.5) circle (.075);
\filldraw (2,0) circle (.075);
\node at (2.75,0) {$e_i$};

\draw[dashed] (-2.5,5) rectangle (9,2.5);
\node at (-2.2,2.75) {$\pp$};

\draw[dashed] (-.5,2) rectangle (2.5,.75);
\node at (-.15,1) {$\pv$};

\draw[dotted] (-3.75,.5) rectangle (3.25,-1);
\node at (-3.5,-.75) {$\ver$};


\draw[dotted] (3.75,2) rectangle (11,-1);
\node at (4,-.75) {$\ver$};





\end{tikzpicture}
\caption{The gadget for implementing the $i$-th $\sf T$ gate, on the $j$-th wire.}\label{fig:leash-T-gadget}
\end{figure}

It is simple to check that the $\sf T$ gadget in Figure \ref{fig:leash-T-gadget} is the same as the $\sf T$ gadget for the EPR Protocol shown in Figure \ref{fig:tgadget-EPR}. In the case of the leash protocol, $W$ is chosen at random, and then $\vec{z}$ is chosen accordingly, whereas in the case of the EPR Protocol, $\vec{z}$ is chosen at random and then $W$ is chosen accordingly. 

%Finally, when all layers of the circuit have been executed, $\pp$ measures the output qubit, which, by convention, we will take to be the qubit on the wire ${\cal X}_1$, obtaining $c_f\in\{0,1\}$. This represents the output of the computation, one-time padded with the final $\sf X$ key on the first computation wire, $a_f$, which can be computing using the update rules in Table \ref{tab:EPR-key-updates}. The verifier computes $c_f\oplus a_f$, and accepts if $c_f\oplus a_f = 0$, and rejects otherwise. 



\begin{table}
\centering
\setlength\tabcolsep{1.5pt}
\begin{tabular}{|l|lll|}
\hline
& Computation Round & $X$-test Round & $Z$-test Round\\
\hline
$N$, input/computation qubits & $\{i\in A:W_i=Z\}$ & $\{i\in A:W_i=Z\}$ & $\{i\in A:W_i=X\}$\\
$T^0_{\ell}$, even $\sf T$ gate auxiliaries & $\{i\in B_{\ell}:W_i\in \{G,F\}\}$ & $\{i\in B_{\ell}:W_i=Z\}$ & $\{i\in B_{\ell}:W_i\in \{X,Y\}\}$ \\
$T^1_{\ell}$, odd $\sf T$ gate auxiliaries & $\{i\in B_{\ell}:W_i\in \{G,F\}\}$ & $\{i\in B_{\ell}:W_i\in \{X,Y\}\}$ & $\{i\in B_{\ell}:W_i=Z\}$ \\
\hline
\end{tabular}
\caption{How the verifier chooses index sets $T=T^0\cup T^1$ and $N$ for each type of round. These index sets determine which of the $m$ systems are labeled by $\{{\cal T}_{i}\}_{i=1}^t$ and $\{{\cal X}_{j}\}_{j=1}^n$, respectively.}\label{tab:index-choices}
\end{table}

We now give the precise protocols for $\ver$ (Figure \ref{fig:leash-protocol-V}) and honest provers $\pv$ (Figure \ref{fig:leash-protocol-PV}) and $\pp$ (Figure \ref{fig:leash-protocol-PP}). To see how these fit together, refer to Figure \ref{fig:full-picture}. For a string $\vec{v}$ and an ordered set of indices $I$, we denote by $\vec{v}_I$ the substring corresponding to indices in $I$.

%----------------%
\begin{figure}[H]
\rule[1ex]{16.5cm}{0.5pt}
\justify 
Let $(Q,\vec{x})$ be the input to the verifier, where $Q$ is compiled in the form described in Section~\ref{sec:EPR-protocol}. Let $n$ be the size of the input to $Q$. Let $d$ be the $\sf T$-depth, and for $\ell\in\{1,\ldots,d\}$ let $t_\ell$ be the number of {\sf T} gates in the $\ell$-th layer. 
\begin{enumerate}
\item The verifier selects $W \in_R\Sigma^{m}$. She partitions $\{1,\ldots,m\}$ arbitrarily into non-overlapping subsets $A$ and $B_1,\ldots,B_d$ such that $W_A$ contains at least $n$ copies of each symbol in $\Sigma$, and for each $\ell\in\{1,\ldots,d\}$, $W_{B_\ell}$ contains at least $t_\ell$ copies of each symbol in $\Sigma$.
\item The verifier sends $A,W_A$ to $\pv$, who returns $\vec{e}_A \in \{0,1\}^A$. The verifier sequentially sends  $(B_1,W_{B_1}),\ldots,(B_d,W_{B_d})$ to $\pv$, each time receiving $\vec{e}_{B_\ell}\in \{0,1\}^{B_\ell}$ as answer. 
\item The verifier selects a round type uniformly at random. She selects sets $N \subseteq A$ and  $T_\ell \subseteq B_\ell$, for $\ell\in\{1,\ldots,d\}$, of sizes $|N|=n$ and $|T_\ell|=t_\ell$, as follows:
\begin{description}
\item[Computation Round:] $N$ is chosen at random from 
$\{i\in A: W_i=Z\}$. $T_\ell$ is chosen at random from $\{i\in B_\ell:\,W_i\in \{G,F\}\}$. 
She sets $\vec{a} = \vec{e}_N + \vec{x}$ and $\vec{b} = 0^n$.
\item[$X$-test Round:] $N$ is chosen at random from 
$\{i\in A:W_i=Z\}$. $T_\ell = T_\ell^0 \cup T_\ell^1$, where $T_\ell^0$ is of size $t_{\ell,0}$ chosen at random from $\{i\in B_\ell:W_i=Z\}$ and $T_\ell^1$ is of size $t_{\ell,1}$ chosen at random from $\{i\in B_\ell:W_i\in \{X,Y\}\}$.
She sets $\vec{a} = \vec{e}_N$ and $\vec{b} = 0^n$.
\item[$Z$-test Round:] $N$ is chosen at random from 
$\{i\in A:W_i=X\}$. $T_\ell = T_\ell^0 \cup T_\ell^1$, where $T_\ell^0$ is of size $t_{\ell,0}$ chosen at random from $\{i\in B_\ell:W_i\in\{X,Y\}\}$ and $T_\ell^1$ is of size $t_{\ell,1}$ chosen at random from $\{i\in B_\ell:W_i=Z\}$.
She sets $\vec{a} = 0^n$ and $\vec{b} = \vec{e}_N$.
\end{description}
The verifier sends the sets $N$ and $T_\ell^0$, $T_\ell^1$, for all $\ell\in\{1,\ldots,d\}$, to $\pp$.
\item For $\ell=1,\dots,d$, 
\begin{enumerate}
  \item For each Clifford gate in the $\ell$-th layer, perform the appropriate key update from Table \ref{tab:EPR-key-updates}.
 \item The verifier receives $\vec{c} = \{c_i\}_{i\in T_{\ell}}$ from $\pp$. If it's an $X$-test round and $i\in T_\ell^0$, or it's a $Z$-test round and $i\in T_\ell^1$, $\sf reject$ if $c_i\neq a_{j}+ e_i$, where $j$ is the wire to which the $i$-th $\sf T$ gate is applied.
\item For each $i\in T_\ell$, the verifier computes $\vec{z}=\{z_i\}_{i\in T_\ell}$ as follows: 
\begin{description}
\item[Computation Round] $z_i=a_{j}+ 1_{W_i=F} + c_i$ ;
\item[$X$-test Round] if $i\in T_\ell^0$, $z_i\in_R\{0,1\}$; else if $i\in T_\ell^1$, $z_i=1_{W_i=Y}$;
\item[$Z$-test Round] if $i\in T_\ell^0$, $z_i=1_{W_i=Y}$; else if $i\in T_\ell^1$, $z_i\in_R\{0,1\}$.
\end{description}
\item The verifier sends $\vec{z}$ to $\pp$ and updates keys $(a_j,b_j)$ for each wire $j$ that had a $\sf T$ gate applied, according to Table \ref{tab:EPR-key-updates}.
\end{enumerate} 
\item The verifier receives a bit $c_f$ from $\pp$. She outputs $\sf reject$ if it's a computation or $X$-test round and $c_f+ a_f\neq 0$, where $a_f$ is the final $\sf X$-key on the output wire; and $\sf accept$ otherwise.
\end{enumerate}
\rule[2ex]{16.5cm}{0.5pt}\vspace{-.5cm}
\caption{The Delegation Game: Verifier's point of view.}\label{fig:leash-protocol-V}
\end{figure}

\begin{figure}[H]
\rule[1ex]{16.5cm}{0.5pt}
\begin{enumerate}
\item For $\ell=0,1,\ldots,d$,
\begin{enumerate}
\item $\pv$ receives a string $W_{S} \in\Sigma^{S}$, for some subset $S$ of $\{1,\ldots,m\}$, from $\ver$. 
\item For $i\in S$, $\pv$ measures his half of the $i$-th EPR pair using the observable indicated by $W_i$, obtaining an outcome $e_i\in\{0,1\}$. 
\item $\pv$ returns $\vec{e}_S$ to $\ver$. 
\end{enumerate}
\end{enumerate}
\rule[2ex]{16.5cm}{0.5pt}\vspace{-.5cm}
\caption{The Delegation Game: Honest strategy for $\pv$.}\label{fig:leash-protocol-PV}
\end{figure}



\begin{figure}[H]
\rule[1ex]{16.5cm}{0.5pt}
\begin{enumerate}
\item $\pp$ receives subsets $N$ and $T_\ell^0,T_\ell^1$ of $\{1,\ldots,m\}$, for $\ell\in\{1,\ldots,d\}$, from the verifier. 
\item For $\ell=1,\dots,d$, 
\begin{enumerate}
\item $\pp$ does the Clifford computations in the $\ell$-th layer.
 \item For each $i\in T_\ell = T_\ell^0\cup T_\ell^1$, $\pp$ applies a $\sf CNOT$ from ${\cal T}_i$ into the input register corresponding to the wire on which this $\sf T$ gate should be performed, ${\cal X}_{j}$, and measures this wire to get a value $c_i$. The register ${\cal T}_i$ is relabeled ${\cal X}_{j}$. He sends $\vec{c}_{T_\ell} = \{c_i\}_{i\in T_{\ell}}$ to $\ver$. (See Figure \ref{fig:leash-T-gadget}).
\item $\pp$ receives $\vec{z}_{T_{\ell}}=\{z_i\}_{i\in T_\ell}$ from $\ver$. For each $i\in T_\ell$, he applies ${\sf P}^{z_i}$ to the corresponding~${\cal X}_{j}$. 
\end{enumerate} 
\item $\pp$ performs the final computations that occur after the $d$-th layer of $\sf T$ gates, measures the output qubit, ${\cal X}_1$, and sends the resulting bit, $c_f$, to $\ver$. 
\end{enumerate}
\rule[2ex]{16.5cm}{0.5pt}\vspace{-.5cm}
\caption{The Delegation Game: Honest strategy for $\pp$.}\label{fig:leash-protocol-PP}
\end{figure}

Finally, we describe the sequential version of the game $\rigid(\Sigma,m)$ in Figure~\ref{fig:consistency-game}. It is no different than $\rigid(\Sigma,m)$, except for the fact that certain subsets of questions and answers are exchanged sequentially, but the acceptance condition is the same. As mentioned earlier, running the game sequentially only reduces the provers' ability to cheat. Hence, the guarantees from $\rigid(\Sigma,m)$ in Section \ref{sec:rigidity} hold verbatim for the sequential version. 

\begin{figure}[H]
\rule[1ex]{16.5cm}{0.5pt}
\vspace{-25pt}
\justify 
Let $m$, $n$, and $t_1,\ldots,t_d$ be parameters provided as input, such that $m = \Theta(n+t_1+\cdots+t_d)$. 
\begin{enumerate}
\item The verifier selects questions $W,W' \in \Sigma^{m}$, for the first and second player respectively, according to the distribution of questions in the game $\rigid(\Sigma,m)$. She partitions $\{1,\ldots,m\}$ at random into subsets $A$ and $B_\ell$, for $\ell\in\{1,\ldots,d\}$, of size $|A|=\Theta(n)$ and $|B_\ell|=\Theta(t_\ell)$, exactly as in Step 1 of the Delegation Game. 
\item The verifier sends $(A,W_A), (B_1,W_{B_1}),.., (B_d,W_{B_d})$ and $(A,W'_A), (B_1,W'_{B_1}), .., (B_d,W'_{B_d})$ in sequence to the first and second prover respectively. They sequentially return respectively $\vec{e}_A \in \{0,1\}^{|A|}$, $\vec{e}_{B_1} \in \{0,1\}^{|B_1|},.., \vec{e}_{B_d} \in \{0,1\}^{|B_d|}$ and $\vec{e}'_A \in \{0,1\}^{|A|}$, $\vec{e}'_{B_1} \in \{0,1\}^{|B_1|},.., \vec{e}'_{B_d} \in \{0,1\}^{|B_d|}$.
\item The verifier accepts if and only if $\vec{e},\vec{e}'$ and $W,W'$ satisfy the winning condition of $\rigid(\Sigma,m)$.
\end{enumerate}
\rule[2ex]{16.5cm}{0.5pt}\vspace{-.5cm}
\caption{Sequential version of $\rigid(\Sigma,m)$.}
\label{fig:consistency-game}
\end{figure} 




\subsection{Completeness}

\begin{lemma}\label{lem:leash-completeness}
Suppose the verifier executes the rigidity game with probability $p_r$ and the delegation game with probability $p_d=1-p_r$, on an input $(Q,\ket{\vec{x}})$ such that $\|\Pi_0 Q \ket{\vec{x}}\|^2 \geq 2/3$. Then there is a strategy for the provers which is accepted with probability at least $p_{\mathrm{compl}} = p_r(1-e^{-\Omega(n+t)}) + \frac{8}{9}p_d$. 
\end{lemma}

\begin{proof}
The provers $\pv$ and $\pp$ play the rigidity game according to the honest strategy, and the delegation game as described in Figures~\ref{fig:leash-protocol-PV} and~\ref{fig:leash-protocol-PP} respectively. Their success probability in the delegation game is the same as the honest strategy in the EPR Protocol, which is at least $\frac{2}{3}+\frac{2}{3}\frac{1}{3}=\frac{8}{9}$, by Theorem \ref{thm:EPR-correctness} and since in our protocol the verifier chooses each of the three types of rounds uniformly.
\end{proof}

\subsection{Soundness}



We divide the soundness analysis into three parts. First we analyze the case of an honest $\pv$, and a cheating $\pp$ (Lemma \ref{lem:soundness-leash-pp}). Then we show that if $\pv$ and $\pp$ pass the rigidity game with almost optimal probability, then one can construct new provers $\pv'$ and $\pp'$, with $\pv'$ honest, such that the probability that they are accepted in the delegation game is not changed by much (Lemma \ref{soundlemma}). In Lemma \ref{lem:leash-soundness}, we combine the previous to derive the desired constant soundness-completeness gap, where we exclude that the acceptance probability of the provers in the rigidity game is too low by picking a $p_r$ large enough.


\begin{lemma}[Soundness against $\pp$]\label{lem:soundness-leash-pp}
Suppose the verifier executes the delegation  game on input $(Q,\ket{\vec{x}})$ such that $\|\Pi_0 Q\ket{\vec{x}}\|^2 \leq 1/3$ with provers $(\pv,\pp^*)$ such that $\pv$ plays the honest strategy. Then the verifier accepts with probability at most $7/9$. 
\end{lemma}

\begin{proof}
Let $\pp^*$ be any prover. Assume that $\pv$ behaves honestly and applies the measurements specified by his query $W$ on halves of EPR pairs shared with $\pp^*$. As a result the corresponding half-EPR pair at $\pp^*$ is projected onto the post-measurement state associated with the outcome reported by $\pv$ to $\ver$. 


From $\pp^*$, we define another prover, $P^*$, such that if $P^*$ interacts with $V_{EPR}$,  the honest verifer for the EPR Protocol (Figure \ref{fig:original-protocol-VEPR}), then $V_{EPR}$ rejects with the same probability that $\ver$ would reject on interaction with $\pp^*$. The main idea of the proof can be seen by looking at Figure \ref{fig:leash-T-gadget}, and noticing that: (1) the combined action of $\ver$ and $\pv$ is unchanged if instead of choosing the $W_i$-values at random and then choosing $z_i$ as a function of these, the $z_i$ are chosen uniformly at random, and then the $W_i$ are chosen as a function of these; and (2) with this transformation, the combined action of $\ver$ and $\pv$ is now the same as the action of $V_{EPR}$ in the EPR Protocol. 

We now define $P^*$. $P^*$ acts on a system that includes $n+t$ qubits that, in an honest run of the EPR Protocol, are halves of EPR pairs shared with $V_{EPR}$. $P^*$ receives $\{{z}_i\}_{i=1}^t$ from $V_{EPR}$. $P^*$ creates $m-(n+t)$ half EPR pairs (i.e. single-qubit maximally mixed states) and randomly permutes these with his $n+t$ unmeasured qubits, $n$ of which correspond to computation qubits on systems ${\cal X}_1,\dots,{\cal X}_n$ --- he sets $N$ to be the indices of these qubits --- and $t$ of which correspond to $\sf T$-auxiliary states --- he sets $T^0$ and $T^1$ to be the indices of these qubits. $P^*$ simulates $\pp^*$ on these $m$ qubits in the following way. First, $P^*$ gives $\pp^*$ the index sets $N$, $T^0$, and $T^1$. In the $\ell$-th iteration of the loop (Step 2.\ in Figure~\ref{fig:leash-protocol-PP}), $\pp^*$ returns some bits $\{c_i\}_{i\in T_\ell}$, and then expects inputs $\{z_i\}_{i\in T_\ell}$, which $P^*$ provides, using the bits he received from $V_{EPR}$. Finally, at the end of the computation, $\pp^*$ returns a bit $c_f$, and $P^*$ outputs $\{c_i\}_{i\in T}$ and ${c_f}$. 

This completes the description of $P^*$. To show the lemma we argue that for any input $(Q,\ket{\vec{x}})$ the probability that $V$ outputs $\sf accept$ on interaction with $\pv$ and $\pp^*$ is the same as the probability that $V_{EPR}$ outputs $\sf accept$ on interaction with $P^*$, which is at most $\frac{2}{3}q_t+\frac{1}{3}q_c$ whenever $\|\Pi_0 Q \ket{\vec{x}}\|^2 \leq 1/3$, by Theorem \ref{thm:EPR-soundness}. Using $\delta=\frac{1}{3}$, Theorem \ref{thm:EPR-soundness} gives $q_c\leq \frac{5}{3}-\frac{4}{3}q_t$, which yields
$$\frac{2}{3}q_t+\frac{1}{3}q_c\leq \frac{5}{9}+\frac{2}{9}q_t\leq \frac{7}{9}.$$


There are two reasons that $V_{EPR}$ might reject: (1) in a computation or $X$-test round, the output qubit decodes to $1$; or (2) in an evaluation of the gadget in Figure \ref{fig:leash-T-gadget} (either an $X$-test round for an even $\sf T$ gate, or a $Z$-test round for an odd $\sf T$ gate) the condition ${c}_i=a_j\oplus e_i$ fails. 

We first consider case (1). This occurs exactly when ${c_f}\oplus a_f=1$, where $a_f$ is the final $\sf X$ key of the output wire, held by $V_{EPR}$. We note that $a_f$ is exactly the final $\sf X$ key that $\ver$ would hold in the Verifier-on-a-Leash Protocol, which follows from the fact that the update rules in both the EPR Protocol and the leash protocol are the same. Thus, the probability that $V_{EPR}$ finds ${v_f}\oplus a_f=1$ on interaction with $P^*$ is exactly the probability that $\ver$ finds $c_f\oplus a_f=1$ in Step 5 of Figure \ref{fig:leash-protocol-V}. 

Next, consider case (2). The condition ${c}_i\neq a_{j}\oplus e_i$ is exactly
 the condition in which a verifier interacting with $P^*$ as in Figure \ref{fig:leash-protocol-V} would reject (see Step 4.(b)).

Thus, the probability that $V_{EPR}$ outputs $\sf reject$ upon interaction with $P^*$ is exactly the probability that $\ver$ outputs $\sf reject$ on interaction with $\pp^*$, which, as discussed above, is at most $7/9$.
\end{proof}




%\begin{figure}[H]
%\rule[1ex]{16.5cm}{0.5pt}
%Let $\Sigma = \{X,Y,Z,F,G\}$.
%\begin{enumerate}
%\item The verifier selects $\vec{y} \in_R\Sigma^{m}$ and sends $\vec{y}$ to $\pv$. 
%\tnote{This is a placeholder since we discussed it, but I don't know what can be written there that would be useful, aside from copying the actual test. I'll put some comments inline instead.}
%\end{enumerate}
%\rule[2ex]{16.5cm}{0.5pt}\vspace{-.5cm}
%\caption{The Rigidity Game: Verifier's point of view \snote{fig:rigidity-V}}\label{fig:rigidity-V}
%\end{figure}

\noindent The following lemma shows soundness against cheating $\pv^*$.

\begin{lemma}\label{soundlemma}
Suppose the verifier executes the leash protocol  on input $(Q,\ket{\vec{x}})$ such that $\|\Pi_0 Q\ket{\vec{x}}\|^2 \leq 1/3$ with provers $(\pv^*,\pp^*)$, such that the provers are accepted with probability $1-\eps$, for some $\eps>0$, in the rigidity game, and with probability at least $q$ in the delegation game. Then there exist provers $\pp'$ and $\pv'$ such that $\pv'$ applies the honest strategy and $\pp'$ and $\pv'$ are accepted with probability at least $q-\poly(\eps)$ in the delegation game.
\end{lemma}

\begin{proof}
By assumption, $\pp^*$ and $\pv^*$ are accepted in the rigidity game with probability at least $1-\eps$. Let $V_A$, $V_B$ be the local isometries guaranteed to exist by Corollary~\ref{cor:clifford-rigid}, and $\{\tau_\lambda\}$ the sub-normalized densities associated with $\pp^*$'s Hilbert space (recall that playing the rigidity game sequentially leaves the guarantees from Corollary~\ref{cor:clifford-rigid} unchanged, since it only reduces the provers' ability to cheat).

First define provers $\pv''$ and $\pp''$ as follows. $\pp''$ and $\pv''$ initially share the state 
$$\ket{\psi'}_{\reg{AB}} = \otimes_{i=1}^{m} \proj{\EPR}_{\reg{AB}} \otimes \sum_{\lambda\in\{\pm\}}  \proj{\lambda}_{\reg{A}'}\otimes \proj{\lambda}_{\reg{B}'}\otimes (\tau_\lambda)_{\reg{A}''}\;,$$
with registers $\reg{A}\reg{A}'\reg{A}''$ in the possession of $\pp''$ and $\reg{BB}'$ in the possession of $\pv''$. 
Upon receiving a query $W\in \Sigma^m$, $\pv''$ measures $\reg{B}'$ to obtain a $\lambda\in\{\pm\}$. If $\lambda=+$ he proceeds honestly, measuring his half-EPR pairs exactly as instructed. If $\lambda=-$ he proceeds honestly except that for every honest single-qubit observable specified by $W$, he instead measures the complex conjugate observable. Note that this strategy can be implemented irrespective of whether $W$ is given at once, as in the game $\rigid$, or sequentially, as in the Delegation Game. $\pp''$ simply acts like $\pp^*$, just with the isometry $V_A$ applied. 

First note that by Corollary~\ref{cor:clifford-rigid}, the distribution of answers of $\pv''$ to the verifier, as well as the subsequent interaction between the verifier and $\pp$, generate (classical) transcripts that are within statistical distance $\poly(\eps)$ from those generated by $\pv^*$ and $\pp^*$ with the same verifier. 

Next we observe that taking the complex conjugate of both provers' actions does not change their acceptance probability in the delegation game, since the interaction with the verifier is completely classical. Define $\pp'$ as follows: $\pp'$ measures $\reg{A}'$ to obtain the same $\lambda$ as $\pv''$, and then executes $\pp''$ or its complex conjugate depending on the value of $\lambda$. Define $\pv'$ to execute the honest behavior (he measures to obtain $\lambda$, but then discards it and does not take any complex conjugates). 

Then $\pv'$ applies the honest strategy, and $(\pv',\pp')$ applies either the same strategy as $(\pv'',\pp'')$ (if $\lambda=+$) or its complex conjugate (if $\lambda=-$). Therefore they are accepted in the delegation game with exactly the same probability. 
\end{proof}

Combining Lemma~\ref{lem:soundness-leash-pp} and Lemma~\ref{soundlemma} gives us the final soundness guarantee.

\begin{lemma}\label{lem:leash-soundness} (Constant soundness-completeness gap)
There exist constants $p_r,p_d=1-p_r$ and $\Delta>0$ such that if the verifier executes the leash protocol with parameters $(p_r,p_d)$ on input $(Q,\ket{\vec{x}})$ such that $\|\Pi_0 Q\ket{\vec{x}}\|^2 \leq 1/3$, then any provers $(\pv^*,\pp^*)$ are accepted with probability at most $p_{\mathrm{sound}}=p_{\mathrm{compl}}-\Delta$.  
\end{lemma}

\begin{proof}
Suppose provers $\pp^*$ and $\pv^*$ succeed in the delegation game with probability $\frac79+w$ for some $w>0$, and the testing game with probability $1-\eps_*(w)$, where $\eps_*(w)$ will be specified below. By Lemma \ref{soundlemma}, this implies that there exist provers $\pp'$ and $\pv'$ such that $\pv'$ is honest and the provers succeed in the delegation game with probability at least $\frac79+w-g(\eps_*(w))$, where $g(\eps) = \poly(\eps)$ is the function from the guarantee of Lemma~\ref{soundlemma}. Let $\eps_*(w)$ be such that $g(\eps_*(w)) \leq \frac{w}{2}$. In particular, $\frac79+w-g(\eps_*(w)) \geq \frac79+\frac{w}{2}>\frac79$. This contradicts Lemma~\ref{lem:soundness-leash-pp}. 

Thus if provers $\pp$ and $\pv$ succeed in the delegation game with probability $\frac79+w$ they must succeed in the rigidity game with probability less than $1-\eps_*(w)$. 
This implies that for any strategy of the provers, on any \textit{no} instance, the probability that they are accepted is at most
\begin{equation}
\max\Big\{p_r+(1-p_r)\Big(\frac79+\frac{1}{18}\Big),\,\, p_r\Big(1-\eps_*\Big(\frac{1}{18}\Big)\Big)+(1-p_r)\cdot 1\Big\}.
\end{equation}
Since $\eps_*(\frac{1}{18})$ is a positive constant, it is clear that one can pick $p_r$ large enough so that 
\begin{equation}
p_r\Big(1-\eps_*\Big(\frac{1}{18}\Big)\Big)+(1-p_r)\cdot 1 < p_r+(1-p_r)\Big(\frac79+\frac{1}{18}\Big).
\end{equation}
Select the smallest such $p_r$. Then the probability that the two provers are accepted is at most 
\begin{align*}
p_{\mathrm{sound}} &:= p_r+(1-p_r)\Big(\frac79+\frac{1}{18}\Big)\\
&< p_r\big(1-e^{-\Omega(n+t)}\big)+(1-p_r)\frac89 \\
&= p_{\mathrm{compl}} \,,
\end{align*}
which gives the desired constant completeness-soundness gap $\Delta$.
\end{proof}

\subsection{Blindness}
\label{sec:leash-blind}

In this subsection, we establish blindness of the Verifier-on-a-Leash Protocol. We will actually prove that the protocol presented in this section has the property that neither prover can learn anything about the input to the circuit, $\vec{x}$, aside from its length. Thus, our protocol can be turned into a blind protocol, where $Q$ is also hidden, by modifying any input $(Q,\vec{x})$ where $Q$ has $g$ gates and acts on $n$ qubits, to an input $(U_{g,n},(Q,\vec{x}))$, where $U_{g,n}$ is a universal circuit that takes as input a description of a $g$-gate circuit $Q$ on $n$ qubits, and an input $\vec{x}$, and outputs $Q\ket{\vec{x}}$. The universal circuit $U_{g,n}$ can be implemented in $O(g\log n)$ gates. Running the Leash Protocol on $(U_{g,n},(Q,\vec{x}))$ reveals nothing about $Q$ or $\vec{x}$ aside from $g$ and $n$.

In the form presented in Figure~\ref{fig:leash-protocol-V}, the verifier $\ver$ interacts first with $\pv$, sending him random questions that are independent from the input $\vec{x}$, aside from the input length $n$. It is thus clear that the protocol is blind with respect to $\pv$. 

In contrast, the questions to $\pp$ depend on $\pv$'s answers and on the input, so it may a priori seem like the questions can leak information to $\pp$. To show that the protocol is also blind with respect to $\pp$, we show that there is an alternative formulation, in which the verifier first interacts with $\pp$, sending him random messages, and then only with $\pv$, with whom the interaction is now adaptive. We argue that, for an arbitrary strategy of the provers, the reduced state of all registers available to either prover, $\pp$ or $\pv$, is exactly the same in both formulations of the protocol --- the \emph{original} and the \emph{alternative} one. This establishes blindness for both provers. This technique for proving blindness is already used in~\cite{reichardt2012classical} to establish blindness of a two-prover protocol based on computation by teleportation. 


\begin{lemma}[Blindness of the Leash Protocol]
For any strategy of $\pv^*$ and $\pp^*$, the reduced state of $\pv^*$ (resp. $\pp^*$) at the end of the leash protocol
is independent of the input $\vec{x}$, aside from its length.
% depends only on the size of the input $(Q,\vec{x})$ to the computation. 
\end{lemma}

\begin{proof}
Let $\pv^*$ and $\pp^*$ denote two arbitrary strategies for the provers in the leash protocol. Each of these strategies can be modeled as a super-operator 
$$\mathcal{T}_\pv:\, \Lin(\mH_{T_\pv} \otimes \mH_\pv) \to \Lin(\mH_{T'_\pv} \otimes \mH_\pv), \qquad \mathcal{T}_{\pp,ad}: \,\Lin(\mH_{T_\pp} \otimes \mH_\pp) \to \Lin(\mH_{T'_\pp} \otimes \mH_\pp)$$
respectively. Here $\mH_{T_\pv}$ and $\mH_{T'_\pv}$ (resp.\ $\mH_{T_\pp}$ and $\mH_{T'_\pp}$) are classical registers containing the inputs and outputs to and from $\pv^*$ (resp.\ $\pp^*$), and $\mH_\pv$ (resp.\ $\mH_\pp$) is the private space of $\pv^*$ (resp.\ $\pp^*$). Note that the interaction of each prover with the verifier is sequential, and we use $\mathcal{T}_{\pv}$ and $\mathcal{T}_{\pp,ad}$ to denote the combined action of the prover and the verifier across all rounds of interaction (formally these are sequences of superoperators).

Consider an alternative protocol, which proceeds as follows. The verifier first interacts with $\pp$. From Figure~\ref{fig:leash-protocol-PP} we see that the inputs required for $\pp$ are subsets $N$ and $T_1,\ldots,T_d$, and values $\{z_i\}_{i\in T_\ell}$ for each $\ell\in\{1,\ldots,d\}$. To select the former, the verifier proceeds as in the first step of the Delegation Game. She selects the latter uniformly at random. The verifier collects values $\{c_i\}_{i\in T_\ell}$ from $\pp$ exactly as in the original Delegation Game. 

Once the interaction with $\pp$ has been completed, the verifier interacts with $\pv$. First, she selects a random string $W_N\in \Sigma^N$, conditioned on the event that $W_N$ contains at least $n$ copies of each symbol in $\Sigma$, and sends it to $\pv$, collecting answers $\vec{e}_N$. The verifier then follows the same update rules as in the delegation game. We describe this explicitly for computation rounds. First, the verifier sets $\vec{a} = \vec{e}_N$. Depending on the values $\{c_i\}_{i\in T_1}$ and $\{z_i\}_{i\in T_1}$ obtained in the interaction with $\pp$, using the equation $z_i = a_j + 1_{W_i=F}+c_i$ she deduces a value for $1_{W_i=F}$ for each $i\in T_1 \subseteq B_1$. She then selects a uniformly random $W_{B_1} \in \Sigma^{B_1}$, conditioned on the event that $W_{B_1}$ contains at least $t_1$ copies of each symbol from $\Sigma$, and for $i\in T_1$ it holds that $W_i=F$ if and only if $z_i = a_j + 1+c_i$. The important observation is that, if $T_1$ is a uniformly random, unknown subset, the marginal distribution on $W_{B_1}$ induced by the distribution described above is independent of whether $z_i = a_j + 1+c_i$ or $z_i = a_j + 0 +c_i$: precisely, it is uniform conditioned on the event that $W_{B_1}$ contains at least $t_1$ copies of each symbol from $\Sigma$. 
The verifier receives outcomes $\vec{e}_{B_1}\in \{0,1\}^{B_1}$ from $\pv$, and using these outcomes performs the appropriate key update rules; she then proceeds to the second layer of the circuit, until the end of the computation. Finally, the verifier accepts using the same rule as in the last step of the original delegation game. 

We claim that both executions of the protocol, original and alternative, generate the same joint final state: 
\begin{equation}\label{eq:super-states}
\mT_{\pp,ad}\circ\mT_\pv(\rho_{orig}) \,=\, \mT_{\pv,ad}\circ \mT_\pp(\rho_{alt}) \,\in\,  \mH_{\pp}\otimes \mH_{T'_{\pp}} \otimes \mH_\ver \otimes \mH_{T'_\pv} \otimes \mH_\pv,
\end{equation}
where we use $\rho_{orig}$ and $\rho_{alt}$ to denote the joint initial state
  of the provers, as well as the verifier's initialization of her workspace, in
  the original and alternative protocols respectively, and $\mT_{\pv,ad}$ and $\mT_\pp$ are the equivalent of $\mT_\pv$ and $\mT_{\pp,ad}$ for the reversed protocol (in particular they correspond to the same strategies $\pv^*$ and $\pp^*$ used to define $\mT_\pv$ and  $\mT_{\pp,ad}$). Notice that $\mT_{\pv,ad}$ and $\mT_\pp$ are well-defined since neither prover can distinguish between an execution of the original and the alternative protocol.\footnote{One must ensure that a prover does not realize if the  alternative protocol is executed instead of the original; this is easily enforced by only interacting with any of the provers at specific, publicly decided times.}
To see that the equality \eqref{eq:super-states}
  holds, it is possible to re-write the final state of the protocol as the
  result of the following sequence of operations. First, the verifier
  initializes the message registers with $\pp^*$ and $\pv^*$ using half-EPR
  pairs, keeping the other halves in her private workspace. This simulates the
  generation of uniformly random messages to both provers. Then, the
  superoperator $\mT_\pv \otimes \mT_\pp$ is executed. Finally, the verifier
  post-selects by applying a projection operator on $\mH_{T_\pv} \otimes \mH_{T'_\pv} \otimes \mH_{T_\pp} \otimes \mH_{T'_\pp}$ which projects onto valid transcripts for the
  original protocol (i.e. transcripts in which the adaptive questions are chosen
  correctly). This projection can be implemented in two equivalent ways: either
  the verifier first measures $ \mH_{T_\pv} \otimes \mH_{T'_\pv}$, and then
  $\mH_{T_\pp} \otimes \mH_{T'_\pp}$; based on the outcomes she accepts a valid transcript for the
  original protocol or she rejects. Or, she first measures $ \mH_{T_\pp} \otimes \mH_{T'_\pp}$, and then
  $\mH_{T_\pv} \otimes \mH_{T'_\pv}$; based on the outcomes she accepts a
  valid transcript for the alternative protocol or she rejects. Using the
  commutation of the provers' actions, conditioned on the transcript being
  accepted, the first gives rise to the first final state
  in~\eqref{eq:super-states}, and the second to the second final state. The two are equivalent because the acceptance condition for a valid transcript is identical in the two versions of the protocol.

Since in the first case the reduced state on $\mH_{T'_{\pv}} \otimes \mH_\pv$ is independent of the input to the computation, $\vec{x}$, and in the second  the reduced state on $ \mH_\pp\otimes \mH_{T'_{\pp}} $ is independent of $\vec{x}$, we deduce that the protocol is hides the input from each of $\pv^*$ and $\pp^*$. 
\end{proof}

%\snote{begin note}
%
%I don't really see how this proof gets around the following attack. Suppose $x$ is a single bit input, and $Q$ consists of a single $\sf T$ gate. Let's suppose $m=2$, since I don't see why this would break the proof. Then let's post-select on $\pv$ being asked to measure the first qubit, which we'll take as the computation qubit, in the $Z$ basis, and the second qubit, the auxiliary, in either $G$ or $F$. 
%
%Now suppose $\pv$ cheats in the following way. He performs the correct measurements, but he doesn't return the correct results. His first measurement, in the $Z$ basis, is a random bit that we will interpret as $a\oplus x$. Instead of returning this to $\ver$, he sends $a\oplus x\oplus 1_{W_2=F}$, so $\ver$ learns the wrong value $\tilde{a}=a\oplus 1_{W_2=F}$ instead of $a$. For the other measurement he can return the correct result, it doesn't really matter. 
%
%Now, $\pp$ is supposed to apply the $\sf T$ gadget, but instead, he does nothing to his computation wire, which is in the state $\ket{a\oplus x}$, and sends $\ver$ a random value $c$. $\ver$ returns $\tilde{a}\oplus c\oplus 1_{W_2=F}=a\oplus c$, from which $\pp$ learns $a$, which he uses to decode $\ket{x\oplus a}$, recovering $x$.
%
%
%Trying to apply the reasoning of the proof to this particular scenario, we get the following. $\ver$ first interacts with $\pp$, although $\pp$ doesn't know that. So $\pp$ still just sends a random $c$, and gets back a random value $z$, which he will attempt to use to decode the input wire. Now $\ver$ interacts with $\pv$. There is a difference though. $\pv$ cannot do both measurements simultaneously, because his second measurement, $W_2\in\{G,F\}$, depends on the outcome of his first measurement, $a\oplus x$, as well as $x$, which $\pv$ does not know. So the only way to accomplish this reversed protocol is for $\ver$ to first receive the measurement result $a\oplus x$ (or some $\tilde{a}\oplus x$ if $\pv$ is dishonest) and then, depending on that, tell $\pv$ what to do for the second measurement. In that modified protocol, $\pv$ can't accomplish the attack, because it depends on making the first returned outcome depend on $W_2$. 
%
%Our actual protocol rules out this attack in the following way: let $m=3$, and post-select on $W=(Z,G,F)$. Again, the first wire is the computation wire, but now the auxiliary wire is either the second or third, chosen uniformly at random (as it would be in our protocol). Now the attack doesn't work, and maybe the protocol can be reversed (I don't quite see this...). I don't see how the proof distinguished between these two cases. Is it implicitly coming from our assumption that the protocol can be reversed? In that case, maybe we should add a discussion about why the protocol can be reversed (but only the way we have implemented it with $\pv$ doing a random $W\in\Sigma^m$, as opposed to the more naive way, where we just have $\pv$ do $n+t$ measurements that $\ver$ chooses for him). 
%
%At the moment, it seems suspiciously obvious to me that our protocol is blind. It seems that $\pv$ is essentially choosing a uniform random string $\vec{y}\in\{0,1\}^t$, determining the value of $W_i\in\{G,F\}$ for all $i\in T$. This string is uniform random, and independent of $T$ and $N$, and it results in the string $\vec{z}\in\{0,1\}^t$ being uniform random and independent of $T$ and $N$, so everything $\pp$ receives is uniform random. Is this true? Seems too simple.
%
%\snote{end note}
%

%===============================%
\section{The Dog-Walker Protocol}
\label{sec:dog-walker}
%===============================%






\subsection{Protocol and statement of results}

The Dog-Walker Protocol again involves a classical verifier and two provers $\pv$ and $\pp$. As in the leash protocol presented in Section \ref{sec:leash}, $\pp$ and $\pv$ take the roles of $P_{EPR}$ and $V_{EPR}$ from \cite{broadbent15howtoverify} respectively. 
The main difference is that the Dog-Walker Protocol gives up blindness in order to reduce the number of rounds to two (one round of interaction with each prover, played sequentially). After an initial round of communication with $\pp$, who returns a sequence of measurement outcomes, the verifier $\ver$ communicates all of $\pp$'s outcomes, except for the one corresponding to the output bit of the computation, as well as the input $\vec{x}$ of the computation, to $\pv$.  Using these, $\pv$ can perform the required adaptive measurements without the need to interact with the verifier.  It may seem quite risky to communicate bits sent by $\pp$ directly to $\pv$ --- this seems to allow for communication between the two provers! Indeed, blindness is lost. However, if $\pp$ is honest, his outcomes $\{c_i\}_i$ in the computation round are the result of measurements he performs on half-EPR pairs, and are uniform random bits. If he is dishonest, and does not return the outcomes  obtained by performing the right measurements, he will be caught in the test rounds. It is only in computation rounds that $\ver$ sends the measurement results $\{c_i\}_i$ to $\pv$. 

%This protocol reproduces the EPR protocol of \cite{broadbent15howtoverify} with
%$\pp$ taking the same role as $P_{EPR}$ and $\pv$ taking the role
%of $V_{EPR}$. For this, the Verifier in the dogwalker protocol, reveal to $\pv$ the input
%and all $\pp$'s measurement outcomes. In this way, if $\pv$ is honest, he can
%adaptively choose the right basis to create the $\sf T$-gadgets.

To guarantee that $\pv$ behaves honestly, we combine the rigidity test $\rigid(\Sigma,m)$ from Section~\ref{sec: RIGID test} with the tomography test $\tom(\Sigma,n+t,m)$ from Section~\ref{subsec:tomography}. Part of the latter test requires $\pv$ to announce
what measurements he has performed and the corresponding outcomes he obtained. He has to do so honestly in order to pass the test.

Throughout this section we let $\Sigma=\{X,Y,Z,F,G\}$, and let $m=\Theta(n+t)$ be chosen large enough so that each symbol in $\Sigma$ appears at least $n+t$ times in a uniform random $W\in\Sigma^m$, with probability close to $1$.
Let $\mu({W})$ denote the probability that a player receives input ${W}$ while playing $\rigid(\Sigma,m)$ (recall that both players have the same marginals in $\rigid$). Let $\mu({W}'|{W})$ denote the probability that one player receives ${W}'$ given that the other player receives~${W}$. %For $W\in\Sigma^m$ and some subset $S\subset \{1,\ldots,m\}$, let $\mu|_{\Sigma}(W_S)=\sum_{W'\in\Sigma^m:W'_S=W_S}\mu(W')$ denote the probability that a player in $\rigid$ receives an input that is equal to $W_S$ on $S$. 

%We will use the fact \snote{proven somewhere}\tnote{this is obvious from the description of the test, so I reformulated a bit} that for $S\subset \{1,\ldots,m\}$ of size $|S|=n+t$, the value $M=\max_{W\in\Sigma^m}\frac{1}{|\Sigma|^{|S|}\mu(W_S)}$, which is independent of $S$, is a constant independent of $m$ (from the description of the test in Figure~\ref{fig:rigid} it is clear the constant is at least $1/2$). This will allow us to begin with a sample $W$ chosen according to $\mu$, and only perform the test $\tom(\Sigma,n+t)$ on $W_S$ with probability $1/(M|\Sigma|^{n+t}\mu(W_S))$, so that, by rejection sampling, we are actually performing the test $\tom(\Sigma,n+t)$ with uniformly distributed inputs $W_S$, and the probability we perform the test $\tom$ is only reduced by a multiplicative constant $1/M$. We call this test $\tom'$, and recall its soundness properties in Lemma \ref{lem:rejection-sampled-tom}.

The full protocols are presented in Figure \ref{fig:dogwalker-protocol-V} (verifier's point of view), Figure \ref{fig:dogwalker-protocol-PV} ($\pv$'s point of view) and Figure \ref{fig:dogwalker-protocol-PP} ($\pp$'s point of view). The protocol has two types of rounds: EPR and Rigidity. Within an EPR round are three types of sub-rounds: Computation sub-round, $X$-test sub-round, and $Z$-test sub-round. We will generally think of $X$- and $Z$-test sub-rounds as one sub-round type (Test sub-round). Within a Rigidity round are two types of sub-rounds: Tomography sub-round, which should be thought of as the Rigidity version of the EPR-Computation round; and Clifford sub-round, which should be thought of as the Rigidity version of the EPR-Test round. With some probability $p_1$, $\ver$ runs a Rigidity round, Clifford sub-round; with some probability $p_2$, $\ver$ runs an EPR round, Test sub-round; with some probability $p_3$, $\ver$ runs an EPR round, Computation sub-round; and with probability $p_4=1-p_1-p_2-p_3$, $\ver$ runs a Rigidity round, Tomography sub-round. We call this the Dog-Walker Protocol with parameters $(p_1,p_2,p_3,p_4)$.


The following theorem states the guarantees of the Dog-Walker Protocol.

\begin{theorem}\label{thm:dog-walker}
There exist constants $p_1$, $p_2$, $p_3$, $p_4=1-p_1-p_2-p_3$, and $\Delta>0$ such that the following hold of the Dog-Walker Protocol with parameters $(p_1,p_2,p_3,p_4)$, when executed on input $(Q,\ket{\vec{x}})$.
\begin{itemize}
\item (Completeness: ) Suppose that $\norm{\Pi_0Q\ket{\vec{x}}}^2\geq 2/3$. Then
  there is a strategy for $\pv$ and $\pp$ that is accepted with probability at
    least $p_{\mathrm{compl}}=p_1(1-e^{-\Omega(n+t)})+p_2+\frac{2}{3}p_3 +
    p_4$. 
\item (Soundness: ) Suppose that $\norm{\Pi_0Q\ket{\vec{x}}}^2\leq 1/3$. Then any strategy for $\pv$ and $\pp$ is accepted with probability at most $p_{\mathrm{sound}}=p_{\mathrm{compl}}-\Delta$. 
\end{itemize}
\end{theorem}
The proof of the completeness property is given in Lemma \ref{lem:dogwalker-completeness}, and the soundness property is given in Lemma \ref{lem:dogwalker-soundness}. 

%----------------%
\begin{figure}[H]
\rule[1ex]{16.5cm}{0.5pt}
\vspace{-20pt}
%\raggedright
\justify
 %Suppose the circuit to be performed is broken into $d$ layers, each with some Clifford computation, followed by at most one $\sf T$ gate per wire. Let $t$ be the total number of $\sf T$ gates in the circuit, with $t_0$ the number of even $\sf T$ gates (as defined in Section \ref{sec:EPR-protocol}). Let $\Sigma = \{X,Y,Z,F,G\}$.\\[5pt]
%\begin{enumerate}
1. Select a random round type \textbf{EPR} or \textbf{Rigidity}, and disjoint sets $N,T^0,T^1\subset \{1,\ldots,m\}$ of sizes $n$, $t_0$ and $t-t_0$.  
\begin{description}
\item[EPR] Choose $\vec{z}$ uniformly at random from $\{0,1\}^t$ and send it, along with $N$, $T^0$ and $T^1$, to $\pp$. Receive measurement outcomes $\vec{c}\in\{0,1\}^t$ and $c_f\in\{0,1\}$ from $\pp$.
\item[Rigidity] Choose $W'$ according to $\mu(\cdot)$ and send it to $\pp$. Receive $\vec{e}'\in \{0,1\}^m$ from $\pp$. 
\end{description}
2. Select a sub-round type at random from \textbf{Computation}, \textbf{X Test} or \textbf{Z Test}. 
\begin{description}
\item[Computation] Based on whether it's an \text{EPR} or a \text{Rigidity} Round:
	\begin{description}
	\item[EPR]
		\begin{enumerate}
		\item[(i)] Send $\vec{x}$, $\vec{z}$, $\vec{c}$ and sets $N$, $T^0$ and $T^1$ to $\pv$, and receive measurement outcomes $\vec{a},\vec{b}\in \{0,1\}^n$ and $\vec{e}\in\{0,1\}^t$.
		\item[(ii)] Apply the update rules from Table \ref{tab:EPR-key-updates} gate-by-gate to obtain the final $\sf X$ key for the output wire $a_f'$. If $c_f+a_f'\neq 0$, $\sf reject$. %Otherwise $\sf accept$.
		\end{enumerate}
	\item[Rigidity (Tomography)]
		\begin{enumerate}
		\item[(i)] Choose uniform random strings $\vec{c},\vec{z}\in\{0,1\}^t$, $\vec{x} \in \{0,1\}^n$ %\snote{or according to the marginals of the tomography game specified by the questions $\vec{y}'$ sent to $\pp$. I don't know if this is uniform.} 
		to send to $\pv$, along with $N$ and $T$, and receive measurement outcomes $\vec{d}\in \{0,1\}^n$ and $\vec{e}\in\{0,1\}^t$. 
		\item[(ii)]
		From $\vec{x}$, $\vec{c}$, $\vec{z}$, $\vec{d}$, and $\vec{e}$, determine the adaptive measurements $W\in\Sigma^{n+t}$ that $V_{EPR}^0$ would have performed (based on Figure \ref{fig:original-protocol-VEPRr}), and $\sf reject$ if the input-output pairs $(W',\vec{e}')$ and $(N\cup T,(W,\vec{e}))$ do not satisfy the winning criterion for $\tom(\Sigma,n+t,m)$.
		\end{enumerate}
	\end{description}
\item[$X$-Test] Based on whether it's an \text{EPR} or a \text{Rigidity} Round:
\begin{description}
	\item[EPR] 
	\begin{enumerate}
		\item[(i)] Choose $W\in\Sigma^m$ uniformly at random among all strings satisfying: $W_i=Z$ for all $i\in N$; $W_i=Z$ for all $i\in T^0$; and $W_i\in\{X,Y\}$ for all $i\in T^1$. Send $W$ to $\pv$ and receive measurement results $\vec{e}\in\{0,1\}^m$. Let $(\vec{a},\vec{b})=(\vec{e}_N,0^n)$. 
		\item[(ii)] Apply update rules from Table \ref{tab:EPR-key-updates} gate-by-gate to obtain $\forall i\in [t]$ the $\sf X$ key before the $i$-th $\sf T$ gate is applied, $a_i'$, and the final $\sf X$ key for the output wire, $a_f'$. 
If $\exists i$ s.t.\ the $i$-th $\sf T$ gate is even and $c_i\neq a_i'+e_i$, $\sf reject$. If $c_f+a_f'\neq 0$, $\sf reject$. %Else $\sf accept$.
%		\item[(iii)] Use the values $\vec{e}_{T^0\cup T^1}$, $\vec{c}$ and $\vec{a}$ to perform the key updates for each step of the computation according to Table \ref{tab:EPR-key-updates} in order to get the final $\sf X$ key for the output wire, $a_f$. Reject if $a_f\oplus c_f\neq 0$. 
	\end{enumerate}
	\item[Rigidity (Clifford)] Choose ${W}$ according to the marginal conditioned on ${W}'$, $\mu(\cdot|{W}')$. %\snote{or according to the marginals of the Clifford game, specified by $\vec{y}'$}
	Send ${W}$ to $\pv$ and receive $\vec{e}\in\{0,1\}^m$. Reject if   $({W}',\vec{e}',{W},\vec{e})$ doesn't win $\rigid(\Sigma,m)$. 
\end{description}

\item[$Z$-Test] Based on whether it's an \text{EPR} or a \text{Rigidity} Round:
\begin{description}
	\item[EPR] 
	\begin{enumerate}
		\item[(i)] Choose $W\in\Sigma^m$ uniformly at random among all strings satisfying: $W_i=X$ for all $i\in N$; $W_i\in\{X,Y\}$ for all $i\in T^0$; and $W_i=Z$ for all $i\in T^1$. Send $W$ to $\pv$ and receive measurement results $\vec{e}\in\{0,1\}^m$. Let $(\vec{a},\vec{b})=(0^n,\vec{e}_N)$.
		\item[(ii)] Apply update rules from Table \ref{tab:EPR-key-updates} gate-by-gate to obtain $\forall i\in [t]$, the $\sf X$ key before the $i$-th $\sf T$ gate is applied, $a_i'$. 
If $\exists i$ s.t.\ the $i$-th $\sf T$ gate is odd and $c_i\neq a_i'+e_i$, $\sf reject$. %Else $\sf accept$.
	\end{enumerate}
	\item[Rigidity (Clifford)] Identical to $X$-Test case.%Choose $W$ according to the marginal conditioned on $W'$, $\mu(\cdot|W')$. Send $W$ to $\pv$ and receive $\vec{e}\in\{0,1\}^m$. Reject if  $(W',\vec{e}',W,\vec{e})$ doesn't win $\rigid(\Sigma,m)$. 
\end{description}
\end{description}
%\end{enumerate}
\rule[2ex]{16.5cm}{0.5pt}\vspace{-.5cm}
\caption{The Dog-Walker Protocol: Verifier's point of view.}\label{fig:dogwalker-protocol-V}
\end{figure}


\begin{figure}[H]
\rule[1ex]{16.5cm}{0.5pt}
\vspace{-20pt}
\begin{enumerate}
  \item If $\pp$ receives a question ${W}'$ from $\ver$ (he is playing $\tom$ or $\rigid$):
\begin{enumerate}
     \item[]  Measure the $m$ qubits in the observable indicated by $W'$ --- for example, if $W'\in\Sigma^m$, for $i\in \{1,\ldots,m\}$, measure the $i$-th qubit in the basis indicated by $W_i'$ --- and report
       the outcomes $\vec{e}'$ to~$\ver$.
\end{enumerate}
\item If $\pp$ receives $\vec{z}$, and sets $N$, $T^0$ and $T^1$ from $\ver$ (he is playing the role of $P_{EPR}$ from the EPR Protocol):
\begin{enumerate}
     \item[] Run the prover $P_{EPR}$ from Figure \ref{fig:original-protocol-PEPR} on input $\vec{z}$, the $n$ qubits in $N$, and the $t$ qubits in $T^0\cup T^1$.
     Report the outputs $\vec{c}\in\{0,1\}^t$ and $c_f\in\{0,1\}$ of $P_{EPR}$  to $\ver$. %measurement outcomes $\vec{c}\in\{0,1\}^t$ of the $\sf T$ gadgets and the measurement of the output qubit $c_f$.
\end{enumerate}
\end{enumerate}
\rule[2ex]{16.5cm}{0.5pt}\vspace{-.5cm}
\caption{The Dog-Walker Protocol: Honest strategy for $\pp$.}\label{fig:dogwalker-protocol-PP}
\end{figure}


\begin{figure}[H]
\rule[1ex]{16.5cm}{0.5pt}
\vspace{-20pt}
\begin{enumerate}
  \item If $\pv$ receives a question ${W}$ from $\ver$ (he is playing $\rigid$ or an $X$- or $Z$-Test Round):
\begin{enumerate}
     \item[]  Measure the $m$ qubits in the observable indicated by $W$ --- for example, if $W\in \Sigma^m$, for $i\in \{1,\ldots,m\}$, measure the $i$-th qubit in the basis indicated by $W_i$ --- and report the outcomes $\vec{e}$ to $\ver$.
\end{enumerate}

  \item If $\pv$ receives $\vec{x}$, $\vec{z}$, $\vec{c}$ and sets $N$, $T^0$ and $T^1$ from $\ver$ (he is playing $\tom$ or a Computation Round):
\begin{enumerate}
	\item[] Run the procedure $V_{EPR}^0$ from Figure \ref{fig:original-protocol-VEPRr} on input $\vec{x}$, $\vec{c}$, $\vec{z}$, the $n$ qubits in $N$, and the $t$ qubits in $T^0\cup T^1$. Report the outputs  $\vec{d}$ and $\vec{e}$ of $V_{EPR}^0$ to $\ver$.
\end{enumerate}
\end{enumerate}
\rule[2ex]{16.5cm}{0.5pt}\vspace{-.5cm}
\caption{The Dog-Walker Protocol: Honest strategy for $\pv$.}\label{fig:dogwalker-protocol-PV}
\end{figure}


\subsection{Completeness}

\begin{lemma}\label{lem:dogwalker-completeness}
Suppose $\ver$ executes the Dog-Walker Protocol with parameters $(p_1,p_2,p_3,p_4)$.
There is a strategy for the provers such that, on any input $(Q,\ket{\vec{x}})$
  such that $\norm{\Pi_0 Q\ket{\vec{x}}}^2\geq \frac{2}{3}$, $\ver$ accepts with
  probability at least
  $p_{\mathrm{compl}}=p_1(1-\delta_c)+p_2+\frac{2}{3}p_3+p_4$, for some $\delta_c = e^{-\Omega(n+t)}$.
\end{lemma}

\begin{proof}
The provers $\pv$ and $\pp$ play the strategy described in Figures
  \ref{fig:dogwalker-protocol-PV} and \ref{fig:dogwalker-protocol-PP}
  respectively. In the Rigidity-Tomography round, the verification performed by
  $\ver$ amounts to playing $\tom(\Sigma,n+t,m)$ with the provers (with an extra
  constraint on the output $W$ of $\pv$ that is always satisfied by the honest
  strategy). This game has perfect
  completeness, which makes the $\ver$
  accept with probability $1$ in the Rigidity-Tomography round.
  In the Rigidity-Clifford round, $\ver$ plays $\rigid(\Sigma,m)$
  with the provers. The game
  has completeness at least $1-\delta_c$ for some $\delta_c=e^{-\Omega(n+t)}$,
  since $m=\Omega(n+t)$, therefore their success probability in this round is
  at least $1-\delta_c$.

In the EPR round, the provers are exactly carrying out the EPR Protocol, with $\ver$ using $\pv$ to run $V_{EPR}^r$, and $\pp$ playing the role of $P_{EPR}$. Thus, test rounds result in acceptance with probability $1$, and the computation round results in acceptance with probability $\norm{\Pi_0 Q\ket{\vec{x}}}^2$, by Theorem \ref{thm:EPR-correctness}. 
\end{proof}


\subsection{Soundness}

Figure~\ref{fig:full-dog-walker} summarizes the high-level structure of the soundness analysis. Intuitively, our ultimate goal is to argue that both provers either apply the correct operations in EPR-Computation rounds, or are rejected with constant probability. This will be achieved by employing a form of ``hybrid argument'' whereby it is argued that the provers, if they are not caught, must be using the honest strategies described in Figure~\ref{fig:dogwalker-protocol-PP} and Figure~\ref{fig:dogwalker-protocol-PV} in the different types of rounds considered in the protocol. Towards this, we divide the round types into the following four scenarios:
\begin{enumerate}
\item Rigidity-Clifford: The round type is \textbf{Rigidity} and the sub-round type is either \textbf{$X$-Test} or \textbf{$Z$-Test}. (When the provers are honest) $\pv$ behaves as in Item 1 of Figure \ref{fig:dogwalker-protocol-PV}, and $\pp$ behaves as in Item 1 of Figure \ref{fig:dogwalker-protocol-PP}. 
\item EPR-Test: The round type is \textbf{EPR} and the sub-round type is either \textbf{$X$-Test} or \textbf{$Z$-Test}. $\pv$ behaves as  in Item 1 of Figure \ref{fig:dogwalker-protocol-PV}, and $\pp$ behaves as in Item 2 of Figure \ref{fig:dogwalker-protocol-PP}. 
\item EPR-Computation: The round type is \textbf{EPR} and the sub-round type is \textbf{Computation}. $\pv$ behaves as in Item 2 of Figure \ref{fig:dogwalker-protocol-PV}, and $\pp$ behaves as in Item 2 of Figure \ref{fig:dogwalker-protocol-PP}. 
\item Rigidity-Tomography: The round type is \textbf{Rigidity} and the sub-round type is \textbf{Computation}. $\pv$ behaves as in Item 2 of Figure \ref{fig:dogwalker-protocol-PV}, and $\pp$ behaves as in Item 1 of Figure \ref{fig:dogwalker-protocol-PP}. 
\end{enumerate}
Examining Figure \ref{fig:dogwalker-protocol-V}, we can see the following. In the Rigidity-Clifford scenario, the verifier is precisely playing the game $\rigid$ with the provers, as the provers receive questions $W'$ and $W$ distributed according to $\mu(\cdot,\cdot)$, the distribution of questions for $\rigid(\Sigma,m)$; their answers are tested against the winning conditions of $\rigid(\Sigma,m)$. In the Rigidity-Tomography scenario, the verifier plays a variant of the game $\tom$ with the provers, in which $\pv$'s choice of observable $W$ is uniquely determined by his inputs $\vec{x}$, $\vec{c}$ and $\vec{z}$: it should match the observable implemented by $V_{EPR}^0$ on these inputs. In EPR rounds, $\pv$ plays the part of $V_{EPR}^r$ from the EPR Protocol, and $\pp$ play the part of $P_{EPR}$. The EPR-Test scenario corresponds to $X$- and $Z$-tests from the EPR Protocol, whereas the EPR-Computation scenario corresponds to computation rounds from the EPR Protocol.


\begin{figure}[H]
\centering
\begin{tikzpicture}
\filldraw[thick, fill=blue!30!white] (0,6) circle (.3);
\filldraw[thick, fill=blue!30!white] (0,4.5) circle (.3);
\filldraw[thick, fill=green!30!white] (0,3) circle (.3);
\filldraw[thick, fill=green!30!white] (0,1.5) circle (.3);

\filldraw[thick, fill=red!30!white] (4,6) circle (.3);
\filldraw[thick, fill=orange!30!white] (4,4.5) circle (.3);
\filldraw[thick, fill=orange!30!white] (4,3) circle (.3);
\filldraw[thick, fill=red!30!white] (4,1.5) circle (.3);

\node at (0,6) {1};
\node at (4,6) {1};
\node at (0,4.5) {2};
\node at (4,4.5) {2};
\node at (0,3) {3};
\node at (4,3) {3};
\node at (0,1.5) {4};
\node at (4,1.5) {4};

\draw[ultra thick, ->, blue!30!white] (0,5.7)--(0,4.8);
\draw[ultra thick, ->, green!30!white] (0,1.8)--(0,2.7);
\path[ultra thick, ->, orange!30!white] (4,4.2) edge (4,3.3);
\path[ultra thick, ->, red!30!white] (4,5.7) edge[bend left] (4,1.8);

\draw[ultra thick, <->] (.3,6)--(3.7,6);
\draw[ultra thick, ->] (.3,4.5)--(3.7,4.5);
\draw[ultra thick, <-] (.268,3.134)--(3.732,4.366);
\draw[ultra thick, <-] (.3,1.5)--(3.7,1.5);

\node at (2,6.25) {$\rigid$ Test};
\node at (2,4.75) {Soundness of EPR};
\node [rotate=18.5] at (2.1,3.45) {Uniformity of $\{c_i\}_i$};
\node at (2,1.75) {$\tom$ Test};

\draw[thick] (8,6) circle (.3);
\node at (8,6) {1};
\node at (9.85,6) {Rigidity-Clifford};

\draw[thick] (8,4.5) circle (.3);
\node at (8,4.5) {2};
\node at (9.27,4.5) {EPR-Test};

\draw[thick] (8,3) circle (.3);
\node at (8,3) {3};
\node at (9.95,3) {EPR-Computation};

\draw[thick] (8,1.5) circle (.3);
\node at (8,1.5) {4};
\node at (10.2,1.5) {Rigidity-Tomography};

\node at (0,7) {\pv};
\node at (4,7) {\pp};

\draw (1.8,5.9) rectangle (2.2,5.5);
\node at (2,5.7) {\small i};

\draw (-.5,5.05) rectangle (-.1,5.45);
\node at (-.3,5.25) {\small ii};

\draw (4.65,3.55) rectangle (5.05,3.95);
\node at (4.85,3.75) {\small iii};

\draw (1.8,4.0) rectangle (2.2,4.4);
\node at (2,4.2) {\small iv};

\draw (4.05,3.95) rectangle (4.45,3.55);
\node at (4.25,3.75) {\small vii};

\draw (1.2,3.95) rectangle (.8,3.55);
\node at (1,3.75) {\small iv};

\draw (1.8,1.05) rectangle (2.2,1.45);
\node at (2,1.25) {\small v};

\draw (-.5,2.0) rectangle (-.1,2.4);
\node at (-.3,2.2) {\small vi};

%\draw (8.5,6.5)--(8.5,0);

\end{tikzpicture}
\caption{Overview of the soundness of the Dog-Walker Protocol}\label{fig:full-dog-walker}
\end{figure}

\noindent The structure of the proof is as follows (see also Figure~\ref{fig:full-dog-walker}):
\begin{enumerate}
\item[(i)] By the game $\rigid$, in the Rigidity-Clifford rounds, both $\pp$ and $\pv$ must be honest, or they would lose the game.
\item[(ii)] Since $\pv$ can't distinguish between Rigidity-Clifford and EPR-Test (both are Figure \ref{fig:dogwalker-protocol-PV} Item 1 from his perspective, and the input distributions, while not identical, are within constant total variation distance), $\pv$ must be honest in the EPR-Test rounds, by (i). 
\item[(iii)] Since $\pp$ can't distinguish between Rigidity-Clifford and Rigidity-Tomography (both are Figure~\ref{fig:dogwalker-protocol-PP} Item 1 from his perspective), $\pp$ must be honest in the Rigidity-Tomography rounds, by~(i). 
\item[(iv)] Since $\pv$ is honest in EPR-Test rounds by (ii), $\pp$ must be honest in EPR-Test rounds or he will get caught, but in particular, he must output values $\{c_i\}_{i\in [t]}$ that are uniform random and independent of $\vec{z}$. Since $\pp$ can't distinguish between EPR-Test and EPR-Computation rounds, this is also true in EPR-Computation rounds, when the verifier sends the values $\{c_i\}_i$ to $\pv$. 
\item[(v)] %Since $\pp$ is honest in Rigidity-Tomography Rounds by [iii], 
$\pv$ must be honest in Rigidity-Tomography rounds, or the provers would lose the game $\tom$.
\item[(vi)] Since $\pv$ can't distinguish between Rigidity-Tomography rounds and EPR-Computation rounds (both are Figure \ref{fig:dogwalker-protocol-PV} Item 2 from his perspective), $\pv$ must be honest in EPR-Computation rounds, by~(v), and his input distribution to both rounds is within constant total variation distance, by (iv).
\item[(vii)] Since $\pv$ is honest in EPR-Test rounds by (ii), and EPR-Computation rounds by (vi), the combined behavior of $\ver$ and $\pv$ in the EPR rounds is that of $V_{EPR}$ in the EPR Protocol, so
by the soundness of the EPR Protocol, $\pp$ must be honest in EPR-Computation rounds, or get caught in the EPR-Test rounds with high probability.
\end{enumerate}

 The following lemma establishes (i), (ii) and (iii). 

\begin{lemma}\label{lem:PV-2-PP-4}
Suppose the verifier executes the Dog-Walker Protocol %on input $(Q,\ket{\vec{x}})$ such that $\norm{\Pi_0 Q\ket{\vec{x}}}^2\leq 1/3$, 
with provers $(\pv^*,\pp^*)$ such that the provers are accepted with probability $q_1\geq 1-\eps$ in the Rigidity-Clifford Round, $q_2$ in the EPR-Test Round, $q_3$ in the EPR-Computation Round, and $q_4$ in the Rigidity-Tomography Round. Then there exist provers $(\pv',\pp')$ such that:
\begin{itemize}[nolistsep]
\item $\pv'$ and $\pp'$ both apply the honest strategy in the Rigidity-Clifford rounds, $\pv'$ applies the honest strategy in the EPR-Test rounds, and $\pp'$ applies the honest strategy in the Rigidity-Tomography rounds; in particular, the state shared by the provers at the beginning of the protocol is a tensor product of the honest state consisting of $m$ shared EPR pairs and an arbitrary shared ancilla;
\item The provers are accepted with probability $q_2'=q_2-O(\mathrm{poly}(\eps))$ in the EPR-Test Round, $q_3'=q_3$ in the EPR-Computation Round, and $q_4'=q_4-O(\mathrm{poly}(\eps))$ in the Rigidity-Tomography Round. 
\end{itemize}
\end{lemma}

\begin{proof}
Using a similar argument as in Lemma~\ref{soundlemma}, the strategy of $\pv^*$ in
Rigidity-Clifford rounds, which is also his strategy in EPR-Test rounds (Figure \ref{fig:dogwalker-protocol-PV} Item 1); and the strategy of $\pp^*$ in Rigidity-Clifford rounds, which is also his strategy in Rigidity-Tomography rounds (Figure \ref{fig:dogwalker-protocol-PP} Item 1);
 can both be replaced with the honest strategies. Since the distribution of inputs to $\pp^*$ in the Rigidity-Tomography rounds and Rigidity-Clifford rounds is the same, the success probability in the Rigidity-Tomography rounds is changed by at most $O(\mathrm{poly}(\eps))$ by using the honest strategy. 
On the other hand, $\pv^*$'s input distribution in EPR-Test rounds is uniform on $\Sigma^m$, whereas his distribution in Rigidity-Clifford rounds is given by $\mu$. However, from the description of the test $\rigid$ it is clear that for all $W\in\Sigma^m$, $\mu(W)\geq \frac{1}{c|\Sigma|^m}$ for some constant $c>1$, thus the total variation distance between the two distributions is at most $1-\frac{1}{c}$. Thus, replacing $\pv^*$ with the honest strategy in the EPR-Test  rounds will change the success probability by at most  $O(\mathrm{poly}(\eps))$. 

Finally, since the provers' strategy in the EPR-Computation round has not changed, the
  acceptance probability in it remains unchanged.
\end{proof}

Next, we will show that whenever $\pv^*$ is honest in the EPR-Test rounds this forces $\pp^*$ to output (close to) uniformly random $\{c_i\}_{i\in [t]}$ that are independent of the round type, even given $\vec{z}$. This will allow us to verify that $\pp^*$ is unable to signal to $\pv^*$ whether the round is an EPR Round in the EPR-Computation round, when $\pv^*$ is sent $\vec{z}$ and $\vec{c}$. This establishes (iv). %Moreover, we establish that when $\pv^*$ is honest, and the provers pass the EPR-Test round with probability $1-\eps$, we can replace $\pp$ with a $\pp'$ that passes the EPR-Test with probability 1, without changing by much the acceptance probability in the EPR-Computation round. \anote{added the last sentence.}


\begin{lemma}\label{lem:ci-unif}
Suppose the verifier executes the Dog-Walker Protocol with provers $(\pv^*,\pp^*)$ such that the initial shared state of the provers consists of $m$ shared EPR pairs, together with an arbitrary shared auxiliary state; $\pv^*$ plays the honest strategy in the EPR-Test rounds; the provers are accepted with probability $q_1$ in the Rigidity-Clifford Round, $q_2 = 1-\eps'$ in the EPR-Test Round, $q_3$ in the EPR-Computation Round, and $q_4$ in the Rigidity-Tomography Round. Then the input $(\vec{c},\vec{z})$ given by the verifier to $\pv^*$ in the EPR-Computation rounds has a distribution that is within $O(\eps')$ total variation distance of uniform on $\{0,1\}^t\times\{0,1\}^t$. 
%\anote{added the moreover part}
%Moreover, there exist provers $(\pv',\pp')$ such that $\pv'$ plays the honest strategy in the EPR-Test rounds, and the provers are accepted with probability $q_1$ in the Rigidity-Clifford Round, $q_2 = 1$ in the EPR-Test Round, $q_3 - O(\eps)$ in the EPR-Computation Round, and $q_4$ in the Rigidity-Tomography Round. 
\end{lemma}

\begin{proof}
Let $a_i'$ denote the $\sf X$ key of the wire to which the $i$-th $\sf T$ gate is applied, just before the $i$-th $\sf T$ gate is applied, and let $D_i$ be a random variable defined as follows. If the $i$-th $\sf T$ gate is even, let $D_i=e_i+a_i'$, where we interpret $e_i$ and $a_i'$ as the random variables representing the measurement result and key $\ver$ would get if she chooses to execute an $X$-Test round. If the $i$-th $\sf T$ gate is odd, let $D_i=e_i+a_i'$, where we interpret $e_i$ and $a_i'$ as the measurement result and key $\ver$ would get if she chooses to execute an $Z$-Test round. Since $\pv^*$ is assumed to play honestly in EPR-Test rounds, $\vec{D}$ is uniformly distributed in $\{0,1\}^t$. In particular, we have, for any $\vec{d},\vec{z}\in\{0,1\}^t$,
\begin{equation}
\Pr[\vec{D}=\vec{d},\vec{Z}=\vec{z}]=\frac{1}{4^t}.\label{eq:D-unif}
\end{equation}

Let $C_i$ be the random variable that corresponds to the measurement output of
  the $i$-th $\sf T$ gadget by $\pp^*$ in $X$-Test round if the $i$-th $\sf T$
  gate is even, or the measurement output of the $i$-th $\sf T$ gadget 
  by $\pp^*$ in $Z$-Test round if the $i$-th $\sf T$ gate is odd.

Let $T^0\subset[t]$ be the set of even $\sf T$ gates and $T^1\subset[t]$ the set of odd $\sf T$ gates. In an $X$-Test Round, the provers are rejected whenever $i\in T^0$ and $c_i\neq d_i$, and in a $Z$-Test Round, they are rejected whenever $i\in T^1$ and $c_i\neq d_i$. An EPR-Test Round consists of running one of these two rounds with equal probability, so:
\begin{equation}
\Pr[\vec{C}\neq\vec{D}]  \leq  2\eps'.\label{eq:C-D-equal}
\end{equation}
We can express \eqref{eq:C-D-equal} as
\begin{equation*}
\Pr[(\vec{C},\vec{Z})\neq(\vec{D},\vec{Z})]  \leq  2\eps'.
\end{equation*}
We conclude by using the easily verifiable fact that for any random variables $X$ and $Y$ such that $\Pr[X= Y]\geq 1-2\eps'$, the total variation distance between the marginal distributions on $X$ and $Y$ is at most $2\eps'$. 

%\anote{added the following concise (sketch) proof of the moreover part.}
%Next, we prove the ``Moreover'' part of the Lemma. Since $\pv^*$ is honest in the EPR-Test round, we can employ arguments from
%\cite[Lemma 2]{broadbent15howtoverify}. As in the soundness analysis from~\cite[Section 4]{broadbent15howtoverify}, the analysis of arbitrary deviations of $\pp^*$ reduces to the analysis of a convex combination of ``non-benign Pauli attacks'', where a non-benign Pauli attack is one whose Kraus decomposition involves Pauli operators which affect the probability of passing the EPR-test. Since, the the provers pass the EPR-test with probability $1-\eps$, such Pauli operators must have total weight at most $\eps$. Thus if we replace all of them by identity operators, we obtain a new prover $\pp'$ such that $\pv^*$ and $\pp'$ are accepted probability $1$ in the EPR-Test, and the acceptance probability in the EPR-computation round changes by at most $O(\eps)$. All other acceptance probabilities are unchanged. 
\end{proof}

Next, we can use the tomography test $\tom$ to establish (v), and then the fact that by Lemma \ref{lem:ci-unif} the input to $\pv$ is not very different in EPR-Computation and Rigidity-Tomography rounds to establish (vi):

\begin{lemma}\label{lem:PV-34}
Suppose the verifier executes the Dog-Walker Protocol with provers $(\pv^*,\pp^*)$ such that: $\pv^*$ applies the honest strategy in EPR-Test rounds; 
$\pp^*$ applies the honest strategy in the Rigidity-Tomography rounds; and the provers are accepted with probability $q_1$ in the Rigidity-Clifford Round, $q_2 = 1-\eps'$ in the EPR-Test Round, $q_3$ in the EPR-Computation Round, and $q_4=1-\eps$ in the Rigidity-Tomography Round. Then there exist provers $(\pv',\pp')$ such that $\pv'$ applies the honest strategy in the Rigidity-Tomography rounds and EPR-Computation rounds, $\pp'$ applies the honest strategy in Rigidity-Tomography rounds, and
the provers are accepted with probability $q_1$ in the Rigidity-Clifford Round, $q_2 = 1-\eps'$ in the EPR-Test Round and $q_3-\mathrm{poly}(\eps)-O(\eps')$ in the EPR-Computation round. 
\end{lemma}

\begin{proof}
The Rigidity-Tomography rounds can be seen as $\ver$ playing the Tomography Game
  with the provers, except that whereas $\pv^*$ gets no non-trivial input in the
  Tomography Game, in the Rigidity-Tomography round, he gets random values
  $\vec{c}$ and $\vec{z}$ on which his strategy can depend. Fix $\vec{x}$, and let
  $\{Q_{\vec{c},\vec{z}}^{u}\}_{u}$ be the projective measurement that $\pv^*$
  applies upon receiving $\vec{c},\vec{z},\vec{x}$, where  $u = (\vec{d},\vec{e})$ is
  the string of outcomes obtained by $\pv$ on the $n+t$ single-qubit
  measurements he is to perform according to Step 2 in
  Figure~\ref{fig:dogwalker-protocol-PV}. 

By Corollary \ref{cor:clifford-rigid-adaptive}, since the provers win the Rigidity-Tomography round with probability $1-\eps$, for every $\vec{c},\vec{z}\in\{0,1\}^t$,
there exist distributions $q_{\vec{c},\vec{z}}$ on $\Sigma^m\times\{\pm\}$ such that the following is $O(\mathrm{poly}(\eps))$:
\begin{equation}\label{eq:big-dist}
\Es{\vec{c},\vec{z}}\sum_{ u\in \{0, 1\}^m}
\Big\| \Tr_{\reg{A},\hat{\reg{B}}}\left((\Id_{\reg{A}}\otimes V_{\reg{B}} Q_{\vec{c},\vec{z}}^{u})\ket{\psi}\bra{\psi}_{\reg{AB}}(\Id_{\reg{A}}\otimes V_{\reg{B}} Q_{\vec{c},\vec{z}}^{u})^\dagger\right)
- \sum_{\lambda\in\{\pm\}}q_{\vec{c},\vec{z}}(W',\lambda)\left(\bigotimes_{i=1}^m \frac{\sigma^{u_i}_{W_i',\lambda}}{2}\right)\Big\|_1. 
\end{equation}
Here we use the notation from Corollary \ref{cor:clifford-rigid} and
  \ref{cor:clifford-rigid-adaptive}. The string
  $W'=W(\vec{c},\vec{z},\vec{u})\in\Sigma^m$ is uniquely determined by
  $\vec{c},\vec{z}$, and the outcomes ${u}$ reported by $\pv^*$; indeed it
  is using this string that $\pv^*$'s answers are checked against the
  measurement outcomes obtained by $\pp^*$, who by assumption applies the
  honest strategy. For any fixed $(W',\lambda)$ the distribution on
  outcomes $u$ obtained in the ``honest'' strategy represented by the right-hand
  side in~\eqref{eq:big-dist} is uniform. Thus the outcomes $u$ reported by
  $\pv^*$ are within $\poly(\eps)$ of uniform. From this it follows that the joint distribution on transcripts $(\vec{c},\vec{z},u,W'=W(\vec{c},\vec{z},u))$ that results from an interaction with $\pv^*$ is within statistical distance $\poly(\eps)$ of the distribution generated by an interaction with the honest $\pv$; furthermore, by~\eqref{eq:big-dist} the resulting post-measurement states on $\pp^*$ are also $\poly(\eps)$ close to the honest ones, on average over this distribution. 

We can now consider two provers $\pv'$ and $\pp'$ who, in Rigidity-Tomography rounds, first apply the isometries $V_A$, $V_B$ from Corollary~\ref{cor:clifford-rigid-adaptive}, then  measure their auxiliary systems $\hat{\reg{A}}$ and $\hat{\reg{B}}$ using $\Delta_Y$, obtaining a shared outcome $\lambda\in\{\pm\}$, and finally apply the honest strategy shown in Item 2 of Figure \ref{fig:dogwalker-protocol-PV} ($\lambda=+$) or its conjugate ($\lambda = -$). Furthermore, conjugating the honest strategy produces exactly the same statistics as the honest strategy itself, so we may in fact assume that $\pv'$ and $\pp'$ both apply the honest strategy in Rigidity-Tomography rounds. 

% but the intuition is that up to some isomorphism $V_B$, the strategy applied by $\pv$ to the initial system is within $O(\mathrm{poly}(\eps))$, in expectation, of measuring $W'\in\Sigma^m$, under some distribution on $\Sigma^m$, and reporting $W'$ and the measurement outcome. However, we can say something stronger, since in the Rigidity-Tomography round, we don't let $\pv$ choose which $W'\in\Sigma^m$ to report, but rather, if we give him input $\vec{c},\vec{z}$ and receive output $\vec{u}$, $\ver$ behaves as if $\pv$ reported a particular $W(\vec{c},\vec{z},\vec{u})\in\Sigma^m$ such that $W_i(\vec{c},\vec{z},\vec{u})$ may depend on $\vec{c}$ and $\vec{z}$, but more interestingly, the measurement results $u_1,\dots,u_{i-1}$. Thus, we can restrict to optimal strategies that always report outcomes of the form $(\vec{u},W(\vec{c},\vec{z},\vec{u}))$ and conclude that the following is $O(\mathrm{poly}(\eps))$, where $\{Q_{\vec{c},\vec{z}}^{\vec{u}}\}_{\vec{u}}$ s $\pv$'s projective measurement on input $\vec{c},\vec{z}$, and $q_{\vec{c},\vec{z}}$ are some distributions on $\{\pm\}$:
%\begin{equation*}
%\Es{\vec{c},\vec{z}}\sum_{\substack{u\in \{\pm 1\}^m}}
%\Big\| \Tr_{\reg{A},\hat{\reg{B}}}\left((Id_{\reg{A}}\otimes V_{\reg{B}} Q_{\vec{c},\vec{z}}^{u})\ket{\psi}\bra{\psi}_{\reg{AB}}(Id_{\reg{A}}\otimes V_{\reg{B}} Q_{\vec{c},\vec{z}}^{u})^\dagger\right)
%- \sum_{\lambda\in\{\pm\}}q_{\vec{c},\vec{z}}(\lambda)\left(\bigotimes_{i=1}^m \frac{\sigma^{u_i}_{W_i(\vec{c},\vec{z},\vec{u}),\lambda}}{2}\right)\Big\|_1. 
%\end{equation*}

A consequence of $\pv'$ applying the honest strategy in Figure \ref{fig:dogwalker-protocol-PV} Item 2 is that $\pv'$ also plays the honest strategy in EPR-Computation rounds. Since $\pv'$ is still honest in the EPR-Test round and $q_2 = 1-\eps'$, Lemma \ref{lem:ci-unif} implies that the distribution of the input to $\pv'$ in EPR-Computation rounds is within $\poly(\eps)+O(\eps')$ total variation distance of his input in
Rigidity-Tomography rounds, therefore the provers' success probability in EPR-Computation rounds changes at most by $\mathrm{poly}(\eps)+O(\eps')$. 
\end{proof}


Finally, we show that if $\pv$ is honest, $\pp$ must be honest in EPR computation rounds, or the acceptance probability would be low, establishing (vii):
\begin{lemma}\label{lem:PP-3}
Suppose the verifier executes the Dog-Walker Protocol on an input $(Q,\ket{\vec{x}})$ such that $\norm{\Pi_0 Q\ket{\vec{x}}}^2\leq 1/3$ with provers $(\pv,\pp)$ such that $\pv$ plays the honest strategy. Let $q_2$ be the provers' acceptance probability in EPR-Test rounds. Then the verifier accepts with probability at most
  $p_1(1-\delta_c) +p_2q_2+p_3(5/3-4q_2/3)+p_4$. 
\end{lemma}
\begin{proof}
With probability $p_2+p_3$, $\ver$ executes an EPR round, in which case, he executes EPR-Computation with probability $\frac{p_3}{p_2+p_3}$ and EPR-Test with probability $\frac{p_2}{p_2+p_3}$. In the former case, since $\pv$ is honest, he is executing $V_{EPR}^0$. In fact, the behavior of an honest $\pv$ in the EPR-Test rounds is also that of $V_{EPR}^r$. Thus, the combined behavior of $\ver$ and $\pv$ is that of $V_{EPR}$. Then the result follows from Theorem \ref{thm:EPR-soundness}. 
\end{proof}

We can now combine Lemmas \ref{lem:PV-2-PP-4}, \ref{lem:PV-34}, and \ref{lem:PP-3} to get the main result of this section, the ``soundness'' part of Theorem~\ref{thm:dog-walker}.

\begin{lemma}[Constant soundness-completeness gap]\label{lem:dogwalker-soundness}
 There exist constants $p_1$, $p_2$, $p_3$, $p_4=1-p_1-p_2-p_3$ and $\Delta>0$ such that if the verifier executes the Dog-Walker Protocol with parameters $(p_1,p_2,p_3,p_4)$ on input $(Q,\ket{\vec{x}})$ such that $\norm{\Pi_0 Q\ket{\vec{x}}}^2\leq 1/3$, then any provers $(\pv^*,\pp^*)$ are accepted with probability at most $p_{\mathrm{sound}}=p_{\mathrm{compl}}-\Delta$. 
\end{lemma}

\begin{proof}
%In a similar vein to the proof of Lemma \ref{lem:leash-soundness}, we will show first that one can choose a small enough function $\eps_*(w)$ such that, if any provers ($\pv$,$\pp$) pass the Computation Round with probability $1/3+w$, then they pass at least one of the Rigidity-Clifford round, EPR-Test round or Rigidity-Tomography round with probability less than $< 1-\eps_*(w)$.

Suppose the provers $\pv^*$ and $\pp^*$ are such that the lowest acceptance probability in either the Rigidity-Clifford round or the Rigidity-Tomography round is $1- \eps$, and they are accepted with probability $1-\eps'$ in the EPR-Test round, and with probability $1/3+w$ in the Computation Round. Applying  Lemma \ref{lem:PV-2-PP-4} and Lemma \ref{lem:PV-34} in sequence, we deduce the existence of provers $(\pv',\pp')$ for which
\begin{align*}
q_1' &= 1- O(\delta_c), \\  q_2' &= 1-\eps'- \poly(\eps), \\ q_3' &= \frac13+w-
  \poly(\eps)-O(\eps'),\\ q_4' &= 1,
\end{align*}
where $q'_1$, $q'_2$, $q'_3$ and $q'_4$ are their success probabilities in the
  four types of rounds, and $1-\delta_c$ is the completeness of the
  $\rigid$ test; from Corollary~\ref{cor:clifford-rigid} we have $\delta_c = 2^{-\Omega(n+t)}$. Moreover $\pv'$ applies the honest strategy in all rounds, while $\pp'$ applies the honest strategy in the Rigidity-Clifford and Rigidity-Tomography rounds. Applying Lemma \ref{lem:PP-3}, it follows that 
$$w \,\leq\, O(\eps') + \poly(\eps) +p_1 \cdot O(\delta_c).$$
Therefore the prover's overall success probability is at most 
\begin{align*}
& \min(p_1,p_4)(1-\eps)+\max(p_1,p_4) + p_2(1-\eps')+p_3\left(\frac{1}{3}+w\right) \\
\leq & p_{\mathrm{compl}} - \left( \frac{p_3}{3} + \eps' p_2+\eps\min(p_1,p_4)\right)+ p_3\left(O(\eps')+\poly(\eps)\right)+ (p_1 + p_3p_1) \cdot O(\delta_c),
\end{align*}
where recall from Lemma~\ref{lem:dogwalker-completeness} that
  $p_{\mathrm{compl}} =  p_1(1-\delta_c)+p_2+p_4+\frac{2}{3}p_3$. Fixing $p_2$
  to be a large enough multiple of $p_1$ and of $p_3$ we can ensure that the net contribution
  of the terms involving $\eps'$ and $\delta_c$ on the right-hand side is always
  non-positive. Choosing $p_1=p_4$ and $p_3$ so that the ratio $p_3/p_1$ is small
  enough we can ensure that the right-hand side is less than $p_{\mathrm{compl}}
  -\Delta$, for some universal constant $\Delta>0$ and all $\eps,\eps'\geq 0$.
  


%\tnote{previous proof follows; remove if above is ok}
%Then, by Lemma \ref{lem:PV-2-PP-4}, there exist provers $(\pv',\pp')$ for which 
%\begin{align*}
%q_1' &= 1, \\  q_2' &= 1-\eps_*(w)-O(poly(\eps_*(w)) = 1-O(poly(\eps_*(w))), \\ q_3' &= \frac13+w,\\ q_4' &= 1-\eps_*(w)-O(poly(\eps_*(w))= 1-O(poly(\eps_*(w))), 
%\end{align*}
%where $q_1',q_2',q_3$ and $q_4'$ are their passing probabilities in the four types of rounds (Rigidity-Clifford, EPR-Test, EPR-Computation, Rigidity-Tomography). Moreover, $\pv'$ applies the honest strategy in the Rigidity-Clifford and EPR-Test rounds, and $\pp'$ in the Rigidity-Clifford and Rigidity-Tomography Rounds. 

%Then, by Lemma \ref{lem:ci-unif}, there exist provers $(\pv'',\pp'')$ for which
%\begin{align*}
%q_1'' &= 1, \\  q_2'' &= 1, \\ q_3'' &= \frac13+w-O(poly(\eps_*(w))),\\ q_4'' &= 1-O(poly(\eps_*(w))),
%\end{align*}
%where $q_1''$, $q_2'',q_3''$ and $q_4''$ are their passing probabilities in the four rounds. $\pv''$ still applies the honest strategy in the Rigidity-Clifford and EPR-Test rounds, and $\pp'$ in the Rigidity-Clifford and Rigidity-Tomography Rounds. 

%Then, by Lemma \ref{lem:PV-34}, there exist provers $(\pv''',\pp''')$ for which
%\begin{align*}
%q_1'' &= 1, \\  q_2'' &= 1, \\ q_3'' &= \frac13+w-O(poly(\eps_*(w))),\\ q_4'' &= 1,
%\end{align*}
%where $q_1''$, $q_2'',q_3''$ and $q_4''$ are their passing probabilities in the four rounds. Moreover $\pv''$ applies the honest strategy in all rounds, while $\pp''$ applies the honest strategy in the Rigidity-Clifford and Rigidity-Tomography rounds.

%Now, one can always choose a continuous and increasing function $\eps_*(w)$ small enough so that so that $q_3'' > \frac13+\frac{w}{2}$. But this choice of $\eps_*$ contradicts Lemma \ref{lem:PP-3}.

%Thus, if provers $\pp$ and $\pv$ succeed in the Computation round with probability $\frac13+w$, then they must succeed with probability less than $1-\eps_*(w)$ in at least one of the Rigidity-Clifford, EPR-Test or Rigidity-Tomography round.

%This implies that for any strategy of the provers, the probability that they are accepted is at most
%\begin{align*}
%\max\big\{p_1+p_2 + p_3\Big(\frac13+\frac16\Big) &+ p_4,\,\, p_1\big(1-\eps_*\Big(\frac16\Big)\big)+p_2+p_3+p_4,\,\, \\
%&p_1+ p_2(1-\eps_*\Big(\frac16\Big))+ p_3 + p_4, \,\,p_1 + p_2 + p_3 + p_4 \big(1-\eps_*\Big(\frac16\Big)\big)\}
%\end{align*}
%Since $\eps_*(\frac16)$ is a positive constant, it is clear that one can pick $p_3$ small enough so that the first term is the largest.
%Pick the largest such $p_3$, then, the probability that the two provers are accepted is at most
%\begin{align*}
% p_{\mathrm{sound}} &:= p_1+p_2 + p_3\Big(\frac13+\frac16\Big)+p_4 \\
%&< p_1+p_2 + \frac23 p_3+p_4\\
%&:= p_{\mathrm{compl}}\;,
%\end{align*}
%which gives the desired constant gap $\Delta$. 
\end{proof}




%\snote{since the transformations on the protocol cause the rejection probability to go to $\eps^k$ for some $k$ that may be smaller than $1/2$, I don't think this works with $1/3$ and $2/3$ any more. I think we need to amplify the circuit $Q$ so that either $\norm{\Pi_0Q\ket{\vec{x}}}^2\leq \delta$ or $\norm{\Pi_0Q\ket{\vec{x}}}^2\geq 1-\delta$ for $\delta\leq k/(k+1)$, where $k$ is the constant in the exponent of $\mathrm{poly}(\eps)$.}


%%===============================%
%\section*{Old dog-walker soundness}
%%===============================%
%
%
%
%
%
%\subsection{Soundness}
%\anote{I did some edits and rearrangements to make the structure of the section similar soundness for leash.}
%In the Dog-Walker Protocol, proving soundness is a bit trickier than the leash
%protocol.  
%In this protocol, acceptance in the Tomography tests is not sufficient to prove
%that $\pv$'s behavior is close to honest: in the Computation round, $\pp$'s output is part of the input to $\pv$,
%therefore $\pp$ might be leaking information to $\pv$, which could allow them to
%behave dishonestly depending on the round type (in particular when they are not being tested).
%
%To prove soundness here,  we start again by using the fact that if the provers
%pass the rigidity games with high probability, than we can conclude that $\pv$'s
%strategy in $X$- and $Z$-test rounds is close to honest.
%
%From this, we  can prove that if the provers also pass $X$- and $Z$-test rounds with high probability,
%then the outcome distribution of $\pp$ is close to uniform.
%
%Finally, this allows us to conclude that $\pv$'s strategy in the Computation round is
%also close to honest, and we finish the soundness proof similarly to the leash
%protocol. Figure \ref{fig:full-dog-walker} shows the arrow of implication in the soundness
%proof.
%
%Again, we divide the analysis in two parts. First, the case of an honest $\pv$, and cheating $\pp$. Then we show that a dishonest $\pv$ is caught with high probability, irrespective of the strategy of $\pp$. 
%
%
%\paragraph{Soundness Against Cheating $\pp$.} \tnote{Should this be ``partially'' cheating, or some approriate name?}
%
%\begin{lemma}\label{lem:soundness-dogwalker-honest-pv}
%  Suppose the verifier executes the Dog-Walker Protocol on input $(Q,\ket{x})$
%  such that $\norm{\Pi_0Q\ket{x}}^2 \leq \frac{1}{3}$.
%  with provers $(\pv,\pp)$ such that $\pv$ plays the honest strategy, and the provers pass the 
%  X/Z test with
%  probability $1$.
%  Then the provers are accepted in the Computation round with probability at most $\frac{1}{3}$.
%\end{lemma}
%\begin{proof} 
%  By assumption $\pv$ and $\pp$ pass the X/Z test with probability $1$.
%  Therefore, by \cite[Lemma 4]{broadbent15howtoverify}, the acceptance
%  probability is at most $\frac{1}{3}\sum_{Q \in B}|a_q|^2 \leq \frac{1}{3}$.\tnote{are these $a_q$ defined anywhere? Why not just say ``at most $1/3$''?}
%\end{proof}
%
%\paragraph{Soundness Against Cheating $\pv$.}
%
%
%\begin{lemma}\label{lem:dogwalker-rigidity}
%Suppose the verifier executes the Dog-Walker Protocol  on input $(Q,\ket{x})$
%  with provers $(\pv,\pp)$, such that the provers are accepted with probability
%  at least
%  $1-\eps$, for some $\eps>0$, in the rigidity game, and with probabilities
%  $q_T$ and $q_C$ in the $X/Z$-test rounds and the computation round, respectively.  Then there exist provers $\pp'$ and $\pv'$ such that
%  $\pv'$ applies the honest strategy in the $X/Z$-test round \anote{and also in the Clifford part of Tomography?} and $\pp'$ and $\pv'$
%  are accepted with probability at least $q_T-O(\sqrt{\eps})$ in the $X/Z$-test
%  rounds and at least $q_C$ in the computation round. \anote{and also the probability of acceptance in the Tom part Tomography is unchanged.}
%\end{lemma}
%\begin{proof}
%  In the Tomography test, the Clifford test is run with probability
%  $\frac{1}{2}$. We assume the provers pass the Tomography test with probability
%  at least
%  $1-\eps$, therefore the Clifford test is passed with probability at least
%  $1-2\epsilon$. 
%  
%  Using the same technique from Lemma~\ref{soundlemma}, the strategy of $\pv$ in
%  X/Z test rounds can replaced to be the honest one and the
%  difference of the acceptance probability in this test is at most
%  $O(\sqrt{\eps})$.
%
%  Since the provers' strategy in the Computation round has not changed, the
%  acceptance probability in it remains $q_C$.
%\end{proof}
%
%
%\begin{lemma}\label{lem:soundness-honest-pp}
%  Suppose the verifier executes the Dog-Walker Protocol  on input $(Q,\ket{x})$
%  with provers $(\pv,\pp)$, such that $\pv$ is honest in the X/Z test round and the provers are accepted with probability
%  $1-\eps$, for some $\eps>0$, in the X/Z test round, with probability $q_C$
%  in the Computation round and with probability $q_R$ in the Tomography round.
%  Then there exist provers
%  $\pp''$ and $\pv''$ such that $\pv''$ applies the honest strategy in the X/Z
%  test,  and $(\pv'', \pp''$)  are accepted with probability $1$ in the X/Z test, with probability at least $q_C-O(\eps)$  in the
%  Computation round and with probability $q_R$ in the Tomography round
%\end{lemma}
%\begin{proof}
%  Since $\pv$ is honest in X/Z test rounds, we use here the arguments of
%  \cite[Lemma 2]{broadbent15howtoverify} to conclude the proof.
%
%  We assume, without loss of generality, that $\pp$ performs the correct circuit
%  $Q$, followed by an arbitrary malicious operation $E$ and that $\pp$ does not
%  perform the measurement, who are performed (just for the purposes of the
%  proof), by the Verifier.\tnote{this paragraph is hard to parse}
%  
%	\tnote{Can't we replace the next four paragraphs by ``As in the soundness analysis from~\cite[Section XX]{Anne}, the analysis of arbitrary deviations of $\pp$ reduces to the analysis of a convex combination of ``non-benign Pauli attacks'', where a non-benign Pauli attack is one in which...''. Why do we need all the details, copied from Anne?}
%  Let 
%  $E(\rho) = \sum_{k} E_k \rho E_k^\dag$. 
%  be the Kraus decomposion of $\pp$'s attack and 
%  $E_k =
%  \sum_{W \in \hat{\pauli}^{(n+t)}} \alpha_{W,k} W$ be
%  each Kraus operator written in the Pauli basis.  It follows that we can write
%  $\pp$'s attack as
%  \[E(\rho) = \sum_{k} \sum_{W, W' \in \hat{\pauli}^{(n+t)}}
%  \alpha_{W,k}\alpha_{W',k}^* W \rho W' .\]
%
%  The $\pp$'s input $\sum_{R \in \hat\pauli^{n+t}} R \kb{\psi} R$ is teleported
%  by the honest $\pv$, where the random Pauli is the quantum one-time pad key
%  due to the teleportation and 
%  $\ket{\psi}$ is the input and gadget states created by $\pv$, that depend on the test type.
%  $\pp$ applies the correct circuit $Q$, followed by the attack $E$ and
%  then  Verifier performs the decoding procedure $\tilde{R}^\dag$, such that $QR = \tilde{R}Q$.
%  The Verifier, after all these operations, holds the state
%  \begin{align*}
%    & \sum_{k} \sum_{R, W, W' \in \hat{\pauli}^{(n+t)}} \alpha_{W,k} \alpha_{W',k}^* 
%     \tilde{R}^\dag W Q R \sigma R^\dag  Q   W' \tilde{R} \\
%     & =
%     \sum_{k} \sum_{R, W, W' \in \hat{\pauli}^{(n+t)}} \alpha_{W,k} \alpha_{W',k}^* 
%     \tilde{R}^\dag W \tilde{R} Q \sigma Q \tilde{R}^\dag    W' \tilde{R} \\
%     &= \sum_{k} \sum_{W \in \hat{\pauli}^{(n+t)}}
%     |\alpha_{W,k}|^2 
%     W Q \sigma Q  W.
%  \end{align*}
%  and the last equality holds by the Pauli twirl lemma \agnote{Add it to
%  preliminaries}.
%  By the last equation, we can interpret $\pp$'s attack as if he is  applying
%  the attack $W$ with probability $\sum_{k}|\alpha_{Q,k}|^2$.
%
%  We define a partition in the set of Pauli matrices  $\hat{\pauli}^{(n+t)}$ in
%  the sets of benign Paulis operators $B$, where
%  the measured qubits are acted only by $\{I, Z\}$,
%  and the set of non-benign Pauli operators $NB$ where at least one of the
%  measured qubits is affected by a gate in $\{X, Y\}$.
%
%  Note that if $W \in B$, the output does not change if the
%  Verifier measures in the $Z$ basis. 
%  However, if $W \in NB$, a measured qubit is flipped, and therefore, 
%  the Verifier detects the malicious operation and rejects in this case,
%  either the X or the Z test round.
%  Therefore, the verifier rejects in X/Z test round with probability $\sum_{W
%  \in NB} \sum_k |\alpha_{k,W}|^2$, which is at most 
%  $\eps$, by assumption.
%
%  We can define provers $\pv''$ and $\pp''$, such that $\pv'' = \pv$
%  and  $\pp''$ replaces all non-benign attacks by identity. More fornally, $\pp$
%  applies $W \in B \backslash \{I\} $ with probability $|\alpha_{i,W}|^2$,
%  as $\pp$, and applies $I$ with probability $\sum_{W \in NB \cup \{I\}} |\alpha_{W,k}|^2$.
%
%  Since by assumption $\pv''$ and $\pp''$ does not
%  apply any non-benign attack, $(\pv'', \pp'')$ pass the X/Z test
%  rounds with probability $1$.
%
%  The strategy of the provers in Tomography round remains unchanged, therefore the
%  acceptance probability remains the same.
%
%  Finally, the statistical distance of the strategy of the provers is 
%  $\eps$, the maximum difference in the acceptance in Computation rounds is $O(\eps)$.
%\end{proof}
%
%
%\begin{lemma}\label{lem:soundness-dogwalker}
%  Suppose the verifier executes the Dog-Walker Protocol on input $(Q,\ket{x})$
%  with provers $(\pv,\pp)$ that accept in the Rigidity test and X/Z test with
%  probability $1-\eps$
%  and with probability  $q_C$ in the Computation round.
%  Then there exist provers
%  $(\pp^*, \pv^*)$ such that $\pv^*$ is honest
%  and they are accepted with probability at least $q_C-O(\sqrt{\eps})$  in 
%  it.
%\end{lemma}
%\begin{proof}
%By Lemma \ref{lem:dogwalker-rigidity}, we know that there exist provers $\pp'$
%  and $\pv'$ such that $\pv'$ applies the honest strategy in the X/Z test round
%  and $\pp'$ and $\pv'$ are accepted with probability at least $1 - \eps -
%  O(\sqrt{\eps}) = 1-O(\sqrt{\eps})$ in the X/Z test round and at least $q_C$ in the computation round.
%
%  By Lemma \ref{lem:soundness-honest-pp}, using the  provers $(\pv',
%    \pp')$, it follows that there exist provers $\pp''$ and $\pv''$ such that
%    $\pv''$ applies the honest strategy in the X/Z test, 
%    $(\pv'', \pp'')$ pass the X/Z test with probability $1$ and
%    $\pv''$ are
%    accepted with probability at least $q_C-O(\sqrt{\eps})$  in the Computation round.
%    
%    Since $\pv''$ is honest \anote{in the X/Z tests} and $(\pv'', \pp'')$ pass the X/Z test with probability $1$ the
%    the output $\vec{c}$ of $\pp''$ is distributed according to the uniform distribution.
%  Therefore the second step in  the Tomography test is indistinguishable from the
%  computation round for $\pv''$.
%  
%  Since we have that
%  $\pv$ and $\pp$ pass the Tomography test with probability $1-O(\eps)$, we can use similar arguments to Lemma~\ref{soundlemma} to obtain provers $(\pv^*, \pp^*)$ such that $\pv^*$ is honest \anote{in the second step of Tomography and in the Computation round, and unchanged in the rest, (hence honest everywhere)}, and the acceptance probability on the
%  Computation round is at least $q_C-O(\sqrt{\eps})-O(\sqrt{\eps})=q_C-O(\sqrt{\eps})$.
%\end{proof}
%
%
%% \begin{theorem}
%%   %The maximum acceptance probability by the Verifier
%%   when the input is a not \textit{no} instance is $\delta$
%%   $1 - \min\{ p_C (\frac{1}{3} + O(\eps)),\min\left\{p_R, p_{X/Z}, p_{ER}\right\}\eps\}$
%%   \agnote{I still have to see which is the probability for each round}.
%% \end{theorem}
%% \begin{proof}
%% Let us assume that the provers accept on Rigidity round, X/Z test and $\pv$-testing round with probability at least $1-\eps$. In this case, we can use Lemma~\ref{lem:soundness-dogwalker} and the Provers are accepted with probability at most $\frac{1}{3} + O(\eps)$ in the Computation round.
%
%% If this is not the case, the Provers are accepted with probability at least $\min\left\{p_R, p_{X/Z}, p_{ER}\right\}\eps$.
%% \end{proof}
%
%\begin{theorem} (Constant soundness-completeness gap) There exists constants $p_r, p_x, p_z, p_c = 1 - p_r - p_x - p_z$ and $\Delta>0$ such that if the verifier executes the Dog-Walker protocol with parameters $(p_r,p_x, p_z, p_c)$ on input $(Q,\ket{x})$ such that $\|\Pi_0 Q\ket{x}\|^2 \leq 1/3$, then any provers $(\pv,\pp)$ are accepted with probability at most $s=c-\Delta$.  
%\end{theorem}
%
%\begin{proof}
%Let $p_r, p_t$ and $p_c$ be respectively the probabilities of running a Rigidity game, an X/Z test round and a Computation round.
%Suppose the provers pass the Computation round with probability $1/3+w$. Just as in the proof of Lemma \ref{lem:leash-soundness}, choose a function $\eps_*(w)$ such that $g(\eps_*(w)) = \frac{w}{2}$, where $g(\eps) = O(\sqrt{\eps})$ is the function from the guarantee of Lemma \ref{lem:soundness-dogwalker}. Then suppose the provers are accepted in both the Rigidity game and the X/Z tests with probability $1-\eps_*(w)$. Then, by Lemma \ref{lem:soundness-dogwalker}, there exists provers $\pp'$ and $\pv'$, with $\pv'$ honest, such that they are accepted in the Computation round with probability 
%$\frac13+w-g(\eps_*(w)) = \frac13+\frac{w}{2}>\frac13$. This contradicts Lemma (the equivalent Lemma of 4.7).
%
%Thus if provers $\pp$ and $\pv$ succeed in the Computation round with probability $\frac13+w$, then they must succeed with probability less than $1-\eps_*(w)$ in at least one of the Rigidity game or the X/Z tests.
%This implies that for any strategy of the provers, on any NO instance, the probability that they are accepted is at most
%\begin{equation}
%\max\big\{p_r+p_t + p_c\Big(\frac13+\frac16\Big),\,\, p_r\big(1-\eps_*\Big(\frac16\Big)\big)+p_t+p_c,\,\, p_r+ p_t(1-\eps_*\Big(\frac16\Big))+ p_c\} \nonumber
%\end{equation}
%Since $\eps_*(\frac16)$ is a positive constant, it is clear that one can pick $p_r$ large enough so that the second and third terms are smaller than the first.
%Pick the largest such $p_r$, then, the probability that the two provers are accepted is at most
%\begin{align*}
% s &:= p_r+p_t + \Big(\frac13+\frac16\Big)\,p_c \\
%&< p_r+p_t +  \frac23 p_c\\
%&= c\;,
%\end{align*}
%which gives the desired constant gap $\Delta$. small enough. If the provers pass both the Rigidity AND the X/Z tests with probability $> 1-\eps(w)$, then by Lemma (as formulated in the note) there exist provers with honest PV that pass the Computation round with probability $>1/3$. This is a contradiction. Hence provers pass at least one of Rigidity or X/Z tests with prob  $< 1-\eps(w)$. One can always pick the probability $p_C$ of running the Computation round small enough so that the maximiser $w_*$ of the provers overall acceptance prob is $w_*< 1/6$. So $1/3+ w_* < 2/3$. This gives the desired constant soundness-completeness gap. 
%\end{proof}
%






\section{Running our protocols in sequence}
\label{sec:sequential}

%As far as practical deployment goes, there are two limitations in our protocols, as they are presented so far. 

In order to make a fair comparison between previous delegated computation protocols and ours (see Figure~\ref{tab:comparison}) we analyzed their resource requirements under the condition that they produce the correct outcome of the computation with $99\%$ probability. For most protocols, this is achieved by sequentially repeating the original version, in order to amplify the completeness-soundness gap. 

In this section, we describe a sequential procedure that, starting from our protocols in Sections \ref{sec:leash} and \ref{sec:dog-walker}, ensures that either the verifier aborts, or she obtains the correct outcome of the computation with probability $99\%$. Moreover, for honest provers, the probability that the procedure aborts is exponentially small in the number of sequential repetitions. Our sequential procedure has a number of rounds which depends on the desired soundness. As long as one only requires amplification of an arbitrarily small, but constant, soundness, to a fixed constant, the number of sequential repetitions remains constant.

To emphasize the importance of having such a sequential procedure, we note that, firstly, the current completeness-soundness gap between acceptance probability on \textit{yes} and \textit{no} instances, for both the leash and the Dog-Walker protocol, is a very small constant. Secondly, if a classical client wishes to employ our protocols to delegate a computation, we need to specify what the client interprets, at the end of the protocol, as the outcome of the delegated computation. The natural approach is to have the verifier interpret $\sf accept$ as a \textit{yes} outcome and $\sf reject$ as a \textit{no} outcome. However, this is not enough, as our security model based on the constant gap between acceptance probability for \textit{yes} and \textit{no} instances means that, while the provers have a low probability of making the verifier accept a \textit{no} instance as a $\textit{yes}$, they can always make the verifier accept a \textit{yes} instance as a \textit{no}, simply by behaving so that they are rejected.

The first point is addressed by running copies of the original protocol in sequence to amplify the completeness-soundness gap. The second point is addressed by having the verifier run the protocol twice: once for the circuit $Q$, and once for the circuit $Q'$ defined by appending an $\sf X$ gate to the output wire of $Q$. If $f:X\rightarrow \{0,1\}$ for some $X\subseteq \{0,1\}^n$ is defined by $f(x)=1$ if $\norm{\Pi_0 Q\ket{x}}^2\geq 2/3$, and $f(x)=0$ if $\norm{\Pi_0 Q\ket{x}}^2\leq 1/3$, i.e.\ $Q$ decides $f$ with bounded error $1/3$, then it is easy to see that $Q'$ decides $1-f$ with bounded error $1/3$. Thus, the verifier will accept $x$ as a \textit{yes} instance of $f$ if the protocol outputs ${\sf accept}$ when running $Q$ on $x$ and outputs $\sf reject$ when running $Q'$ on $x$. The verifier accepts $x$ as a \textit{no} instance of $f$ if the protocol outputs $\sf reject$ when running $Q$ on $x$ and outputs $\sf accept$ when running $Q'$ on $x$. The verifier aborts if she sees $\sf accept$-$\sf accept$ or $\sf reject$-$\sf reject$. 
%If one requires a soundness vanishing with the size of the input $n$, then the number of rounds will depend on $n$.
%We leave for future work investigating the possibility of running the required copies in parallel.



\subsection{Sequential version of our protocols}

Let $P$ denote either the Verifier-on-a-leash or the Dog-Walker protocol from Sections \ref{sec:leash} and \ref{sec:dog-walker} respectively, and let $c$ and $\Delta$ denote the completeness and completeness-soundness gap. Let $\kappa$ be a security parameter.

\begin{figure}[H]
\rule[1ex]{16.5cm}{0.5pt}
\justify
Protocol $\mbox{Seq}(P,c,\Delta, \kappa)$: Let $(Q,x)$ be the verifier's input. 
\begin{enumerate}
\item The verifier runs $\kappa$ copies of protocol $P$ in sequence on input $(Q,x)$ with $\pp$ and $\pv$. Then she runs $\kappa$ copies in sequence on input $(Q',x)$. 
\item Let $\vec{o}, \vec{\tilde{o}} \in \{0,1\}^{\kappa}$ be such that $o_i = 1$ iff the $i$-th copy on input $(Q,x)$ accepts, and $\tilde{o}_i = 1$ iff the $i$-th copy on input $(Q',x)$ accepts. Let $wt(\vec{o})$ and $wt(\vec{\tilde{o}})$ be their Hamming weights. Then, the verifier accepts $1$ as the outcome of the delegated computation if $wt(\vec{o}) \geq (c- \frac{\Delta}{2}) \cdot \kappa$ and $wt(\vec{\tilde{o}}) < (c- \frac{\Delta}{2}) \cdot \kappa$, and she accepts $0$ as the outcome of the computation if $wt(\vec{o}) < (c- \frac{\Delta}{2})\cdot \kappa$ and $wt(\vec{\tilde{o}}) \geq (c- \frac{\Delta}{2}) \cdot \kappa$. Otherwise the verifier aborts.

\end{enumerate}
\rule[2ex]{16.5cm}{0.5pt}\vspace{-.5cm}
\caption{Sequential version of our protocols} \label{fig: gardenhose-protocol-parallel}
\end{figure}

\noindent We state and prove completeness and soundness for the sequential protocol.

\begin{theorem}
Let $c$ and $\Delta$ be respectively the completeness and completeness-soundness gap of protocol P. On input $(Q,x)$:
\begin{itemize}
\item If the provers are honest, $$ \Pr\big(\mbox{Seq}(P, c, \Delta, \kappa) \mbox{  outputs } f(x)\big) \geq 1 - 2\exp \left(-\frac{\Delta^2\kappa}{2}\right) .$$ 
\item For any cheating provers, $$\Pr\big(\mbox{Seq}(P, c, \Delta, \kappa) \mbox{  outputs } 1-f(x)\big) \leq \exp \left(-\frac{\Delta^2\kappa}{8}\right) .$$
\end{itemize}

\end{theorem}

\begin{proof} We first show completeness. 
Let $s = c- \Delta$ be the soundness of protocol P.
Suppose $f(x) = 1$ (the case $f(x) = 0$ is analogous). If the provers are honest, then the probability that the verifier outputs~$1$~is:
\begin{align*}
\Pr(\mbox{Verifier outputs $1$}) &= \Pr \left(wt(\vec{o}) \geq \left(c - \frac{\Delta}{2}\right)\cdot \kappa \,\, \land \,\, wt(\vec{\tilde{o}}) < \left(c - \frac{\Delta}{2}\right)\cdot \kappa \right)\\
&\geq 1-\Pr \left(wt(\vec{o}) < \left(c - \frac{\Delta}{2}\right)\cdot \kappa \right) - \Pr \left(wt(\vec{\tilde{o}}) \geq \left(c - \frac{\Delta}{2}\right)\cdot \kappa \right) \\
&\geq 1 - 2\exp \left(-\frac{\Delta^2\kappa}{2}\right)
\end{align*}
by Hoeffding's inequality.

Next we show soundness.
Again suppose $f(x) = 1$ (the case $f(x) = 0$ is analogous). Let $W_j$ be an indicator random variable for the event $\tilde{o}_j = 1$, and let $F_j = W_j - s$. Define $X_l = \sum_{j=1}^l F_j$, for $l=1,..,\kappa$. The $F_j$ define a submartingale with $|F_j| \leq 1 \,\, \forall j$. Hence, by Azuma's inequality, for any $\kappa\geq 1$, $\Pr(X_\kappa \geq t) \leq \exp(-\frac{t^2}{2\kappa})$. This implies that 
\begin{equation*}
\Pr \left(\sum_{j=1}^{\kappa} W_j - \kappa \cdot s \geq t \right) = \Pr \left(\sum_{j=1}^{\kappa}F_j \geq t \right) = \Pr \left(X_{\kappa} \geq t \right) \leq \exp\left(-\frac{t^2}{2\kappa}\, \right).
\end{equation*}
Then, for any provers $\pp$ and $\pv$,
\begin{align*}
\Pr(\mbox{Verifier outputs $0$}) &\leq \Pr \Big(wt(\vec{\tilde{o}}) \geq (c - \frac{\Delta}{2})\cdot \kappa \Big) \\
&= \Pr \left(\sum_{j=1}^\kappa W_j \geq (c - \frac{\Delta}{2})\cdot \kappa \right) \\
&= \Pr \left(\sum_{j=1}^{\kappa} W_j - \kappa \cdot s \geq \kappa \cdot \frac{\Delta}{2} \right) \\
&\leq \exp \left(-\frac{\Delta^2\kappa}{8}\right). \qedhere
\end{align*}
\end{proof}


\appendix

\input{clifford-appendix.tex}





%\section{Multi-prover game for QMA}
%\agnote{Here is some draft of what I think it would be the right level of
%details for the proof. If we decide to let it in, we should also decide what to
%add in Preliminaries (def of QMA and Local Hamiltonians?) and in the previous
%work (talk about FV, Ji, etc).}
%
%In Complexity Theory, multi-prover games\cite{BenOrGKW88} have been used extensively in order to 
%improve efficiency in proof verification
%systems and tighten innaproximability results through the PCP theorem\cite{AroraS98}\cite{AroraLMSS98}\cite{Raz98}.
%
%In the quantum case, it is still an open question if the quantum PCP\cite{AharonovAV13} conjecture can be casted in the language of multi-prover games. 
%
%We present here how to use the Dogwalker protocol in order to devise a classical verifier 2-prover game for QMA.
%
%\subsubsection{Preliminaries}
% 
%A promise problem $L=L_{yes} \cup L_{no}$ is in QMA if there exist polynomials $p$, $q$ and a polynomial-time uniform family of quantum circuits $\{Q_n\}$, 
%      where $Q_n$ takes as input a string $x\in\Sigma^*$ with $|x|=n$, a $p(n)$-qubit quantum state, and $q(n)$ ancilla qubits in state $\ket{0}^{\otimes q(n)}$, such that:
%      \begin{description}
%      \item[Completeness:] If $x\in L_{yes}$, then there exists a $p(n)$-qubit quantum state $\ket{\psi}$ such that $Q_n$ accepts $(x,\ket{\psi})$ with probability at least $1 - exp(n)$.
%      \item[Soundness:] If $x\in L_{no}$, then for any $p(n)$-qubit quantum state $\ket{\psi}$, $Q_n$ accepts $(x,\ket{\psi})$ with probability at most $exp(n)$.
%      \end{description} 
%
%  For simplicity, we denote as $V_x$ as the circuit $Q_n$ with the input $x$ hardcoded on it.
%
%%  The input for a $k$-Local Hamiltonian problem (LH) 
%%   is a set of $m(n)$ Hamiltonians $H_1, \ldots, H_{m(n)}$
%%  where $m$ is a polynomial in $n$, $\forall i \in [m(n)] : 0 \leq H_i \leq \Id $
%%  and each $H_i$ acts on $k$ qubits out of an $n$ qubit system. 
%  
%%  For $H = \sum_{j = 1}^{m(n)} H_j$ and the parameters $a,b \in \R$ with $a<b$, we define the yes and no instances of the LH as
%%    \begin{description}
%%      \item[Yes-instances:] There exists a
%%      state $\ket{\psi} \in \C^{2^{n}}$ such that
%%      $
%%        \bra{\psi} H \ket{\psi}
%%        \leq a \cdot m(n) .
%%      $
%%      \item[No-instances] All states $\ket{\psi} \in %\C^{2^{n}}$
%%      it holds that
%%      $
%%        \bra{\psi} H \ket{\psi}
%%        \geq b \cdot m(n) .
%%      $
%%    \end{description}
% 
%
%The existence of classical client two-prover games for QMA with questions with polynomially many bits and constant bits answer is known through the inclusion of NEXP in MIP(2). However, this requires exponential-time provers. 
%
%
%Here, we are interested in providing multi-prover protocols for QMA where honest provers are polynomially bounded with access to copies of accepting witness (when they exist).
%In this line, 
%Fitzsimons and Vidick \cite{FitzsimonsV15} first proposed a quantum verifier 5-prover game for Local Hamiltonians, the QMA-complete problem that can be seen the quantum analog of MAX-SAT. In their game, the verifier sends questions of logarithmic size to the provers, who answers with constant number of qubits. However, for any gap in the groundstate energy, the gap on the acceptance probability is inverse polynomial.
%
%Based on ideas of self-testing, Ji\cite{Ji16} modified \cite{FitzsimonsV15} making the the verifier (and all communication) classical. In\cite{Ji16}, the classical verifier also sends log-size messages to 7-provers, who then answer with a constant number of bits. The gap in the acceptance probability between games from yes and no instances is still inverse polynomial.
%
%More recently,  Natarajan and Vidick\cite{natarajan2016robust} have proposed a new classical verifier 7-provers game for LH, where the verifier's questions increase from logarithmic size to polynomial, but on the other hand, the gap between the acceptance probability for yes/no instances is constant.
%
%We show now how to
%use the Dogwalker protocol in order to obtain a classical verifier 2-prover game for QMA, where the verifier sends polynomially many bits, the provers answer with polynomially many bits and the 
%
%
%\begin{table}[t]
%\centering
%\begin{tabular}{l|llllll}
%& Verifier & Provers & Rounds & Question size & Answer size & Gap\\
%\hline\\[-8pt]
%FV15 \cite{FitzsimonsV15}  & Quantum & 5 & 1 & $O(log(n))$ & $O(1)$ & $1/poly(n)$ \\[3pt]
%Ji16 \cite{Ji16}  & Classical & 7 & 1 & $O(log(n))$ & $O(1)$ & $1/poly(n)$ \\[3pt]
%NV16 \cite{natarajan2016robust}  & Classical & 7 & 1 & $O(poly(n))$ & $O(1)$ & $O(1)$ \\[3pt]
%\hline\\[-8pt]
%Dog-Walker  & Classical & 2 & 2 & $poly(n)$ & $poly(n)$ & $O(1)$ 
%\end{tabular}
%\caption{
%Resource requirements of various multi-prover games for QMA.} 
%\label{tab:comparison_qma}
%\end{table}
%
%
%\subsubsection{Our approach}
%We show now how to use the Dogwalker protocol\footnote{We
%could do it also with the leash protocol, but since the provers must know the
%input in order to create the witness state, blindness would be lost.} to devise a classical client, 2 prover, constant round multi-prover game for QMA.
%
%The idea is quite simple: the verifier and the two provers would run the
%Dogwalker protocol with additional qubits for the witness. On EPR-Test and EPR-Computation rounds,  $\pp$ uses the qubits in positions informed by the Verifier as the witness in the computation of  QMA verifier circuit. On EPR-Test
%rounds, the Verifier ensures that $\pp$ has copies of $\ket{0}$ or
%$\ket{+}$, according to the test type, in these positions. Finally, the Verifier informs $\pv$ which are these position on EPR-Computation rounds, so $\pv$ teleports the correct witness to $\pp$.
%
%
%We state now the result and sketch its proof.
%
%\begin{corollary}
%Let $x$ be an instance of $L$, which is in QMA, $n = |x|$,  $V_x$ be the verification circuit for this instance and $g$ be the number of $T$ gates (in the compiled form as described in section TODO) and two constants $p_{compl}$ and $\Delta$. There exists a two-round interactive protocol
%between a classical verifier and two entangled provers where the Verifier
%sends $O(n + g)$ bits questions to the provers, and the provers answer with $O(n + g)$ bits and the protocol follows the following properties
%\begin{description}
%\item[Completeness:] If $x$ is a yes-instance, then the acceptance probability of the Verifier is
%$p_{compl}$.
%\item[Soundness:] If $x$ is a no-instance, then the acceptance probability of the Verifier is
%$p_{sound} = p_{compl} - \Delta$.
%\end{description}
%\end{corollary}
%\begin{proof}[Proof sketch] 
%  The behaviour of the multi-prover game Verifier is the same of the Verifier in the Dogwalker protocol, only adapting to include the qubits for the QMA witness in all the tests.
%  
%  For Rigidity-Test rounds, the honest strategy for the provers is unchanged.
%  
%  For EPR-Test rounds, the Verifier has also to
%  indicate to $\pp$ which are the positions corresponding to the witness state (which will be
%  $\ket{0}$ or $\ket{+}$, depending on the test type). The round then proceed as in the Dogwalker protocol, with $\pp$ running $V_x$
%  using the random $z_i$ as previously, and the Verifier performing the consistency checks.
%
%  For EPR-Computation and Rigidity-Computation, the Verifier also informs $\pv$ which are the positions
%  corresponding to the witness state. In the honest strategy $\pv$, in addition to the behaviour in the Dogwalker protocol, also teleports the witness to the $\pp$ using the positions informed by the Verifier. $\pv$ reports all measurements and measurement outcomes (including the ones for teleporting the witness).
%  In EPR-Computation, the positions are also informed to $\pp$ (as in EPR-Test rounds), who then
%  proceed as in the EPR-Test round.
%  
%  In Rigidity-Computation, the Verifier just ignores the outcomes for the
%  teleportation measurements and do the consistency checks as in the Dogwalker protocol.
%
%  The completeness of the protocol is stratightforward: if the provers use the
%  honest strategy for the delegation and $\pv$ teleports a witness that is
%  accepted with high probability by $V_x$, then the Verifier accepts with  high probability.
%
%  The soundness of the protocol follows from the soundness of the Dogwalker
%  protocol and the soundness of the QMA verifier. 
%  As in Lemma~\ref{lem:dogwalker-soundness}, if the acceptance probability in 
%  Rigidity-Test, Rigidity-Computation and EPR-Test is sufficiently high, there is an strategy for the provers where they follow the honest strategy and the acceptance probabilily in EPR-Computation is only slightly changed. We remark that the teleportation of the witness in Rigidity-Computation does not change anything, since the outcome measurments are ignored. If the provers follow the honest strategy, by the assumption that $x$ is a no-instance makes that no matter which state was teleported by $\pv$, the acceptance probability by $V_x$ is small and then the Verifier rejects with high probability.
%\end{proof}
%

\bibliography{delegation}

%\notesendofpaper

\end{document}
